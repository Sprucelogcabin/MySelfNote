# 个人经历

### 个人介绍

面试官您好，我叫华冉冉，来自河北大学网络空间安全与计算机学院，我的专业是信息安全，然后学习方面，四年成绩绩点是3.59，排名在我们专业是前20%，四年期间也是每一年都有获得河北大学优秀学生奖学金，生活上积极向上，乐于助人，去年4月份被选上中共预备党员，也参加过很多志愿活动，

关于课程方面，大一期间主要学习了解了C语言，然后加入了我们院的一个关于技术方面的社团，学习了java有关的一些知识，也学习了html,css等前端的知识。大二的时候开始学习java这门课程，

是作为选修学的。同时，我也选择留在了那个社团当组长，也带领学妹学弟做过几个项目，简历里边那个在线学习平台就是那个时候做的。

在大四上学期，我的课程比较少了，于是就在保定本地找了一个公司实习。在公司实习的话我也学到了好多东西。在公司实习做的都是商业项目，不仅要考虑功能还要考虑用户的体验。在这个公司我参与的主要项目就是：河北大学大型仪器设备档案归档项目。

在实习期间，我主要负责后端Java的开发工作。

前期主要是学习阶段，了解git的相关命令，学习了SSM框架的使用，以及vue，freemarker，JS前台的相关知识，以及如何搭建框架。在工作中负责比较单简单的模块的增删改查工作。

后期自己就负责一些比较难的技术点，通过自我学习解决比较难的问题。负责对接项目经理，分析需求文档，书写接口文档，设计数据库等任务。



### 优缺点

性格乐观，积极向上，善于沟通，因为之前大二在社团当组长的时候也有带领学弟学妹学一些东西，所以有一定的演讲能力，自学能力也还可以，适应能力也很强，能快速融于一个新的团队。缺点就是技术还不够深入，然后经验欠缺，以后会更加努力学习，弥补不足。

### 在线学习平台

1，在线学习平台有三个角色：管理员、老师、学生 
管理员：拥有这个平台的所有权限，平台只有一个管理员管理员拥有对老师和学生信息的增删改查等内容和
            一个课程信息管理 
老师：课程信息管理 ---- 老师请假 --- 管理员批复
          老师能够对学生信息进行增删改查处理。
          课件管理：拥有上传课件和搜索课件的功能。
          查看讨论话题：查看讨论话题、留言
          留作业：留作业---（平台上留）、查看学生完成情况（优、良、可、差）
学生：课程信息管理----学生请假----老师批复
          讨论话题：发起话题、查看话题、并回答话题
          课件管理：搜索和下载课件
          写作业：写作业----（平台上写）

2，文件上传和下载

上传的逻辑是将本地文件上传到tomcat的服务器路径下，然后插入数据库

下载就是把文件拉下来

在本地跑的话，是上传到了的tomcat的target路径下；放到服务上运行就直接上传到了服务器tomcat路径下

3，请假查看当月数据

```
<div>{{ layui.util.toDateString(d.time, "yyyy-MM-dd HH:mm:ss") }}</div>
```

（1）login表

![image-20220315162913913](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220315162913913.png)

（2）class表

![image-20220315163018460](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220315163018460.png)

（3）grade表

![image-20220315163129267](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220315163129267.png)

（4）leave表

![image-20220315163258066](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220315163258066.png)



### 河北大学大型仪器设备档案归档项目

1，简介图

![image-20220304155723518](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220304155723518.png)

2，对接河北大学统一工具类

![image-20220315160411689](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220315160411689.png)

3，短信验证

（1）**验证签名是否有效**
    1、签名生成：所有参数+时间戳+随时字符串 =》 排序 =》 appSerect + 加密
     2、服务端接受到：
      客户端传过来的 ：sign => 加密之后的字符串
     服务端需要和客户端一样的规则生成一个新的签名：sign
     1、获取到所有参数，不包含签名，生成一个新的
       对比两个签名是否一致 =>  确保参数没有被篡改！

（2）**签名规则**

​		1、线下分配appid和appsecret，针对不同的调用方分配不同的appid和appsecret

​		2、加入timestamp（时间戳），5分钟内数据有效

​		3、加入临时流水号 nonce（防止重复提交），至少为10位。针对查询接口，流水号只用于日志落地，便于后期日志核查。针对办理类接口需校验流水号在有效期内的唯一性，以避免重复请求。

​		4、加入签名字段signature，所有数据的签名信息。

以上字段放在请求头中。

（3）**签名算法的实现**

​		1）验证必须的头部参数

​		2）获取头部参数，request参数，Url请求路径，请求体Body，把这些值放入SortMap中进行排序

​		3）对SortMap里面的值进行拼接

​		4）对拼接的值进行加密，生成sign

​		5）把生成的sign和前端传入的sign进行比较，如果不相同就返回错误

## 面试

###### 1，spring和springBoot,

Spring框架为开发Java应用程序提供了全面的基础架构支持。它包含一些很好的功能，如依赖注入和开箱即用的模块，Spring Boot基本上是Spring框架的扩展，它消除了设置Spring应用程序所需的XML配置，为更快，更高效的开发生态系统铺平了道路。

###### 1,TCP和UDP的区别

![image-20220323153533351](C:\Users\qing  chun\AppData\Roaming\Typora\typora-user-images\image-20220323153533351.png)

###### 2，TCP三次握手过程

第一次握手：主机A通过向主机B 发送一个含有同步序列号的标志位的数据段给主机B，向主机B 请求建立连接，通过这个数据段， 主机A告诉主机B 两件事：我想要和你通信；你可以用哪个序列号作为起始数据段来回应我。

第二次握手：主机B 收到主机A的请求后，用一个带有确认应答（ACK）和同步序列号（SYN）标志位的数据段响应主机A，也告诉主机A两件事：我已经收到你的请求了，你可以传输数据了；你要用那个序列号作为起始数据段来回应我

第三次握手：主机A收到这个数据段后，再发送一个确认应答，确认已收到主机B 的数据段："我已收到回复，我现在要开始传输实际数据了，这样3次握手就完成了，主机A和主机B 就可以传输数据了。

###### 3，TCP四次挥手

第一次： 当主机A完成数据传输后,将控制位FIN置1，提出停止TCP连接的请求 ；

第二次： 主机B收到FIN后对其作出响应，确认这一方向上的TCP连接将关闭,将ACK置1；

第三次： 由B 端再提出反方向的关闭请求,将FIN置1 ；

第四次： 主机A对主机B的请求进行确认，将ACK置1，双方向的关闭结束.。

###### 4，为什么要四次挥手

因为是双方彼此都建立了连接，因此双方都要释放自己的连接，A向B发出一个释放连接请求，他要释放链接表明不再向B发送数据了，此时B收到了A发送的释放链接请求之后，给A发送一个确认，A不能再向B发送数据了，它处于FIN-WAIT-2的状态，但是此时B还可以向A进行数据的传送。此时B向A 发送一个断开连接的请求，A收到之后给B发送一个确认。此时B关闭连接。A也关闭连接。

## 八大排序

![img](https://img-blog.csdnimg.cn/20190206100152611.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI0MDE2MzA5,size_16,color_FFFFFF,t_70)

### **快排**

选择一个基准元素，将比基准元素小的元素放在其前面，比基准元素大的元素放在其后面，然后在将小于基准值元素的子数列和大于基准元素的子数列按原来的方法排序，直到整个序列有序;

#### 快速排序时间复杂度

> 快速排序的时间复杂度在最坏情况下是O(N2)，平均的时间复杂度是O(N*lgN)。

这句话很好理解: 假设被排序的数列中有N个数。遍历一次的时间复杂度是O(N)，需要遍历多少次呢? 至少lg(N+1)次，最多N次。

- 为什么最少是lg(N+1)次? 快速排序是采用的分治法进行遍历的，我们将它看作一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的定义，它的深度至少是lg(N+1)。因此，快速排序的遍历次数最少是lg(N+1)次。
- 为什么最多是N次? 这个应该非常简单，还是将快速排序看作一棵二叉树，它的深度最大是N。因此，快读排序的遍历次数最多是N次。

**优缺点**

优点：极快数据移动少；

缺点：不稳定；

**效率分析**

此排序算法的效率在序列越乱的时候，效率越高。在数据有序时，会退化成冒泡排序；

**优化方法**

a.当待排序序列的长度分割到一定大小后，使用插入排序；

原因：对于很小和部分有序的数组，快排不如插排好。当待排序序列的长度分割到一定大小后，继续分割的效率比插入排序要差，此时可以使用插排而不是快排；

b.在一次分割结束后，可以把与key相等的元素聚集在一起，继续下次分割时，不必再对于key相等元素分割；

**应用场景**

 a.求数组中第k小的数

将数组中某一个元素m作为划分依据,即m=arr[0]。若m前面的元素个数大于k，则第k小的数一定在m前面的元素中，这时我们只需要继续在m前面的元素中找第k小的数；若m前面的元素小于k，则第k小的数一定在m后面的元素中，这时我们只需要在m后面的元素中找第k小的数；

```java
public class QuickSort {
    public static void main(String[] args) {
        Random random = new Random();
        int[] arr = new int[10];
        for (int i = 0; i < 10; i++) {
            arr[i] = random.nextInt(100);
        }
        System.out.println("排序前："+Arrays.toString(arr));
        quickSort(arr, 0, arr.length - 1);
        System.out.println("排序后：" + Arrays.toString(arr));
    }

    public static void quickSort(int[] arr, int start, int end) {
        if (arr.length < 0) {
            return;
        }
        //如果最左边索引等于右边索引，即数组中只有一个元素，直接返回
        if (start >= end) {
            return;
        }
        int left = start;
        int right = end;
        //选取左边的数为基准数
        int temp = arr[left];
        while (left < right) {
            //right左移，直到遇到比基准数小的
            while (left < right && arr[right] >= temp) {
                right--;
            }
            arr[left] = arr[right];
            //left右移，直到遇到比基准数大的
            while (left < right && arr[left] <= temp) {
                left++;
            }
            arr[right] = arr[left];
        }
        arr[left] = temp;
        //对基准数左边进行排序
        quickSort(arr, start, left - 1);
        //对基准数右边进行排序
        quickSort(arr, left + 1, end);
    }
}

```



### 简单选择排序

(1)从待排序序列中，找到关键字最小的元素；

(2)如果最小元素不是待排序序列的第一个元素，将其和第一个元素互换；

(3)从余下的 N - 1 个元素中，找出关键字最小的元素，重复(1)、(2)步，直到排序结束。

最好情况下，即待排序记录初始状态就已经是升序排列了，则不需要移动记录。

最坏情况下，即待排序记录初始状态是按第一条记录最大，之后的记录从大到小顺序排列，则需要移动记录的次数最多为3（n-1）。简单选择排序过程中需要进行的比较次数与初始状态下待排序的记录序列的排列情况无关。当i=1时，需进行n-1次比较；当i=2时，需进行n-2次比较；依次类推，共需要进行的比较次数是(n-1)+(n-2)+…+2+1=n(n-1)/2，即进行比较操作的时间复杂度为**O(n^2)，进行移动操作的时间复杂度为O(n)**。

简单选择排序是不稳定排序。

**基本思想**

第一趟：从第一个记录开始，将后面n-1个记录进行比较，找到其中最小的记录和第一个记录进行交换；

第二趟：从第二个记录开始，将后面n-2个记录进行比较，找到其中最小的记录和第2个记录进行交换；

...........

第i趟：从第i个记录开始，将后面n-i个记录进行比较，找到其中最小的记录和第i个记录进行交换；

以此类推，经过n-1趟比较，将n-1个记录排到位，剩下一个最大记录直接排在最后；

```java
public static void simpleSort(int[] arr){
    int length = arr.length;
    int index;
    for(int i = 0;i<length;i++){
        index = i;
        //每次找到最小数的索引，并与当前值交换
        for(int j = i+1;j<length;j++){
            if(arr[j]<arr[index]){
                index = j;
            }
        }
        int temp = arr[i];
        arr[i] = arr[index];
        arr[index] = temp;
    }
}

```



### 冒泡排序

（1）**基本原理**

在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现他们的排序与排序要求相反时，就将他们互换。

（2）**优缺点**

优点：稳定

缺点：慢，每次只能移动两个相邻的数据；

```java
public static void bubbleSort(int[] arr){
        int length = arr.length;
        for(int i = 0;i<length - 1;i++){
            for(int j = 0; j < arr.length - i - 1;j++){
                //若arr[j]>arr[j+1]则下沉
                if(arr[j] > arr[j + 1]){
                    int temp = arr[j];
                    arr[j] = arr[j+1];
                    arr[j+1] = temp;
                }
            }
        }
    }
```



### **插入排序**

（1）**基本思想**

将一个记录插入到已排序好的有序表中，从而得到一个新的，记录数增1的有序表。即先将序列的第一个记录看成是一个有序的子序列，然后从第二个记录逐个进行插入，直至整个序列有序为止。

（2）优缺点

优点：稳定，快

缺点：比较次数不一定，比较次数越少，插入点后的数据移动越多，特别是数据量庞大的时候

```java
public static void insertSort(int[] arr){
        int length = arr.length;
        for(int i = 1;i < length;i++){
            //每次将一个新的数据插入到一个有序数组中
            for(int j = i;j > 0;j--){
                if(arr[j] < arr[j-1]){
                    int temp = arr[j];
                    arr[j] = arr[j-1];
                    arr[j-1] = temp;
                }else{
                    break;
                }
            }
        }
    }
```



### 基数排序

基数排序（radix sort）属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort）或bin sort，顾名思义，它是透过键值的部份资讯，将要排序的==元素分配==至某些“桶”中，藉以达到排序的作用，基数排序法是属于==稳定性==的排序，其==时间复杂度==为O (nlog(r)m)，其中r为所采取的基数，而m为堆数，在某些时候，基数排序法的效率高于其它的稳定性排序法。

```java
public class RadixSort {
    public static void main(String[] args) {
        Random random = new Random();
        int[] arr = new int[10];
        for (int i = 0; i < arr.length; i++) {
            arr[i] = random.nextInt(100);
        }
        System.out.println("排序前："+ Arrays.toString(arr));
        sort(arr,2);
        System.out.println("排序后："+ Arrays.toString(arr));
    }

    public static void sort(int[] arr,int d){
        //参数d代表最大的数有多少位
        //k相当于一个计数器，记录放到数组哪个位置
        int k = 0;
        int n = 1;
        //控制键值排序依据在哪一位
        int m = 1;
        //数组的第一位表示可能的余数0-9
        int[][] temp = new int[10][arr.length];
        //数组order[i]用来表示该位是i的数的个数
        int[] order = new int[10];
        while (m <= d){
            //依次将余数为t的数放入第t行第order[t]的位置
            for (int i = 0; i < arr.length; i++) {
                int t = (arr[i]/n)%10;
                temp[t][order[t]] = arr[i];
                order[t]++;
            }
            //依次取出每一个桶中的元素，放入数组中的新位置
            for(int i = 0;i < 10;i++){
                if(order[i] != 0){
                    for(int j = 0;j < order[i];j++){
                        arr[k] = temp[i][j];
                        k++;
                    }
                }
                order[i] = 0;
            }
            n *= 10;
            k = 0;
            m++;
        }
    }
}

```



### 堆排序

4.1、**二叉堆定义**

二叉堆是完全二叉树或近似完全二叉树。二叉堆满足两个特性:

（1）父结点的键值总是大于或者等于（小于或者等于）任何一个子节点的键值；

（2）每个结点的左子树和右子树都是一个二叉堆；

当父结点的键值总是大于或者等于任何一个子节点的键值时为大根堆。当父结点的键值总是小于或等于任何一个子节点的键值时为小根堆；

4.2、**堆的存储**

一般都用数组来表示堆，i结点的父结点下标就为（i-1）/2.它的左右子节点的下标分别为2*i+1和2*i+2.

![img](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20211003201923.jpeg)

4.3、堆的插入：

每次插入都是将新数据放在数组最后。可以发现从这个新数据的父结点到根结点必然为一个有序的数列，然后将这个新数据插入到这个有序数据中

（1）**用大根堆排序的基本思想**

先将初始数组建成一个大根堆，此堆为初始的无序区；

再将最大的元素和无序区的最后一个记录交换，由此得到新的无序区和有序区，且满足<=的值；

由于交换后新的根可能违反堆性质，故将当前无序区调整为堆。然后再次将其中最大的元素和该区间的最后一个记录交换，由此得到新的无序区和有序区，且仍满足关系的值<=的值，同样要将其调整为堆；

..........

直到无序区只有一个元素为止；

4.4：**应用**

寻找M个数中的前K个最小的数并保持有序；

时间复杂度：O(K)[创建K个元素最大堆的时间复杂度] +（M-K）*log(K)[对剩余M-K个数据进行比较并每次对最大堆进行从新最大堆化]

```java
public class HeapSort {
    //堆排序，从小到大
    public static void main(String[] args) {
        Random random = new Random();
        int[] arr = new int[10];
        for(int i=0;i<arr.length;i++){
            arr[i] = random.nextInt(50);
        }

        //构建大顶堆
        for(int i = (arr.length-1)/2;i>=0;i--){
            adjustHead(arr,arr.length,i);
        }
        System.out.println(Arrays.toString(arr));
        //逐次调整，将堆顶与最后一个元素交换，把大的元素放在后边
        for(int i = arr.length-1;i>0;i--){
            swap(arr,0,i);
            adjustHead(arr,i,0);
        }

        System.out.println(Arrays.toString(arr));
    }

    public static void adjustHead(int[] arr,int size,int index){
        int leftIndex = index*2+1;
        int rightIndex = index*2+2;
        int minIndex = index;
        //如果左边的比较大，就交换
        if(leftIndex < size && arr[leftIndex] > arr[minIndex]){
            minIndex = leftIndex;
        }
        //如果右边比较大，就交换
        if(rightIndex < size && arr[rightIndex] > arr[minIndex]){
            minIndex = rightIndex;
        }
        //交换，并调整子堆
        if(minIndex != index){
            swap(arr,index,minIndex);
            adjustHead(arr,size,minIndex);
        }
    }

    public static void swap(int[] arr, int i,int j){
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
    
}

```



### **希尔排序**

（1）**基本思想**

先将整个待排序元素序列分割成若干子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序（因为直接插入排序在元素基本有序的情况下，效率很高）；

（2）**适用场景**

比较在希尔排序中是最主要的操作，而不是交换。用已知最好的步长序列的希尔排序比直接插入排序要快，甚至在小数组中比快速排序和堆排序还快，但在涉及大量数据时希尔排序还是不如快排；

```java
public class ShellSort {
    public static void main(String[] args) {
        Random random = new Random();
        int[] arr = new int[10];
        for (int i = 0; i < arr.length; i++) {
           arr[i] = random.nextInt(100);
        }
        System.out.println("排序前"+ Arrays.toString(arr));
        shellSort(arr);
        System.out.println("排序后："+Arrays.toString(arr));
    }

    public static void shellSort(int[] arr){
        //步长
        int gap = arr.length;
        while (true){
            //步长每次减半
            gap /= 2;
            for(int i = 0;i < gap;i++){
                //使用简单插入排序
                for(int j = i+gap;j<arr.length;j+=gap){
                    int k = j - gap;
                    while (k >= 0 && arr[k] > arr[k+gap]){
                        int temp = arr[k];
                        arr[k] = arr[k+gap];
                        arr[k+gap] = temp;
                        k -= gap;
                    }
                }
            }
            if(gap == 1){
                break;
            }
        }
    }
}

```



### **归并排序**

**（1）基本思想**

首先将初始序列的n个记录看成是n个有序的子序列，每个子序列的长度为1，然后两两归并，得到n/2个长度为2的有序子序列，在此基础上，再对长度为2的有序子序列进行两两归并，得到若干个长度为4的有序子序列，以此类推，直到得到一个长度为n的有序序列为止；

***（2）适用场景***

若n较大，并且要求排序稳定，则可以选择归并排序。

```java
public class MergeSort {
    public static void main(String[] args) {
        Random random = new Random();
        int[] nums = new int[10];
        for(int i = 0;i<nums.length;i++){
            nums[i] = random.nextInt(100);
        }
        System.out.println("排序前："+Arrays.toString(nums));
        sort(nums,0,nums.length-1);
        System.out.println("排序后："+Arrays.toString(nums));
    }

    public static int[] sort(int[] nums,int low,int high){
        int mid = (low + high)/2;
        if(low<high){
            //排序左边
            sort(nums,low,mid);
            //排序右边
            sort(nums,mid+1,high);
            //左右归并
            merge(nums,low,mid,high);

        }
        return nums;
    }

    public static void merge(int[] nums,int low,int mid,int high){
        int[] temp = new int[high-low+1];
        int i = low;
        int j = mid + 1;
        int k = 0;
        //把较小的数先移到新数组中
        while(i<=mid && j<=high){
            if(nums[i]<nums[j]){
                temp[k++] = nums[i++];
            }else {
                temp[k++] = nums[j++];
            }
        }
        //把左边剩余的数移入数组
        while(i<=mid){
            temp[k++] = nums[i++];
        }
        //把右边剩余的数移入数组
        while (j<=high){
            temp[k++] = nums[j++];
        }
        //把新数组中的数覆盖nums数组
        for(int x = 0;x<temp.length;x++){
            nums[x+low] = temp[x];
        }
    }
}
```



### 总结

一、稳定性:

　  稳定：冒泡排序、插入排序、归并排序和基数排序

　　不稳定：选择排序、快速排序、希尔排序、堆排序

二、平均时间复杂度

　　O(n^2):直接插入排序，简单选择排序，冒泡排序。

　　在数据规模较小时（9W内），直接插入排序，简单选择排序差不多。当数据较大时，冒泡排序算法的时间代价最高。性能为O(n^2)的算法基本上是相邻元素进行比较，基本上都是稳定的。

　　O(nlogn):快速排序，归并排序，希尔排序，堆排序。

　　其中，快排是最好的， 其次是归并和希尔，堆排序在数据量很大时效果明显。

三、排序算法的选择

　　1.数据规模较小

 　　（1）待排序列基本序的情况下，可以选择**直接插入排序**；

 　　（2）对稳定性不作要求宜用简单选择排序，对稳定性有要求宜用插入或冒泡

　　2.数据规模不是很大

　　（1）完全可以用内存空间，序列杂乱无序，对稳定性没有要求，**快速排序**，此时要付出log（N）的额外空间。

　　（2）序列本身可能有序，对稳定性有要求，空间允许下，宜用归并排序

　　3.数据规模很大

  　　（1）对稳定性有求，则可考虑归并排序。

  　　（2）对稳定性没要求，宜用堆排序

　　4.序列初始基本有序（正序），宜用直接插入，冒泡

## 链表反置

```
public ListNode Rever() {
		ListNode preNode = null;
		ListNode nextNode = null;
		while(head!=null) {
			nextNode = head.getNext();
			head.setNext(preNode);
			preNode = head;
			head = nextNode;
		}
		return preNode;
	}
```

# 简历知识点

### HashMap

（1）哈希表：在哈希表中进行添加，删除，查找等操作，性能十分之高，不考虑哈希冲突的情况下（后面会探讨下哈希冲突的情况），仅需一次定位即可完成，时间复杂度为O(1)，

（2）**哈希表的主干就是数组**。

**比如我们要新增或查找某个元素，我们通过把当前元素的关键字 通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可完成操作。**

这个函数可以简单描述为：**存储位置 = f(关键字)** ，这个函数f一般称为哈希函数，这个函数的设计好坏会直接影响到哈希表的优劣。

（3）**如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办**？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的**哈希冲突**，也叫**哈希碰撞**。哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址），再散列函数法，链地址法，而HashMap即是采用了**链地址法**，也就是**数组+链表**的方式。

## HashMap底层源码

JDK1.8 之前 HashMap 底层是 **数组和链表** 结合在⼀起使⽤也就是 链表散列。 HashMap 通过 key 的hashCode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) & hash 判断当前元素存放的位置，如果定位到的数组位置不含链表，就可以直接插入，时间复杂度为O(1)，如果当前位置存在元素的话，就判断该元素与要存⼊的元素的 hash值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。链表出现的越少，HashMap性能越高。

相⽐于之前的版本， JDK1.8 之后在解决哈希冲突时有了较⼤的变化，当链表⻓度⼤于阈值（默认为8）（将链表转换成红⿊树前会进行一个判断，如果当前数组的⻓度⼩于 64，那么会选择先进⾏数组扩容，⽽不是转换为红⿊树）时，将链表转化为红⿊树，以减少搜索时间。

#### 1.7和1.8的区别

* HashMap在1.7中是由 **数组＋链表**  也可以说 **哈希表＋链表** 实现的,

  HashMap在1.8中是由 **数组＋链表** +**红黑树** 

* 在**JDK1.7**中，HashMap存储的是**Entry对象**

  在**JDK1.8**当中，HashMap存储的是**实现Entry接口**的**Node对象**

* **JDK1.7**用的是**头插法**，而**JDK1.8及之后**使用的都是**尾插法**

  * **为什么从头插法改成尾插法？**

    在1.7中，是没有红黑树的，在并发的情况下单链表过长**，**会成环**，**发生死循环

    在1.8中，尾插法就可以解决这个问题

  - 1.8也没有解决数据覆盖的问题

* **扩容机制**

  * 在**JDK1.7的时候是先扩容后插入**的，这样就会导致无论**这一次插入是不是发生hash冲突都需要进行扩容**，如果这次插入的并**没有发生Hash冲突**的话，那么就会造成**一次无效扩容**，

    但是**在1.8的时候是先插入再扩容**的，优点是可以**减少1.7的一次无效的扩容**，因为如果这次插入没有发生Hash冲突的话，那么其实就不会造成扩容

  * **扩容过程不一样（上面）**

#### HashMap中获取hash值的方法

>  首先判断 key 是否为 null，为 null 则返回 0 ，所以 key 为空的元素对应的[数组](https://so.csdn.net/so/search?q=数组&spm=1001.2101.3001.7020)坐标一定是 0，而且根据 put 会覆盖相同 key 的逻辑来思考，key 为空的元素最多只有一个。不为 null 则返回 key 的 hashCode异或上它的高16位。 

```
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

#### HashMap扩容

#### 进行位运算的原因

> (h >>> 16)是无符号右移16位的运算，右边补0，得到 hashCode 的高16位
> (h = key.hashCode()) ^ (h >>> 16) 把 hashCode 和它的高16位进行异或运算，可以使得到的 hash 值更加散列，极可能减少哈希冲突，提升性能。
> 而这么来看 hashCode 被散列 (异或) 的是低16位。原因是获取 key 所对应数组下标的方式是 hash值 % 数组长度。比如 10001 % 101 取余的结果只会看前面二进制数的低三位，其余高位不影响取余结果。而 HashMap 数组长度一般不会超过2的16次幂，那么高16位在大多数情况是用不到的，所以只需要拿 key 的 HashCode 和它的高16位做异或即可让hash值更加散列。

#### 为什么链表出现的越少，HashMap性能越高

简单来说，**HashMap由数组+链表组成的，数组是HashMap的主体**，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度为O(n)，首先遍历链表，存在即覆盖，否则新增；对于查找操作来讲，仍需遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。

#### put的流程（1.8）

1.通过**hash函数计算key的hash值**，调用putVal方法

2.如果hash表为空，调用**resize()方法创建一个hash表**

3.根据**hash值索引hash表对应桶位置，判断该位置是否有hash碰撞**

　　3.1 **没有碰撞，直接插入映射入hash表**

　　3.2 **有碰撞，遍历桶中节点**

　　　　3.2.1 第一个节点匹配，记录该节点

　　　　3.2.2 第一个节点没有匹配，桶中结构为红黑树结构，按照红黑树结构添加数据，记录返回值

　　　　3.2.3 第一个节点没有匹配，桶中结构是链表结构。遍历链表，找到key映射节点，记录，退出循环。
　　　　　　没有则在链表尾部添加节点。插入后判断链表长度是否大于转换为红黑树要求，符合则转为红黑树结构

　　　　3.2.4 用于记录的值判断是否为null，不为空则是需要插入的映射key在hash表中原来有，替换值，返回旧值putValue方法结束

![image-20210807160731433](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210807160731433.png)

**总结：**HashMap在put方法中，它使用hashCode()和equals()方法。当我们通过传递key-value对调用put方法的时候，HashMap使用Key hashCode()和哈希算法来找出存储key-value对的索引。如果索引处为空，则直接插入到对应的数组中，否则，判断是否是红黑树，若是，则红黑树插入，否则遍历链表，若长度不小于8，则将链表转为红黑树，转成功之后 再插入。

#### 为什么HashMap的容量大小要取2的指数倍？

有两个原因：**1**，**提升计算效率**：因为2的指数倍的二进制都是只有一个1，而2的指数倍-1的二进制就都是左全0右全1。那么跟（2^n - 1）做按位与运算的话**，**得到的值就一定在【0,（2^n - 1）】区间内**，**这样的数就刚合适可以用来作为哈希表的容量大小，因为往哈希表里插入数据，就是要对其容量大小取余，从而得到下标。所以用2^n做为容量大小的话，就可以用按位与操作替代取余操作，提升计算效率**。**2.**便于动态扩容后的重新计算哈希位置时能均匀分布元素**：因为动态扩容仍然是按照2的指数倍，所以按位与操作的值的变化就是二进制高位+1，比如16扩容到32，二进制变化就是从0000 1111（即15）到0001 1111（即31）**，**那么这种变化就会使得需要扩容的元素的哈希值重新按位与操作之后所得的下标值要么不变，要么+16（即挪动扩容后容量的一半的位置），这样就能使得原本在同一个链表上的元素均匀（相隔扩容后的容量的一半）分布到新的哈希表中。

#### 线程安全HashMap

- **Hashtable线程安全但效率低下**

Hashtable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下Hashtable的效率非常低下。因为当一个线程访问Hashtable的同步方法时，其他线程访问Hashtable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。

**解决**

**分段锁（ConcurrentHashMap所使用的锁分段技术）**

HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是**ConcurrentHashMap所使用的锁分段技术**，

##### ConcurrentHashMap（JDK1.7）

**JDK1.7的时候ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成**。**首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。**有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要**按顺序**锁定所有段，操作完毕后，又**按顺序**释放所有段的锁。这里“按顺序”是很重要的，否则极有可能出现死锁，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，但是，仅仅是将数组声明为final的并不保证数组成员也是final的，这需要实现上的保证。这可以确保不会出现死锁，因为获得锁的顺序是固定的。
 ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。

![img](https:////upload-images.jianshu.io/upload_images/17755742-0aeb208cbf2192f9.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/502/format/webp)

#### **LinkedHashMap**

LinkedHashMap的概述: Map 接口的哈希表和链接列表实现，具有可预知的迭代顺序LinkedHashMap的特点： 底层的数据结构是链表和哈希表 元素有序 并且唯一
元素的有序性由链表数据结构保证 唯一性由 哈希表数据结构保证
Map集合的数据结构只和键有关

#### TreeMap集合

TreeMap 键不允许插入null
TreeMap: 键的数据结构是红黑树,可保证键的排序和唯一性
排序分为自然排序和比较器排序
线程是不安全的效率比较高
TreeMap集合排序：
实现Comparable接口，重写CompareTo方法
使用比较器

#### HashTable

Hashtable继承Map接口，同样实现一个key-value映射的哈希表。其数据结构同样基于数组加链表，任何非空（non-null）的对象都可作为key或者value。

Hashtable通过initial capacity和load factor两个参数调整性能。通常缺省的load factor 0.75也和hashMap相同。

**由于作为key的对象将通过获取它的hashcode来确定与之对应的value的位置，因此任何作为key的对象都必须实现hashCode和equals方法，因为HashTable直接调用对象的方法。**hashCode和equals方法继承自根类Object，如果你用自定义的类当作key的话，要相当小心，按照散列函数的定义，如果两个对象相 同，即obj1.equals(obj2)=true，则它们的hashCode必须相同，但如果两个对象不同，则它们的hashCode不一定不同，

如果两个不同对象的hashCode相同，这种现象称为冲突，即两个对象在同一链表上存储，冲突会导致操作哈希表的时间开销增大，所以尽量定义好的hashCode()方法，能加快哈希表的操作。

如果相同的对象有不同的hashCode，对哈希表的操作会出现意想不到的结果，要避免这种问题，要牢记一条：要同时覆写equals方法和hashCode方法，而不是只写其中一个。

HashTable是线程安全的，和HashMap不同

HashTable在不指定容量的情况下的默认容量为11，而HashMap为16，Hashtable不要求底层数组的容量一定是为2的n次方，而HashMap则一定为2的n次方。

Hashtable扩容时，将容量变为原来的2倍加1，而HashMap扩容时，将容量变为原来的2倍

### List

List是Java中比较常用的集合类，关于List接口有很多实现类，本文就来简单介绍下其中几个重点的实现ArrayList、LinkedList和Vector之间的关系和区别。

List 是一个接口，它继承于Collection的接口。它代表着有序的队列。当我们讨论List的时候，一般都和Set作比较。

**ArrayList**

ArrayList底层是用数组实现的，可以认为ArrayList是一个可改变大小的数组。随着越来越多的元素被添加到ArrayList中，其规模是动态增加的。

**LinkedList**

LinkedList底层是通过双向链表实现的。所以，LinkedList和ArrayList之前的区别主要就是数组和链表的区别。

> 数组中查询和赋值比较快，因为可以直接通过数组下标访问指定位置。
>
> 
>
> 链表中删除和增加比较快，因为可以直接通过修改链表的指针（Java中并无指针，这里可以简单理解为指针。其实是通过Node节点中的变量指定）进行元素的增删。

所以，LinkedList和ArrayList相比，增删的速度较快。但是查询和修改值的速度较慢。同时，LinkedList还实现了Queue接口，所以他还提供了offer(), peek(), poll()等方法。

**Vector**

Vector和ArrayList一样，都是通过数组实现的，但是Vector是线程安全的。和ArrayList相比，其中的很多方法都通过同步（synchronized）处理来保证线程安全。

如果你的程序不涉及到线程安全问题，那么使用ArrayList是更好的选择（因为Vector使用synchronized，必然会影响效率）。

二者之间还有一个区别，就是扩容策略不一样。在List被第一次创建的时候，会有一个初始大小，随着不断向List中增加元素，当List认为容量不够的时候就会进行扩容。Vector缺省情况下自动增长原来一倍的数组长度，ArrayList增长原来的50%。



### LinkedList，ArrayList

**如何选择**

如果涉及到多线程，那么就选择Vector（当然，你也可以使用ArrayList并自己实现同步）。

如果不涉及到多线程就从LinkedList、ArrayList中选。 LinkedList更适合从中间插入或者删除（链表的特性）。 ArrayList更适合检索和在末尾插入或删除（数组的特性）。

- 

###  https请求流程

1.客户端想服务器发起HTTPS的请求，连接到服务器的443端口；

2.服务器将非对称加密的公钥传递给客户端，以证书的形式回传到客户端

3.服务器接受到该公钥进行验证，就是验证2中证书，如果有问题，则HTTPS请求无法继续；如果没有问题，则上述公钥是合格的。（第一次HTTP请求）客户端这个时候随机生成一个私钥，成为client key,客户端私钥，用于对称加密数据的。使用前面的公钥对client key进行非对称加密；

4.进行二次HTTP请求，将加密之后的client key传递给服务器；

5.服务器使用私钥进行解密，得到client key,使用client key对数据进行对称加密

6.将对称加密的数据传递给客户端，客户端使用非对称解密，得到服务器发送的数据，完成第二次HTTP请求。

### linux系统常用命令

```
# 与用户或用户组名有关的参数：
-user name : 列出文件所有者为name的文件
-group name : 列出文件所属用户组为name的文件
-uid n : 列出文件所有者为用户ID为n的文件
-gid n : 列出文件所属用户组为用户组ID为n的文件
```

```
 与文件权限及名称有关的参数：
-name filename ：找出文件名为filename的文件
-size [+-]SIZE ：找出比SIZE还要大（+）或小（-）的文件
-tpye TYPE ：查找文件的类型为TYPE的文件，TYPE的值主要有：一般文件（f)、设备文件（b、c）、
             目录（d）、连接文件（l）、socket（s）、FIFO管道文件（p）；
-perm mode ：查找文件权限刚好等于mode的文件，mode用数字表示，如0755；
-perm -mode ：查找文件权限必须要全部包括mode权限的文件，mode用数字表示
-perm +mode ：查找文件权限包含任一mode的权限的文件，mode用数字表示
```

# Redis

### 为什么要用 redis/为什么要用缓存

主要从“高性能”和“高并发”这两点来看待这个问题。

**高性能：**

假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！

**高并发：**

直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

### 为什么redis的zset用跳表不用红黑树

共同点：两者**插入删除，删除，查找以及迭代输出**时间复杂度红黑树和跳表的时间复杂度是一样的

跳表在区间查询的时候效率是高于红黑树的，跳表进行查找O(logn)的时间复杂度定位到区间的起点，然后在原始链表往后遍历就可以了 ，其他插入和单个条件查询，更新两者的复杂度都是相同的O(logn)
跳表的代码实现相对于红黑树更容易实现，
跳表更加灵活，他可以通过改变索引构建策略，有效平衡执行效率和内存消耗。（红黑树的平衡是通过左旋转和有旋转来进行平衡）

### redis 的线程模型

> 参考地址:https://www.javazhiyin.com/22943.html

redis 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。


###  redis 和 memcached 的区别

对于 redis 和 memcached 我总结了下面四点。现在公司一般都是用 redis 来实现缓存，而且 redis 自身也越来越强大了！

1. **redis支持更丰富的数据类型（支持更复杂的应用场景）**：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。
2. **Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。**
3. **集群模式**：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.
4. **Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。**


> 来自网络上的一张图，这里分享给大家！

![redis 和 memcached 的区别](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/61603179.jpg)



### Redis操作多个key

- 原生命令mset,mget，具有原子性

- pipeline:使用pipeline的命令个数不能太多，不然数据量过大，增加客户端的等待时间，可能会网络堵塞，可以将大量命令的拆分多个小的pipeline命令来完成。通过redis事务保证原子性。

  步骤：

  - 获取Jedis对象（一般从连接池中获取）
  - 获取Jedis对象的pipeline对象
  - 添加指令
  - 执行指令

### redis分布式锁实现原理redlock

抽奖，统计奖品数量，保证一个人抽到以后其他人能看到数量-1

#### 特性

Redis 官方站这篇文章提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。

<!-- more -->

它可以保证以下特性：

1. 安全特性：互斥访问，即永远只有一个 client 能拿到锁
2. 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
3. 容错性：只要大部分 Redis 节点存活就可以正常提供服务

#### 怎么在单节点上实现分布式锁

> SET resource_name my_random_value NX PX 30000

主要依靠上述命令NX，该命令仅当 Key 不存在时（NX保证）set 值，并且设置过期时间 3000ms （PX保证），值 my_random_value 必须是所有 client 和所有锁请求发生期间唯一的，释放锁的逻辑是：

```lua
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

上述实现可以避免释放另一个client创建的锁，如果只有 del 命令的话，那么如果 client1 拿到 lock1 之后因为某些操作阻塞了很长时间，此时 Redis 端 lock1 已经过期了并且已经被重新分配给了 client2，那么 client1 此时再去释放这把锁就会造成 client2 原本获取到的锁被 client1 无故释放了，但现在为每个 client 分配一个 unique 的 string 值可以避免这个问题。至于如何去生成这个 unique string，方法很多随意选择一种就行了。

#### Redlock 算法

算法很易懂，起 5 个 master 节点，分布在不同的机房尽量保证可用性。为了获得锁，client 会进行如下操作：

1. 得到当前的时间，微秒单位
2. 尝试顺序地在 5 个实例上申请锁，当然需要使用相同的 key 和 random value，这里一个 client 需要合理设置与 master 节点沟通的 timeout 大小，避免长时间和一个 fail 了的节点浪费时间
3. 当 client 在大于等于 3 个 master 上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。
4. 如果锁申请到了，那么锁真正的 lock validity time 应该是 origin（lock validity time） - 申请锁期间流逝的时间
5. 如果 client 申请锁失败了，那么它就会在少部分申请成功锁的 master 节点上执行释放锁的操作，重置状态

#### 失败重试

如果一个 client 申请锁失败了，那么它需要稍等一会在重试避免多个 client 同时申请锁的情况，最好的情况是一个 client 需要几乎同时向 5 个 master 发起锁申请。另外就是如果 client 申请锁失败了它需要尽快在它曾经申请到锁的 master 上执行 unlock 操作，便于其他 client 获得这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得 client 无法联系上这些 master，那么这种浪费就是不得不付出的代价了。

#### 放锁

放锁操作很简单，就是依次释放所有节点上的锁就行了

#### 性能、崩溃恢复和 fsync

如果我们的节点没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这是注意 **整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！** 违反了互斥性。如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，我们规定在 max TTL 期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。

### redis缓存更新策略

1. LRU（最近最少使用，首先淘汰最长时间未被使用的页面）/LFU(最近不常用 淘汰一定时间内不常使用的页面)/FIFO(先进出去)算法的剔除：例如maxmemory-policy
2. 超时剔除：例如expire
3. 主动更新：开发控制生命周期

![image-20220316170501120](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220316170503.png)

低一致性：最大内存和淘汰策略

高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底

## Redis数据类型

string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。

**String（字符串）**

 String是redis中最基本的数据类型，一个key对应一个value。 

string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。

string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。

**实战场景**

- **缓存**：经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力。
- **计数器**：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。
- **session**：常见方案spring session + redis实现session共享，

**List（列表）**

Redis中的List其实就是链表（Redis用双端链表实现List）。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。

**实战场景**

- **微博TimeLine**: 有人发布微博，用lpush加入时间轴，展示新的列表信息。
- **消息队列**

**Hash（哈希）**

Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。 

Redis hash 是一个键值(key=>value)对集合。

**实战场景**

- **缓存**： 能直观，相比string更节省空间，的维护缓存信息，如用户信息，视频信息等 

**Set（集合）**

Redis 的 Set 是 string 类型的无序集合， 集合中不能出现重复的数据 。

集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。

比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。

**实战场景**

- **标签**（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。
- **点赞，或点踩，收藏等**，可以放到set中实现

**zset(sorted set：有序集合)**

Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。

zset的成员是唯一的,但分数(score)却可以重复。

**实战场景**

- **排行榜**：例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。

## 缓存模式

## jvm垃圾回收

### 判断一个对象是否可被回收

#### 引用计数算法

给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。

两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。

正因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。

#### 可达性分析算法

通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。

![image](https://www.pdai.tech/_images/pics/0635cbe8.png)

Java 虚拟机使用该算法来判断对象是否可被回收，在 Java 中 GC Roots 一般包含以下内容:

- 虚拟机栈中引用的对象
- 本地方法栈中引用的对象
- 方法区中类静态属性引用的对象
- 方法区中的常量引用的对象

### 引用类型（强软弱虚）

无论是通过引用计算算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。

Java 具有四种强度不同的引用类型。

#### 强引用

被强引用关联的对象不会被回收。

使用 new 一个新对象的方式来创建强引用。

```java
Object obj = new Object();
```

#### 软引用

被软引用关联的对象只有在内存不够的情况下才会被回收。

使用 SoftReference 类来创建软引用。

```java
Object obj = new Object();
SoftReference<Object> sf = new SoftReference<Object>(obj);
obj = null;  // 使对象只被软引用关联
```

#### 弱引用

被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。

使用 WeakReference 类来实现弱引用。

```java
Object obj = new Object();
WeakReference<Object> wf = new WeakReference<Object>(obj);
obj = null;
```

#### 虚引用

又称为幽灵引用或者幻影引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。

为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。

使用 PhantomReference 来实现虚引用。

```java
Object obj = new Object();
PhantomReference<Object> pf = new PhantomReference<Object>(obj);
obj = null; 
```

### jvm垃圾回收算法

#### 标记-清除算法

![image](https://www.pdai.tech/_images/pics/a4248c4b-6c1d-4fb8-a557-86da92d3a294.jpg)

将存活的对象进行标记，然后清理掉未被标记的对象。

不足:

- 标记和清除过程效率都不高；
- 会产生大量不连续的内存碎片，导致无法给大对象分配内存。

#### 标记-整理

![image](https://www.pdai.tech/_images/pics/902b83ab-8054-4bd2-898f-9a4a0fe52830.jpg)

让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。

#### 复制算法

 ![image](https://www.pdai.tech/_images/pics/e6b733ad-606d-4028-b3e8-83c3a73a3797.jpg) 

将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。

主要不足是只使用了内存的一半。

现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将新生代划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。

HotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。

### 垃圾回收器![经典垃圾收集器之间的关系](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220322163019.png)

#### Parallel scavenge

　　ps收集器是一个新生代收集器，与Parnew一样，是多线程的垃圾收集器，也是采用复制算法

　看起来与Parnew没什么不同，但其实他有自己的特点，他主要为能控制吞吐量而开发的一款收集器

　　吞吐量，就是CPU运行用户代码的时间与CPU运行总时间的比值，即吞吐量=运行用户代码时间／（运行用户代码时间+垃圾回收时间）

　　ps收集器的两个关键参数：MaxGCPauseMillis和GCTimeRatio

​		**MaxGCPauseMillis**：用于控制收集器最大垃圾回收时间

　　**GCTimeRatio**：用于控制吞吐量，即最大gc时间占比，例如设置参数为19，则gc时间占比为 1/（19+1），结果为5%。

#### CMS 收集器

CMS收集器是一种**以获取最短回收停顿时间**为目标的收集器。它非常符合在注重用户体验的应用上使用。

**CMS（Concurrent Mark Sweep）收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。**

从名字中的**Mark Sweep**这两个词可以看出，CMS 收集器是一种 **“标记-清除”**算法实现的，它的运作过程相比于前面几种垃圾收集器来说更加复杂一些。整个过程分为四个步骤：

- **初始标记：** 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
- **并发标记：** 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
- **重新标记：** 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
- **并发清除：** 开启用户线程，同时 GC 线程开始对为标记的区域做清扫。

![CMS 垃圾收集器 ](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-8-27/82825079.jpg)

从它的名字就可以看出它是一款优秀的垃圾收集器，主要优点：**并发收集、低停顿**。但是它有下面三个明显的缺点：

- **对 CPU 资源敏感；**
- **无法处理浮动垃圾；**
- **它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。**

#### G1 收集器

**G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.**

被视为 JDK1.7 中 HotSpot 虚拟机的一个重要进化特征。它具备一下特点：

- **并行与并发**：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
- **分代收集**：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
- **空间整合**：与 CMS 的“标记--清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。
- **可预测的停顿**：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。


G1 收集器的运作大致分为以下几个步骤：

- **初始标记**
- **并发标记**
- **最终标记**
- **筛选回收**

**G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region(这也就是它的名字 Garbage-First 的由来)**。这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限时间内可以尽可能高的收集效率（把内存化整为零）。

#### CMS和G1区别

区别一： 使用范围不一样
    CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用

    G1收集器收集范围是老年代和新生代。不需要结合其他收集器使用

区别二： STW（stop-the-world）的时间
CMS收集器以最小的停顿时间为目标的收集器。

G1收集器可预测垃圾回收的停顿时间（建立可预测的停顿时间模型）

区别三： 垃圾碎片
CMS收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片

G1收集器使用的是“标记-整理”算法，进行了空间整合，降低了内存空间碎片。

区别四： 垃圾回收的过程不一样
CMS收集器                      G1收集器

1. 初始标记                   1.初始标记
2. 并发标记                   2. 并发标记
3. 重新标记                   3. 最终标记
4. 并发清除                   4. 筛选回收

#### 常用垃圾收集器比较

![](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/11e9dcd0f1ee4f25836e6f1c47104c51-new-image69e1c56a-1d40-493a-9901-6efc647a01f3.png)

### 内存分配和回收策略——新生代如何进入老年代

**新生代GC（Minor GC）**

指发生在新生代的垃圾收集动作，因为Java对象大多都具备朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也比较快。

**老年代GC（Major GC/Full GC）**

指发生在老年代的GC，出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。 Major GC的速度一般会比Minor GC慢10倍以上。

**对象优先在Eden分配**

大多数情况下，对象在新生代Eden区中分配，当Eden区没有足够空间进行分配时，虚拟机将发起一次Minor GC。

**大对象直接进入年老代**

大对象即需要大量连续内存空间的Java对象，如长字符串及数组。经常出现大对象导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来安置他们。
虚拟机提供了一个-XX：PretenureSizeThreshold参数，令大于这个设置值的对象直接在老年代分配。 这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存复制（新生代采用复制算法收集内存）。

**长期存活的对象将进入年老代**

虚拟机给每个对象定义了一个对象年龄计数器，在对象在Eden创建并经过第一次Minor GC后仍然存活，并能被Suivivor容纳的话，将会被移动到Survivor空间，并对象年龄设置为1。每经历过Minor GC，年龄就增加1岁，当到一定程度（默认15岁，可以通过参数-XXMaxTenuringThreshold设置），就将会晋升年老代。

**动态对象年龄判定**

为了更好地适应不同程序内存状况，虚拟机并不硬性要求对象年龄达到MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入年老代。

**空间分配担保**

在发生Minor GC之前，虚拟机会先检查年老代最大可用的连续空间是否大于新生代所有对象的总空间，如果条件成立，那么Minor GC可以确保是安全的。

如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。

如果允许，那么会继续检查年老代最大可用连续空间是否大于历次晋升到年老代对象的平均大小，如果大于，将尝试进行一次Minor GC,尽管这次Minor GC是有风险的。

如果小于，或者HandlePromotionFailure设置不允许冒险，那这时候改为进行一次Full GC。

下面解释一下“冒险”是冒了什么风险，新生代使用复制收集算法，但为了内存利用率，只使用其中一个Survivor空间来作为轮换备份，因此当出现大量对象在MinorGC后仍然存活的情况（最极端的情况就是内存回收后新生代中所有对象都存活），就需要老年代进行分配担保，把Survivor无法容纳的对象直接进入老年代。

与生活中的贷款担保类似，老年代要进行这样的担保，前提是老年代本身还有容纳这些对象的剩余空间，一共有多少对象会活下来在实际完成内存回收之前是无法明确知道的，所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值，与老年代的剩余空间进行比较，决定是否进行Full GC来让老年代腾出更多空间。

取平均值进行比较其实仍然是一种动态概率的手段，也就是说，如果某次Minor GC存活后的对象突增，远远高于平均值的话，依然会导致担保失败（Handle Promotion Failure）。

如果出现了HandlePromotionFailure失败，那就只好在失败后重新发起一次Full GC。 虽然担保失败时绕的圈子是最大的，但大部分情况下都还是会将HandlePromotionFailure开关打开，避免Full GC过于频繁。



### Tomcat源码

我了解过tomcat的实现原理，我给你讲一下tomcat 吧。在学tomcat之前，我只是知道怎么用它的。我第一次学的时候是学的 servlet+tomcat 的使用，当我对他使用的很熟练的时候，我开始想他们的实现原理是什么，**思考为什么servlet 项目要配合 tomcat 使用、servlet项目里为什么加了注解，它怎么和前端交互，doGet和doPost都是void 方法，为什么能给前端回信息，**这些都驱使着我去读源码理解它。**所以我开始找servlet的主方法，因为我想的是任何程序要启动都要有它的主方法，遗憾的是我在 servlet 项目里没有找到主方法。**当时我感觉很震惊，一个程序没有主方法是怎么启动的。这时候我突然想到了，**它是结合tomcat使用的，我猜想他部署在tomcat里面是不是和tomcat 合成了一个项目。如果能合成一个项目，这就说明tomcat也是一个java写的项目。**之前虽然熟练使用，但是没注意过tomcat是不是java写的，所以我赶紧去确认了一下，果然发现 tomcat 就是完全由java写的。所以我就认为了它确实是tomcat 和servlet 最终合成了一个项目。
为了验证我的想法，我去找 tomcat 的主方法，**那么 tomcat的主方法在哪呢？**因为之前学过 shell 脚本，所以我去找它的启动脚本，看他执行的是哪个 jar包，发现启动脚本最终导入的是catalina.sh ，我又去catalina.sh里面找 jar包，找到了bootstrap.jar，然后我用反编译工具 gui 进行反编译，**果然发现了他的主方法。**然后我开始从主方法研究它的运行原理，这是我第一次研究源码，我花了一个多月，后期我又研究了springMVC 的源码，比第一次快多了。

头一次研究源码让我进步非常大，是跨越式的进步。我通过梳理整个源码之后把tomcat分成了两个阶段，分别是启动阶段和接收转发阶段。

**启动阶段**
首先我从启动阶段开始介绍，我发现在**启动阶段，他会扫描webapp目录下的所有子目录和子文件，然后把这个目录下的 .class 文件挑选出来，拿到每个java类的类路径，拿到类路径之后我发现他用到了一个class.forName()方法去获取 Class 类信息，**当时我并不清楚这段代码是什么意思，我去查了资料才发现这个环节叫反射。从网上查资料的时候没太理解反射，往后面读了以后才发现反射是框架里的重要环节。**它在拿到所有的java类Class类信息之后会 for循环遍历每一个Class类信息，然后从Class类信息里去获取注解信息，拿到注解信息之后看哪些java的类信息里面有@WebServlet注解，**把这些java文件挑选出来，**挑选出来之后，发现有 newInstance() 步骤，**读到这我就不懂了，我又去网上搜newInstance是什么意思，然后发现可以通过newInstance() 生成类的实例，它代替了new操作，**为什么这些环节没办法使用直接new的方式而是要用newInstance() 呢，使用 new 的前提是要知道类的名字和它的包路径，很可惜tomcat的开发者事先不知道使用者创建的 servlet 叫什么名字以及所在包是什么，所以 new是不能使用的，才有了newInstance()  的方式生成实例。**读到了这我隐隐约约感觉到好像所有的框架都可能有这一层。**生成servlet实例的时候，又进一步通过方法的实例拿到了它里面的 method实例，method实例里面挑选出 doGet 和 doPost实例**，同时上面也**拿到了注解里的路径值，然后把它们放到了 hashMap 中，其中 key	值就是注解里的路径，value值就是对象实例信息。**除了method实例，servlet实例也存在hashMap中，method实例和servlet实例对应的key值都是注解的路径。



**请求转发阶段**
接下来介绍请求分发部分。**tomcat负责接收来自网络的请求，tomcat 是通过socket监听端口**，我读源码的时候发现 这里的socket 和之前学的不一样，后来发现这里引用的是netty框架中的socket （我把netty框架列入了学习计划中，打算在未来半年把netty看完）。**当tomcat 借助socket拿到http请求后并不是立即开启线程处理的，而是把它放入线程池中，**也从这我首次接触到了线程池，为了攻克这一环节我又钻研了线程池，把线程池的作用和原理都看了一遍，
**在这为什么使用线程池呢？**主要有以下几个原因：
1、**如果没有线程池，而是每个请求来了之后立刻开启线程对请求进行处理，如果一瞬间来上千个请求的话，会瞬间开启很多线程把内存完全消耗，导致服务器死机。**线程池在过多请求来的时候会把请求打到队列中，而不是立刻开启线程执行。根据线程池原理，如果队列满了还可以执行饱和策略，过多的请求不在处理，不会导致服务器宕机。
2、**如果没有线程池，每个请求来了都要新建线程，线程执行完毕后销毁。随着请求的不断到来，会不断的有线程的新建和销毁，线程的新建和销毁都是有巨大的开销的，这种开销是毫秒级的。**说道线程的新建和销毁，我又看了一下线程的新建和销毁过程，当我看过程的时候，我去查找了很多资料发现 java线程的创建和销毁都是调用的本地方法，所以我又研究了操作系统的内核，去图书馆看了linux内核源码，通过查看linux内核源码我发现原来 **线程的创建和销毁实际上实在它的栈区域申请了一个数组类型的栈结构，每个方法的执行实际上是一个个栈帧入栈的过程，方法的执行完毕是出栈的过程。**线程的创建和申请伴随着栈空间的申请和回收，而它的回收并不是立刻回收的而是批量回收的，**它的回收频率和回收次数是由java控制的。因为立刻回收会占用大量 CPU资源，会影响其他线程性能。如果不立即回收就得每隔一段时间回收，意味着回收前会堆积大量线程栈垃圾，**尤其在高并发场景下垃圾会更多。这种垃圾会占用大量内存，进而影响到整体性能。所以我们应该尽可能避免线程的新建和销毁，所以我们就考虑如何在已申请的栈空间上进行资源重复利用，线程池能让线程不会被销毁，通过读源码发现线程池里的线程 run()方法里是有死循环的，它会循环从队列里获取任务，所以线程池可以重复利用线程，大幅提升了多线程性能。
**接下来我钻研了每个线程做的工作，首先把通过端口传过来的 http字符信息封装成 httpRequest 对象和 httpResponce对象，同时提取出请求的 URL ，把URL中的 ip、端口、项目名字去掉剩下的就是要请求的servlet地址或前端地址。**如果请求的是**前端资源**那么会根据**请求路径去相应的目录下找前端文件**，之后按照相应的编码读取里面的字符串返回给前端；**如果请求的是servlet** 那么会**根据URL去之前启动阶段的 hashMap里匹配 servlet实例和 method对象，提取出来之后执行代理**，我一开始看到代理的代码时很陌生，并不理解代理是什么东西，然后我通过网上查询和书籍阅读以及请教学长的方式学习代理，之后发现java的代理有两种模式，**一是 jdk的动态代理，还有静态代理，**在学习过程中我逐渐了解到代理是用来干什么的。因为在有些情况下我们不能直接通过new对象调用方法，所以就需要有一种技术解决这种情况，我通过查询资料发现代理正好可以解决这种问题。**我通过new对象调用方法的方式猜测出代理和这种方式有异曲同工之妙，一般调用方法的时候我们知道是哪个对象调用哪个方法和方法的参数，正好对应上了 invoke() 方法的三个参数**，tomcat通过invoke()方法完成了 servlet的调用。doGet() 和doPost() 方法都是void方法没有返回值，是通过invoke()拿到返回结果然后返回给tomcat的



### SpringMVC源码

启动流程：
**当tomcat启动之后，tomcat会自动读取web.xml配置文件（约定）。首先读取DispatcherServlet，**还有其他配置文件的路径。

**DispatcherServlet的作用**：使用springMVC时，**java和前端对接的是Controller，而tomcat并不识别Controller，无法和前端沟通，所以需要一个中介。**tomcat是支持访问servlet的，所以中介就是DispatcherServlet。**由于dispatcherServlet和controller都是第三方开发人员编写的，所以dispatcherServlet里的doGet和doPost里写上controller的相关java代码。**在web.xml里配置，目的是把所以请求打到dispatcherServlet上。交给servlet负责分发。

**读取其他配置文件目的：**是把其他配置文件合到web.xml里来。读取配置文件的方式是java的DOM方法。在配置文件中有些是javaEE自带的，有些是第三方标签。**自带的标签tomcat可以直接识别，而第三方的标签是用spring的jar包去识别。**配置文件里有spring的j启动类的包路径。当tomcat读到包路径的时候，包的路径是按约定在web.xml中注册的。tomcat在启动过程中，会用DOM操作读取这些标签，看有哪些路径。按约定，凡是在这个标签里的路径都会提取出来进行反射。反射拿到类信息之后再通过newInstance拿到类实例。再通过代理的方式对他们进行执行。执行主方法引起一连串的执行。

**在springMVC的启动类中会执行以下操作：**读取web.xml文件，用DOM操作读取自定义标签。其中自定义标签里有controller的扫描范围。**当读取扫描范围之后，springMVC去包下面扫描所有文件**。把.class文件全挑出来，**根据路径进行反射。获取每个类的class类信息，挑选出带有controller注解的类的类信息。再把类里带有requestMapping注解的方法挑出来，把类上的requestMapping注解的value值和方法上requestMapping注解的value值拼成一个url，通过newInstance获取类实例，**同时也获取方法实例，然后以url为key，以方法实例做value存入hashmap。

**请求流程：**
**tomcat接收到请求后，没办法把请求塞给controller的，所以会把请求发给Dispatcherservlet**（参照tomcat原理），接收的还是httprequest。**dispatcherServlet会从请求中提取url，根据提取的url去hashmap中进行匹配，匹配成功，拿出实例，进行代理去执行相应的Method方法。**
controller方法的入参可以是对象类型，httprequest参数如何转化成对象？借助的是java反射。将参数对象进行反射，跟请求参数进行匹配，key一样就把请求参数value赋值给对象的域的值。

# Java基础

### 关于八大基本类型

**类型的转换**

![img](https://img-blog.csdnimg.cn/20190314165054201.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N1eHVlX2phdmE=,size_16,color_FFFFFF,t_70)  

**转换规则**：从存储范围大的类型到存储范围小的类型。

**具体规则为**：double→float→long→int→short(char)→byte

### java数组中最多可以放多少个元素？

java数组用int做引索，最大容量2G=2 147 483 639=2^31^个元素空间。
同时受“可用内存空间”的大小限制。
java每个对象元素实际占用内存都大于12字节，即使你有16GB内存，也不够2G个对象。

### String，StringBuffer，StringBuilder

![image-20210812103536158](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210812103536158.png)

### String为什么要设立成不可变类

1.由于 String 在 Java 中是不可变的，这样 Java Runtime 就可以**节省大量的 Java 堆空间**，因为不同的 String 变量可以在String Pool中引用相同的 String 变量(实际String对象的值)。
2.如果String不是不可变的，那么它**将对应用程序造成严重的安全威胁。** 例如，数据库用户名，密码作为String传递以获取数据库连接.如果String是可变的,黑客可以轻松改变它的引用值以导致应用程序中出现安全问题。
3.由于String是不可变的,所以它在**多线程环境(multithreading)是线程安全的,**一个 String 实例可以在不同的线程中共享。 这避免了使用同步(synchronization)来保护线程安全,String是隐式线程安全的.
4.String被用在了classloader 类加载器中，**不可变性提供了正确的类由Classloader加载的安全性。** 例如，假设您尝试加载java.sql.Connection类的实例，但引用的值更改为myhacked.Connection类，可以对数据库执行有害的操作。
5.由于 String 是不可变的，它的 hashcode 在创建时就被缓存了，它不需要再次计算,并且它的**处理速度**比其他 Object对象要快。这也是为什么 HashMap 常用 String 对象作 key的原因

### 字符串为什么是不可变的，以及不可变的好处

- 类本身是final修饰的
- 数组也是final修饰的，private修饰的
- 整个类没有提供任何一个修改数组内容，以及返回数组引用的方法

### Java创建对象的几种方式

- 调用构造函数

  - 使用new关键字

  - 使用Class类的newInstance方法（无参，反射）

    ```java
    Employee emp2 = (Employee)Class.forName("org.programming.mitra.exercises.Employee").newInstance();
    
    或者Employee emp2 = Employee.class.newInstance();
    ```

    

  - 使用Constructor类的newInstance方法(有参无参均可，反射)

    ```java
    Constructor constructor = Employee.class.getConstructor();
    
    Employee emp3 = constructor.newInstance();
    ```

    

- 不调用构造函数

  - 使用clone方法
  - 使用反序列化：当我们序列化和反序列化一个对象时，jvm会给我们创建一个单独的对象。为了反序列化一个对象，我们需要让我们的类实现Serializable接口

- 除了第1个方法，其他4个方法全都转变为invokevirtual(创建对象的直接方法)，第一个方法转变为两个调用，new和invokespecial(构造函数调用)。

### JDK和JRE

JDK拥有JRE所拥有的一切，还有编译器(javac) 和工具(如javadoc和jdb)。它能够创建和编译程序。
JRE是Java运行时环境。它是运行已编译Java程序所需的所有内容的集合，包括Java虚拟机(JVM)，Java 类库，java命令和其他的一些基础构件。但是，它不能用于创建新程序。

### Java泛型了解么？什么是类型擦除？介绍⼀下常用的通配符

Java泛型(generics) 是JDK5中引入的一个新特性，泛型提供了编译时类型安全检测机制，该机制允许程序员在编译时检测到非法的类型。泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。
Java的泛型是伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉，这也就是通常所说类型擦除。

### ==和equals区别

==：它的作用是判断两个对象的地址是不是相等。即判断两个对象是不是同一个对象。
(基本数据类型比较的是值，引用数据类型比较的是内存地址)

equals()：它的作用也是判断两个对象是否相等，它不能用于比较基本数据类型的变量。equals()方法存在于0bject类中，而0bject类是所有类的直接或间接父类。

### Object常见方法

>  如图可知，Object类有12个成员方法，按照用途可以分为以下几种 
>  1，构造函数 
>  2，hashCode和equale函数用来判断对象是否相同, 
>  3，wait(),wait(long),wait(long,int),notify(),notifyAll() 
>  4，toString()和getClass, 
>  5，clone() 
>  6，finalize()用于在垃圾回收 

### HashCode()和equals()

#### HashCode()介绍

hashCode()的作用是获取哈希码，也称为散列码；它实际上是返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。hashCode()定义在JDK的0bject类中，这就意味着Java中的任何类都包含有hashCode()函数。另外需要注意的是:
0bject的hashcode方法是本地方法，也就是用C语言或C++实现的，该方法通常用来将对象的内存地址转换为整数之后返回。

#### 为什么重写equals()要重写hashcode()

对于对象集合的判重，如果一个集合含有100个对象实例，仅仅使用equals()方法的话，那么对于一个对象判重就需要比较4950次，随着集合规模的增大，时间开销是很大的。但是同时使用哈希表的话，就能快速定位到对象的大概存储位置，并且在定位到大概存储位置后，后续比较过程中，如果两个对象的hashCode不相同，也不再需要调用equals（）方法，从而大大减少了equals()比较次数。所以从程序实现原理上来讲的话，既需要equals()方法，也需要hashCode()方法。那么既然重写了equals（），那么也要重写hashCode()方法，以保证两者之间的配合关系。



### 访问修饰符

定义: Java中,可以使用访问修饰符来保护对类、变量、方法和构造方法的访问。Java 支持4种不同的访问权限。

- private:在同一类内可见。使用对象:变量、方法。注意:不能修饰类（外部类）
- default (即缺省,什么也不写,不使用任何关键字）：在同一包内可见,不使用任何修饰符。使用对象:类、接口、变量、方法。
- protected：对同- -包内的类和所有子类可见。使用对象:变量、方法。注意:不能修饰类（外部类）。
- public：对所有类可见。使用对象：类、接口、变量、方法
    ![image-20210804154317989](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210804154317989.png)

### final、finally、finalize

**final关键字主要用在三个地方：变量、方法、类。**

1. 对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。
2. 当用final修饰一个类时，表明这个类不能被继承。final类中的所有成员方法都会被隐式地指定为final方法。
3. 使用final方法的原因有两个。第一个原因是把方法锁定，以防任何继承类修改它的含义；第二个原因是效率。在早期的Java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不到内嵌调用带来的任何性能提升（现在的Java版本已经不需要使用final方法进行这些优化了）。类中所有的private方法都隐式地指定为final。

**fianlly**
finally在异常处理时，提供finally块来执行任何清除操作。如果发生异常，匹配的catch块就会执行，然后进入finally块执行。

**finalize**
finalize是方法名，java.lang.Object里定义的，也就是说每个对象都有这一个方法。
垃圾回收器删除对象之前调用对象的该方法做清理工作。

### Java特性（封装继承多态）

**封装**

封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供方法给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。

**继承**

继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便地复用以前的代码。

**关于继承如下 3 点请记住：**

1. 子类拥有父类对象所有的属性和方法（包括私有属性和私有方法），但是父类中的私有属性和方法子类是无法访问，**只是拥有**。
2. 子类可以拥有自己属性和方法，即子类可以对父类进行扩展。
3. 子类可以用自己的方式实现父类的方法。（以后介绍）。

**多态**

父类对象指向子类对象，

所谓多态就是指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须在由程序运行期间才能决定。

在 Java 中有两种形式可以实现多态：继承（多个子类对同一方法的重写）和接口（实现接口并覆盖接口中同一方法）。

### 重载和重写

- 方法的重载和重写都是实现多态的方式，区别在于前者实现的是编译时的多态性,而后者实现的是运行时的多态性。
- **重载**：发生在同一个类中，**方法名相同参数列表不同**（参数类型不同、个数不同、顺序不同），与方法返回值和访问修饰符无关，即重载的方法不能根据返回类型进行区分
- **重写**：发生在有继承关系的类中，**方法名、参数列表必须相同，返回值小于等于父类，抛出的异常小于等于父类，访问修饰符大于等于父类**（里氏代换原则）；**如果父类方法访问修饰符为private则子类中就不是重写**。
- **构造方法**不能被继承，因此**不能被重写**，但**可以被重载**。

### 深拷贝VS浅拷贝

浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。
深拷贝：对基本数据类型进行值传递，对引用数据类型，创建-一个新的对象，并复制其内容，此为深拷贝。

### 抽象类和接口

![image-20210825123045986](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20210825123047.png)

1. 接口的方法默认是public,所有方法在接口中不能有实现(Java 8开始接口方法可
    以有默认实现) ，而抽象类可以有非抽象的方法。
2. 接口中除了static、final 变量,不能有其他变量，而抽象类中则不一-定。
3. 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过
    extends关键字扩展多个接口。
4. 接口方法默认修饰符是public,抽象方法可以有public、protected 和default这
    些修饰符( 抽象方法就是为了被重写所以不能使用private关键字修饰! )。
5. 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，
    是一种行为的规范。

接口(interface)和抽象类(abstract class)是支持抽象类定义的两种机制。

接口是公开的，不能有私有的方法或变量，接口中的所有方法都`没有方法体`，通过关键字`interface`实现。

抽象类是可以有私有方法或私有变量的，通过把类或者类中的方法声明为`abstract`来表示一个类是抽象类，被声明为抽象的方法`不能包含方法体`。子类实现方法必须含有相同的或者更低的访问级别(public->protected->private)。抽象类的子类为父类中`所有抽象方法`的具体实现，否则也是抽象类。

接口可以被看作是抽象类的变体，接口中所有的方法都是抽象的，可以通过接口来间接的实现`多重继承`。接口中的成员变量都是`static final`类型，由于抽象类可以包含部分方法的实现，所以，在一些场合下`抽象类比接口更有优势`。

**`相同点`：**
（1）都**不能**被实例化
（2）接口的实现类或抽象类的子类都只有**实现了接口或抽象类中的方法后**才能实例化。

**`不同点`：**
（1）接口只有定义，**不能有方法的实现**，`java 1.8中可以定义default方法体`，而抽象类可以有定义与实现，方法可在抽象类中实现。
（2）实现接口的关键字为`implements`，继承抽象类的关键字为`extends`。一个类**可以实现多个接口**，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。
（3）接口强调特定功能的实现，而抽象类强调所属关系。
（4）接口成员变量默认为`public static final`，**必须赋初值**，不能被修改；其所有的成员方法都是`public`、`abstract`的。抽象类中成员变量默认`default`，可在子类中被重新定义，也可被重新赋值；抽象方法被`abstract`修饰，不能被`private`、`static`、`synchronized`和`native`等修饰，**必须以分号结尾**，**不带花括号**。
（5）接口被用于常用的功能，便于日后维护和添加删除，而抽象类更倾向于充当公共类的角色，不适用于日后重新对立面的代码修改。功能需要累积时用抽象类，不需要累积时用接口。



### 消息队列

https://www.jianshu.com/p/ffd0806e0947

## 异常体系

![image-20210808162104720](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210808162104720.png)

- 所有的异常都是由 **Throwable** 继承而来，但在下一层立即分解为两个分支：**Error** 和 **Exception**

- **Error** 类层次结构描述了 **Java** 运行时系统的内部错误和资源耗尽错误。(栈溢出等)

- Exception:一个分支派生于 **RuntimeException** ; 另一个分支包含其他异常。划分两个分支的规则是：由程序错误导致的异常属于 **RuntimeException** ; 而程序本身没有问题， 但由于像 **I**/**O** 错误这类问题导致的异常属于其他异常

-  **RuntimeException** ：（程序问题） 

  错误的类型转换。 

  数组访问越界 

  访问 **null** 指针

- **IOException**： 

  试图在文件尾部后面读取数据。 

  试图打开一个不存在的文件。 

  试图根据给定的字符串查找 **Class** 对象， 而这个字符串表示的类并不存在

- 受查异常：IOException；非受查异常：RuntimeException，error

## 反射和代理

### 反射

**一，反射是什么（反射是框架设计的灵魂）**

1，JAVA反射机制是在***\*运行状态中\****

对于任意一个类，都能够知道这个类的所有属性和方法；

对于任意一个对象，都能够调用它的任意一个方法和属性；

这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。

**2，反射提供的功能：**

- 在运行时判断任意一个对象所属的类
- 在运行时构造任意一个类的对象
- 在运行时判断任意一个类所具有的成员变量和方法
- 在运行时调用任意一个对象的方法

（要想解剖一个类,必须先要获取到该类的字节码文件对象（class）。而解剖使用的就是Class类中的方法.所以先要获取到每一个字节码文件对应的Class类型的对象.）

**1、获得Class：主要有三种方法：**

（1）Object-->getClass

（2）任何数据类型（包括基本的数据类型）都有一个“静态”的class属性

（3）通过class类的静态方法：forName(String className)（最常用），获取到类的信息，通过method.invoke执行方法

三种方式中，常用第三种，第一种对象都有了还要反射干什么，第二种需要导入类包，依赖太强，不导包就抛编译错误。一般都使用第三种，一个字符串可以传入也可以写在配置文件中等多种方法。

 **谈谈反射机制的优缺点**

**优点** ： 可以让咱们的代码更加灵活、为各种框架提供开箱即用的功能提供了便利

**缺点** ：让我们在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。

### 代理

代理模式是一种比较好理解的设计模式。简单来说就是 **我们使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。**

**代理模式的主要作用是扩展目标对象的功能，比如说在目标对象的某个方法执行前后你可以增加一些自定义的操作。**

举个例子来说明代理的作用:假设我们想邀请一位明星,那么并不是直接连接明星,而是联系明星的经纪人,来达到同样的目的.明星就是一个目标对象,他只要负责活动中的节目,而其他琐碎的事情就交给他的代理人(经纪人)来解决.这就是代理思想在现实中的一个例子

**静态代理**

**静态代理中，我们对目标对象的每个方法的增强都是手动完成的，非常不灵活（比如接口一旦新增加方法，目标对象和代理对象都要进行修改）且麻烦(需要对每个目标类都单独写一个代理类\)。** 实际应用场景非常非常少，日常开发几乎看不到使用静态代理的场景。

上面我们是从实现和应用角度来说的静态代理，从 JVM 层面来说， **静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。**

静态代理实现步骤:

1. 定义一个接口及其实现类；
2. 创建一个代理类同样实现这个接口
3. 将目标对象注入进代理类，然后在代理类的对应方法调用目标类中的对应方法。这样的话，我们就可以通过代理类屏蔽对目标对象的访问，并且可以在目标方法执行前后做一些自己想做的事情。

静态代理在使用时，需要定义接口或者父类，被代理对象与代理对象一起实现相同的接口或者是继承相同父类。

**静态代理总结:**

优点：可以做到在符合开闭原则的情况下对目标对象进行功能扩展。

缺点：我们得为每一个服务都得创建代理类，工作量太大，不易管理。同时接口一旦发生改变，代理类也得相应修改。 

如何解决静态代理中的缺点呢?答案是可以使用动态代理方式

**动态代理**

相比于静态代理来说，动态代理更加灵活。我们不需要针对每个目标类都单独创建一个代理类，并且也不需要我们必须实现接口，我们可以直接代理实现类( **CGLIB 动态代理机制**)。

**从 JVM 角度来说，动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。**

说到动态代理，Spring AOP、RPC 框架应该是两个不得不的提的，它们的实现都依赖了动态代理。

**动态代理在我们日常开发中使用的相对较小，但是在框架中的几乎是必用的一门技术。学会了动态代理之后，对于我们理解和学习各种框架的原理也非常有帮助。**

**JDK 动态代理类使用步骤**

1. 定义一个接口及其实现类；
2. 自定义 `InvocationHandler` 并重写`invoke`方法，在 `invoke` 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；
3. 通过 `Proxy.newProxyInstance(ClassLoader loader,Class[] interfaces,InvocationHandler h)` 方法创建代理对象；

**JDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。**

**为了解决这个问题，我们可以用 CGLIB 动态代理机制来避免。**

**CGLIB 动态代理类使用步骤**

1. 定义一个类；
2. 自定义 `MethodInterceptor` 并重写 `intercept` 方法，`intercept` 用于拦截增强被代理类的方法，和 JDK 动态代理中的 `invoke` 方法类似；
3. 通过 `Enhancer` 类的 `create()`创建代理类；

 **JDK 动态代理和 CGLIB 动态代理对比**

1. **JDK 动态代理只能代理实现了接口的类或者直接代理接口，而 CGLIB 可以代理未实现任何接口的类。** 另外， CGLIB 动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final 类型的类和方法。
2. 就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。
3. CGLIB基于继承来实现代理，代理对象实际上是目标对象的子类，它内部通过第三方类库ASM，加载目标对象类的class文件，修改字节码来生成子类，生成类的过程较低效，但生成类以后的执行很高效，可以通过将ASM生成的类进行缓存来解决生成类过程低效的问题；

**静态代理和动态代理的区别**

1. **灵活性** ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！
2. **JVM 层面** ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。

**动态代理有以下特点:**
1.代理对象,不需要实现接口
2.代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)

## 内部类

#### 成员内部类

 成员内部类是最普通的内部类，它的定义为位于另一个类的内部 

```java
class Circle {
	double radius = 0;
  	public Circle(double radius) {
    	this.radius = radius;
    }
    class Draw {     //内部类
		public void drawSahpe() {
        	System.out.println("drawshape");
        }
    }
}
```

#### 局部内部类

局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。 

```java
class People{
	public People() {
    
	}
}
```

```java
class Man{
	public Man(){
    
	}
  
	public People getWoman(){
    	class Woman extends People{  //局部内部类
      	int age =0;
    	}
    return new Woman();
	}
}
```

#### 匿名内部类

匿名内部类应该是平时我们编写代码时用得最多的，在编写事件监听的代码时使用匿名内部类不但方便，而且使代码更加容易维护。 



#### 静态内部类

静态内部类也是定义在另一个类里面的类，只不过在类的前面多了一个关键字static。静态内部类是不需要依赖于外部类的，这点和类的静态成员属性有点类似，并且它不能使用外部类的非static成员变量或者方法，这点很好理解，因为在没有外部类的对象的情况下，可以创建静态内部类的对象，如果允许访问外部类的非static成员就会产生矛盾，因为外部类的非static成员必须依附于具体的对象。 

```java
public` `class` `Test {
  ``public` `static` `void` `main(String[] args) {
    ``Outter.Inner inner = ``new` `Outter.Inner();
  ``}
}
```

```java
class` `Outter {
  ``public` `Outter() {
    
  ``}
  
    static` `class` `Inner {
    ``public` `Inner() {
      
    ``}
  ``}
}
```

为什么在Java中需要内部类？总结一下主要有以下四点：

　　1.每个内部类都能独立的继承一个接口的实现，所以无论外部类是否已经继承了某个(接口的)实现，对于内部类都没有影响。内部类使得多继承的解决方案变得完整，

　　2.方便将存在一定逻辑关系的类组织在一起，又可以对外界隐藏。

　　3.方便编写事件驱动程序

　　4.方便编写线程代码

## I/O通信



### BIO（Blocking I/O）

**同步阻塞I/O模式**，数据的读取写入必须阻塞在一个线程内等待其完成。

采用 **BIO 通信模型** 的服务端，**通常由一个独立的 Acceptor 线程负责监听客户端的连接。我们一般通过在 `while(true)` 循环中服务端会调用 `accept()` 方法等待接收客户端的连接的方式监听请求，**请求一旦接收到一个连接请求，就可以建立通信套接字在这个通信套接字上进行读写操作，此时不能再接收其他客户端连接请求，只能等待同当前连接的客户端的操作执行完成， 不过可以通过多线程来支持多个客户端的连接，如上图所示。

如果要让 **BIO 通信模型 能够同时处理多个客户端请求，就必须使用多线程**（主要原因是 `socket.accept()`、 `socket.read()`、 `socket.write()` 涉及的三个主要函数都是同步阻塞的），也就是说它在接收到客户端连接请求之后为每个客户端创建一个新的线程进行链路处理，处理完成之后，通过输出流返回应答给客户端，线程销毁。这就是典型的 **一请求一应答通信模型** 。



### NIO（New I/O）

NIO是JDK1.4引入的，目的就是为了提高速度

**NIO是一种同步非阻塞的I/O模型**，在Java 1.4 中引入了NIO框架，对应 java.nio 包，提供了 Channel , Selector，Buffer等抽象。

NIO中的N可以理解为Non-blocking，不单纯是New。**它支持面向缓冲的，基于通道的I/O操作方法。** **NIO提供了与传统BIO模型中的 `Socket` 和 `ServerSocket` 相对应的 `SocketChannel` 和 `ServerSocketChannel` 两种不同的套接字通道实现,两种通道都支持阻塞和非阻塞两种模式。**阻塞模式使用就像传统中的支持一样，比较简单，但是性能和可靠性都不好；非阻塞模式正好与之相反。对于低负载、低并发的应用程序，可以使用同步阻塞I/O来提升开发速率和更好的维护性；**对于高负载、高并发的（网络）应用，应使用 NIO 的非阻塞模式来开发。**



IO流是阻塞的，NIO流是不阻塞的。



**IO 面向流(Stream oriented)，而 NIO 面向缓冲区(Buffer oriented)。**

在NIO厍中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的; 在写入数据时，写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。

最常用的缓冲区是 ByteBuffer,一个 ByteBuffer 提供了一组功能用于操作 byte 数组。除了ByteBuffer,还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean类型）都对应有一种缓冲区。

3)**Channel (通道)**

NIO 通过Channel（通道） 进行读写。

通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因为 Buffer，通道可以异步地读写。

4)Selectors(选择器)

**NIO有选择器，而IO没有。**

选择器用于使用单个线程处理多个通道。因此，它需要较少的线程来处理这些通道。线程之间的切换对于操作系统来说是昂贵的。 因此，为了提高系统效率选择器是有用的。

##### **NIO 读数据和写数据方式**

通常来说NIO中的所有IO都是从 Channel（通道） 开始的。

- 从通道进行数据读取 ：创建一个缓冲区，然后请求通道读取数据。
- 从通道进行数据写入 ：创建一个缓冲区，填充数据，并要求通道写入数据。



### AIO (Asynchronous I/O)

AIO 也就是 NIO 2。在 Java 7 中引入了 NIO 的改进版 NIO 2,**它是异步非阻塞的IO模型。异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。**

**AIO 是异步IO的缩写，虽然 NIO 在网络操作中，提供了非阻塞的方法，但是 NIO 的 IO 行为还是同步的。**对于 NIO 来说，我们的业务线程是在 IO 操作准备好时，得到通知，接着就由这个线程自行进行 IO 操作，IO操作本身是同步的。（除了 AIO 其他的 IO 类型都是同步的，这一点可以从底层IO线程模型解释

查阅网上相关资料，我发现就目前来说 AIO 的应用还不是很广泛，Netty 之前也尝试使用过 AIO，不过又放弃了。

# java数据结构

## 树

`数组`的下标寻址十分迅速，但计算机的内存是有限的，故数组的长度也是有限的，实际应用当中的数据往往十分庞大；而且无序数组的查找最坏情况需要遍历整个数组；后来人们提出了二分查找，二分查找要求数组的构造一定有序，二分法查找解决了普通数组查找复杂度过高的问题。任和一种数组无法解决的问题就是插入、删除操作比较复杂，因此，在一个增删查改比较频繁的数据结构中，数组不会被优先考虑

`普通链表`由于它的结构特点被证明根本不适合进行查找

`哈希表`是数组和链表的折中，同时它的设计依赖散列函数的设计，数组不能无限长、链表也不适合查找，所以也适合大规模的查找

`二叉查找树`因为可能退化成链表，同样不适合进行查找

`AVL树`是为了解决可能退化成链表问题，但是AVL树的旋转过程非常麻烦，因此插入和删除很慢，也就是构建AVL树比较麻烦

`红黑树`是平衡二叉树和AVL树的折中，因此是比较合适的。集合类中的Map、关联数组具有较高的查询效率，它们的底层实现就是红黑树。

`多路查找树` 是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的(如果元素数量非常多的话，查找就退化成节点内部的线性查找了)，这样导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下。

`B树`与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。它的应用是文件系统及部分非关系型数据库索引。

`B+树`在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。通常用于关系型数据库(如Mysql)和操作系统的文件系统中。

`B*树`是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针, 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3。

### 二叉树、完全二叉树、满二叉树

- 二叉树: 最多有两棵子树的树被称为二叉树
- 完全二叉树: 如果一个二叉树与满二叉树前m个节点的结构相同，这样的二叉树被称为完全二叉树
- 满二叉树: 二叉树中所有非叶子结点的度都是2，且叶子结点都在同一层次上

### 红黑树

红黑树是一棵二叉搜索树，它在每个节点增加了一个存储位记录节点的颜色，可以是红色,也可以是黑色；通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡。

**红黑树的特性**:
**（1）每个节点或者是黑色，或者是红色。**
**（2）根节点是黑色。**
**（3）如果一个节点是红色，那么它的两个子节点就是黑色的(没有连续的红节点)**
**（4）对于每个节点，从该节点到其后代叶节点的简单路径上，均包含相同数目的黑色节点。**                                      
**（5)   每个页节点都是黑的                                                                                                                                          **
**（6）所有左节点都<=父节点，所有右节点都>父节点**



### 红黑树和自平衡二叉(查找)树区别

>   1、红黑树放弃了追求完全平衡，追求大致平衡，在与平衡二叉树的时间复杂度相差不大的情况下，保证每次插入最多只需要三次旋转就能达到平衡，实现起来也更为简单。
>   2、平衡二叉树追求绝对平衡，条件比较苛刻，实现起来比较麻烦，每次插入新节点之后需要旋转的次数不能预知。
>
>   AVL树是最早出现的自平衡二叉(查找)树
>   红黑树和AVL树类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能。
>   红黑树和AVL树的区别在于它使用颜色来标识结点的高度，它所追求的是局部平衡而不是AVL树中的非常严格的平衡。
>
>   红黑树是牺牲了严格的高度平衡的优越条件为代价红黑树能够以O(log2 n)的时间复杂度进行搜索、插入、删除操作。
>   此外，由于它的设计，任何不平衡都会在三次旋转之内解决。
>   当然，还有一些更好的，但实现起来更复杂的数据结构能够做到一步旋转之内达到平衡，但红黑树能够给我们一个比较“便宜”的解决方案。
>   红黑树的算法时间复杂度和AVL相同，但统计性能比AVL树更高.

### 红黑树与B树的区别

> (B-树，即为B树。因为B树的原英文名称为B-tree，而国内很多人喜欢把B-tree译作B-树，其实，这是个非常不好的直译，很容易让人产生误解。如人们可能会以为B-树是一种树，而B树又是一种一种树。而事实上是，**B-tree就是指的B树**。特此说明。)
>
>
> B树又叫平衡多路查找树。B树是为了磁盘或其它存储设备而设计的一种多叉（下面你会看到，相对于二叉，B树每个内结点有多个分支，即多叉）平衡查找树。与红黑树很相似，但在降低磁盘I/0操作方面要更好一些。 许多数据库系统都一般使用B树或者B树的各种变形结构，如下文即将要介绍的B+树，B*树来存储信息。
>
> 红黑树与B树的区别在于，B树的结点可以有许多子女，从几个到几千个。那为什么又说B树与红黑树很相似呢?因为与红黑树一样，一棵含n个结点的 B树的高度也为O（lgn） ，但可能比一棵红黑树的高度小许多，应为它的分支因子比较大。所以， B树可以在O（logn）时间内，实现各种如插入（insert），删除（delete）等动态集合操作

### B树、B+树

#### B树

B树(英语: B-tree)是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一种自平衡的m阶树，与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。

- 根结点至少有两个子女。
- 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 <= k <= m
- 每一个叶子节点都包含k-1个元素，其中 m/2 <= k <= m
- 所有的叶子结点都位于同一层。
- 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。

B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree:

![img](/_images/alg/alg-tree-15.png)

#### B+树

B+ 树是一种树数据结构，通常用于关系型数据库(如Mysql)和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反。

在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。

b+树的非叶子节点不保存数据，只保存子树的临界值(最大或者最小)，所以同样大小的节点，b+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少。

将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示:

![img](/_images/alg/alg-tree-16.png)

#### B树、B+树

B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。

B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。

在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。

#### 操作

进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。

插入删除操作记录会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。

####  b+树相比b树的优点 

1. b+树的非叶节点不保存数据，所以可以存储更多节点元素
2. b+树的查找路径是由根到叶子节点，每次查找路径长度比较稳定 
3. 范围遍历，b+树的叶子节点构成一条链表，访问更加方便  

### 跳表

跳表全称为跳跃列表，它允许快速查询，插入和删除一个有序连续元素的数据链表。跳跃列表的平均查找和插入时间复杂度都是O(logn)。快速查询是通过维护一个多层次的链表，且每一层链表中的元素是前一层链表元素的子集（见右边的示意图）。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。

### 堆和树的区别

**节点的顺序**
在二叉搜索树中，左子节点必须比父节点小，右子节点必须必比父节点大。但是在堆中并非如此。在最大堆中两个子节点都必须比父节点小，而在最小堆中，它们都必须比父节点大。

**内存占用**
普通树占用的内存空间比它们存储的数据要多。你必须为节点对象以及左/右子节点指针分配额外内存。堆仅仅使用一个数据来存储数组，且不使用指针。

**平衡**
二叉搜索树必须是“平衡”的情况下，其大部分操作的复杂度才能达到O(log n)。你可以按任意顺序位置插入/删除数据，或者使用 AVL 树或者红黑树，但是在堆中实际上不需要整棵树都是有序的。我们只需要满足对属性即可，所以在堆中平衡不是问题。因为堆中数据的组织方式可以保证O(log n) 的性能。

**搜索**
在二叉树中搜索会很快，但是在堆中搜索会很慢。在堆中搜索不是第一优先级，因为使用堆的目的是将最大（或者最小）的节点放在最前面，从而快速的进行相关插入、删除操作。

## Java集合

![image-20210807165411338](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210807165411338.png)

#### Collections与Collection

##### java.util.Collection

- Collection是一个集合框架的父接口。它提供了对集合对象进行基本操作的通用接口方法。Collection接口在Java 类库中有很多具体的实现。Collection接口的意义是为各种具体的集合提供了最大化的统一操作方式。

- Collection接口的继承树，i 代表接口，c 代表实现类

  ![image-20210807164734396](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210807164734396.png)

- Collection接口是Set、List和Queue接口的父接口，Collection通常情况下不被直接使用。
  因此Collection 接口定义了一些通用的方法，List 接口和 Set 接口继承自 Collection 接口，所以也可以调用这些方法。

  ![image-20210807164643177](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210807164643177.png)

##### java.util.Collections

- Collections 是一个包装类。它包含有各种有关集合操作的静态多态方法。此类不能实例化，就像一个工具类，服务于Java的Collection框架。他提供一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作
- ![image-20210807164911578](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210807164911578.png)

#### ArrayList与LinkList

1. ArrayList和LinkedList可想从名字分析，它们一个是Array(动态数组)的数据结构，一个是Link(链表)的数据结构，此外，它们两个都是对List接口的实现。前者是数组队列，相当于动态数组；后者为双向链表结构，也可当作堆栈、队列、双端队列
2. 当随机访问List时（get和set操作），ArrayList比LinkedList的效率更高，因为LinkedList是线性的数据存储方式，所以需要移动指针从前往后依次查找。
3. 当对数据进行增加和删除的操作时(add和remove操作)，LinkedList比ArrayList的效率更高，因为ArrayList是数组，所以在其中进行增删操作时，会对操作点之后所有数据的下标索引造成影响，需要进行数据的移动。
4. 从利用效率来看，ArrayList自由性较低，因为它需要手动的设置固定大小的容量，但是它的使用比较方便，只需要创建，然后添加数据，通过调用下标进行使用；而LinkedList自由性较高，能够动态的随数据量的变化而变化，但是它不便于使用。
5. ArrayList主要控件开销在于需要在lList列表预留一定空间；而LinkList主要控件开销在于需要存储结点信息以及结点指针信息。
6. ArrayList初始大小10，扩容0.5倍+1；LinkList无扩容

#### List和数组相互转换

```java
/**
*array->list
**/
//第一种
String[] arrays = new String[]{"a", "b", "c"};
List<String> listStrings = Stream.of(arrays).collector(Collectors.toList());
//第二种
String[] arrays = new String[]{"a", "b", "c"};
List<String> listStrings = Arrays.asList(arrays);

/**
*list->array
**/
String[] ss = listStrings.stream().toArray(String[]::new);
String[] sss = listStrings.toArray(new String[listStrings.size()]);
```

#### 数组和链表

- 数组：
  - ==优点：==查找快O(1)
  - ==缺点：==头插和头删的效率低，时间复杂度为O(N)
    空间利用率不高
    内存空间要求高，必须有足够的连续的内存空间
    数组空间的大小固定，不能动态拓展
- 链表
  - ==优点：==任意位置插入元素和删除元素的速度快，时间复杂度为O(1)
    内存利用率高，不会浪费内存
    链表的空间大小不固定，可以动态拓展
  - ==缺点：==随机访问效率低，时间复杂度为0(N)

#### list，set，map的区别

**List** (对付顺序的好帮⼿)： 存储的元素是有序的、可重复的。
**Set** (注重独⼀⽆⼆的性质): 存储的元素是⽆序的、不可重复的。
**Map** (⽤ Key 来搜索的专家): 使⽤键值对（kye-value）存储，类似于数学上的函数 y=f(x)，
“x”代表 key， "y"代表 value， Key 是⽆序的、不可重复的， value 是⽆序的、可重复的，每个
键最多映射到⼀个值。

#### 集合框架底层数据结构总结

**List**

**Arraylist** ： Object[] 数组，初始大小为10，线程不安全，扩容0.5倍+1-->16
**Vector** ： Object[] 数组,初始大小为10，线程安全，扩容1倍
**LinkedList** ： 双向链表(JDK1.6 之前为循环链表， JDK1.7 取消了循环)

**Set**

**HashSet** （⽆序，唯⼀） : 基于 HashMap 实现的，底层采⽤ HashMap 来保存元素
**LinkedHashSet** ： LinkedHashSet 是 HashSet 的⼦类，并且其内部是通过
LinkedHashMap 来实现的。有点类似于我们之前说的 LinkedHashMap 其内部是基于
HashMap 实现⼀样，不过还是有⼀点点区别的
**TreeSet** （有序，唯⼀）： 红⿊树(⾃平衡的排序⼆叉树)

**Map**

**HashMap** ：

- JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主
  要为了解决哈希冲突⽽存在的（“拉链法”解决冲突）。

- 初始容量为0，放入第一个数据容量为16，最大容量2^30^,int最高位是符号位，所以不能是31 

- HashMap在jdk1.8之后引入了红黑树的概念，表示若桶中链表元素超过8时，会自动转化成红黑树；若桶中元素小于等于6时，树结构还原成链表形式。

  **原因：**红黑树的平均查找长度是log(n)，长度为8，查找长度为log(8)=3，链表的平均查找长度为n/2，当长度为8时，平均查找长度为8/2=4，这才有转换成树的必要；链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。

  **还有选择6和8的原因是**：中间有个差值7可以防止链表和树之间频繁的转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。

- JDK1.8 以后在解决哈希冲突时有了较⼤的变化，当链表⻓度⼤于阈值（默认为 8）（将链表转换成红⿊树前会判断，如果当前数组的⻓度⼩于 64，那么会选择先进⾏数组扩容，⽽不是转换为红⿊树）时，将链表转化为红⿊树，以减少搜索时间
  **Hashtable** ： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突⽽存在的
  **TreeMap** ： 红⿊树（⾃平衡的排序⼆叉树）  

- **Hashmap的扩容**需要满足两个条件：当前数据存储的数量（即size()）大小必须大于等于阈值；当前加入的数据是否发生了hash冲突。

  因为上面这两个条件，所以存在下面这些情况

  1. 就是hashmap在存值的时候（默认大小为16，负载因子0.75，阈值12），可能达到最后存满16个值的时候，再存入第17个值才会发生扩容现象，因为前16个值，每个值在底层数组中分别占据一个位置，并没有发生hash碰撞。
  2. 当然也有可能存储更多值（超多16个值，最多可以存26个值）都还没有扩容。原理：前11个值全部hash碰撞，存到数组的同一个位置（这时元素个数小于阈值12，不会扩容），后面所有存入的15个值全部分散到数组剩下的15个位置（这时元素个数大于等于阈值，但是每次存入的元素并没有发生hash碰撞，所以不会扩容），前面11+15=26，所以在存入第27个值的时候才同时满足上面两个条件，这时候才会发生扩容现象。

- **Hashmap的插入：**根据我的理解讲一下插入元素的过程，在插入之前会根据将要插入元素的key值通过一个哈希算法计算出一个hash值传入put方法中，

  然后tab代表一个存放链表头结点的数组，首先判断链表是否为空或者长度为0，如果是则进行调用resize()扩容，
  如果不为空或者长度不为0则通过数组长度-1与hash值进行一个位与运算得到一个数组下标，并获取到该下标数组元素的值，
  判断是否为空，即这个p = tab[i = (n - 1) & hash]) == null判断。
  如果为空则创建一个新的链表节点放在此数组上tab[i] = newNode(hash, key, value, null)，
  如果不为空则先判断数组上这个链表元素p的hash值和key的内容是否和传入hash值和key是否相同，否则else if在判断p是否为一个树节点，
  如果是一个树节点则再调用树节点插入方法，否则else循环判断是否存在相同的key和hash值，如果有则覆盖，
  没有则在链表尾部插入新的链表元素(jdk1.8之后是采用尾插法，之前是头插法)，如果链表长度大于8则转为红黑树结构
  ( if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash)😉。
  如果 if (++size > threshold)链表长度大于当前最大容量乘以负载因子时则扩容

  

#### 如何选⽤集合?

主要根据集合的特点来选⽤，⽐如我们需要根据键值获取到元素值时就选⽤ Map 接⼝下的集合，需
要排序时选择 TreeMap ,不需要排序时就选择 HashMap ,需要保证线程安全就选⽤
ConcurrentHashMap 。
当我们只需要存放元素值时，就选择实现 Collection 接⼝的集合，需要保证元素唯⼀时选择实现
Set 接⼝的集合⽐如 TreeSet 或 HashSet ，不需要就选择实现 List 接⼝的⽐如 ArrayList
或 LinkedList ，然后再根据实现这些接⼝的集合的特点来选⽤。  

#### 为什么要使⽤集合？

当我们需要保存⼀组类型相同的数据的时候，我们应该是⽤⼀个容器来保存，这个容器就是数组，但
是，使⽤数组存储对象具有⼀定的弊端， 因为我们在实际开发中，存储的数据的类型是多种多样的，
于是，就出现了“集合”，集合同样也是⽤来存储多个数据的。
数组的缺点是⼀旦声明之后，⻓度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数
据的类型；⽽且，数组存储的数据是有序的、可重复的，特点单⼀。 但是集合提⾼了数据存储的灵活
性， Java 集合不仅可以⽤来存储不同类型不同数量的对象，还可以保存具有映射关系的数据。



### 

**树的概念**

　　树（tree）是一种抽象数据类型（ADT），用来模拟具有树状结构性质的数据集合。它是由n（n>0）个有限**节点**通过连接它们的**边**组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。

**B树**

B 树是一种多路查找树，相比于二叉树来说，B 树更适合于建立存储设备中的文件索引。

从算法时间复杂度上看，因为 B 树节点中的项都是有序存储的，我们在一个节点内寻找数据时，使用二分查找可以使时间复杂度落在 O(log2N) 内，与在二叉树中的查找相同。因此总的来看，B 树相比于二叉树更适用于在存储设备上维护文件索引。

　　另外，B 树是平衡的，其维护平衡性的思路非常典型。对于普通的二叉树，是自上向下生长的，而对于B树，是自下而上生长的。

　　我们的插入操作都只会将新项插入到叶子节点，叶子节点满后进行分裂，并将中间节点向上融合。整颗树高度的增加必然是由根节点的分裂带来的，而根节点的分裂不会破坏整颗树的平衡性，因为左右子树的高度均加一。

**B+树**

对于B树的改进，每个节点具有关键字以及孩子指针属性：

非叶子结点的子树指针与关键字个数相同；

非叶子结点的子树指针P[i]，指向关键字值属于**[K[i], K[i+1])**的子树（B-树是开区间）；

为所有叶子结点增加一个链指针；

所有关键字都在叶子结点出现；

所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的；不可能在非叶子结点命中；非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；更适合文件索引系统；

**B*树（B乘数）**

B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针；

B*树定义非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3（代替B+树的1/2）；

B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针；

B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针；B*树分配新结点的概率比B+树要低，空间使用率更高；

**红黑树**

https://www.jianshu.com/p/4cd37000f4e3

红黑树***并不追求“完全平衡“***——它只要求部分地达到平衡要求，降低了对旋转的要求，从而提高了性能。

红黑树能够以**O(\*log2\* n)** 的时间复杂度进行搜索、插入、删除操作。此外，由于它的设计，任何不平衡都会在三次旋转之内解决。

红黑树是特殊的二叉查找树，又名R-B树(RED-BLACK-TREE)，由于红黑树是特殊的二叉查找树，即红黑树具有了二叉查找树的特性，而且红黑树还具有以下特性：

- **1.每个节点要么是黑色要么是红色**
- **2.根节点是黑色**
- **3.每个叶子节点是黑色，并且为空节点(还有另外一种说法就是，每个叶子结点都带有两个空的黑色结点（被称为黑哨兵），如果一个结点n的只有一个左孩子，那么n的右孩子是一个黑哨兵；如果结点n只有一个右孩子，那么n的左孩子是一个黑哨兵。)**
- **4.如果一个节点是红色，则它的子节点必须是黑色**
- **5.从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。**







## 各个数据结构的时间复杂度

**动态数组**

对于一个基于Java E[]实现的动态数组Array来说，它的时间复杂度如下：

增：O(n)
删：O(n)
改：已知索引 O(1)；未知索引 O(n)
查：已知索引 O(1)；未知索引 O(n)
resize：通过均摊复杂度分析得 O(1)

**数组队列**

对于一个基于动态数组Array实现的数组队列ArrayQueue来说，它的时间复杂度如下：

void enqueue(E): O(1) 均摊
E dequeue(): O(n)
E front(): O(1)
int getSize(): O(1)
boolean isEmpty(): O(1)

**链表**

增：O(n)
删：O(n)
改：O(n)
查：O(n)
链表不适合修改操作；
如果只对链表头进行增删查操作：O(1)

**集合**

.   			LinkedListSet   BSTreeSet   BSTreeSet最优   BSTreeSet最差
增add   			O(n)  		 O(h)   			O(logn)  			 O(n)
删remove   	O(n)   		O(h)  				 O(logn)  		 O(n)
查contains   	O(n)  		O(h)   				O(logn)   		O(n)
基于搜索树的实现：有序集合
基于哈希表的实现：无序集合

多重集合：集合中的元素可以重复

**映射**

.   			LinkedListMap   BSTreeMap   BSTreeMap最优   BSTreeMap最差
增add  		 O(n)   				O(h)  				 O(logn) 				  O(n)
删remove   	O(n)   			O(h)   				O(logn) 				  O(n)
改set   			O(n)  			 O(h)  				 O(logn)  				 O(n)
查contains   O(n)  				 O(h)  				 O(logn) 				  O(n)
查get  		 O(n)   					O(h)  				 O(logn) 			  O(n)
基于搜索树的实现：有序映射
基于哈希表的实现：无序映射

多重映射：映射中的键可以重复

**哈希表**

链地址法解决哈希冲突时，总共有M个地址，如果放入哈希表的元素为N：
（1）每个地址用链表实现，则时间复杂度：O(N/M)
（2）每个地址用平衡树实现，则时间复杂度：O(log(N/M))

动态空间的哈希表：均摊复杂度是O(1)

**二叉树**

 查找时间复杂度：最好：![O(lgn)](https://math.jianshu.com/math?formula=O(lgn)),最差![O(n)](https://math.jianshu.com/math?formula=O(n))。最差情况是所有的数据全部在一端时。

**二叉搜索树（二叉排序树、二叉查找树）**

 查找时间复杂度：最好：![O(lgn)](https://math.jianshu.com/math?formula=O(lgn)),最差![O(n)](https://math.jianshu.com/math?formula=O(n))。最差情况是所有的数据全部在一端时。

**平衡二叉树**

 查找时间复杂度：![O(lgn)](https://math.jianshu.com/math?formula=O(lgn))

**红黑树**

 查找删除插入时间复杂度：![O(lgn)](https://math.jianshu.com/math?formula=O(lgn))

。商业转载请联系作者获得授权，非商业转载请注明出处。



# Java并发

### 锁的概念

#### lock

从底层角度看常见的锁也就两种：**Synchronized和Lock接口以及ReadWriteLock接口（读写锁）**

从类关系看出Lock接口是jdk5后新添的来实现锁的功能，其实现类：**ReentrantLock（可重入锁）、WriteLock、ReadLock。**

其实还有一个接口**ReadWriteLock，读写锁（读读共享、读写独享、写读独享、写写独享）**。

**Lock接口与synchronized关键字本质上都是实现同步功能。**

区别：

- **ReentrantLock（可重入锁）**：使用上需要显示的获取锁和释放锁，提高可操作性、可中断的获取获取锁以及可超时的获取锁，默认是非公平的但可以实现公平锁，悲观，独享，互斥，可重入，重量级锁。
- **ReentrantReadWriteLock**：默认非公平但可实现公平的，悲观，写独享，读共享，读写，可重入，重量级锁。
- **synchronized**：关键字，隐式的获取锁和释放锁，不具备可中断、可超时，非公平、互斥、悲观、独享、可重入的重量级

**Lock接口简介**

　　Lock锁是一种工具，用来控制对共享资源的访问。

　　Lock锁和Synchronized锁两者各个有各自的使用场景，lock并不是来替换Synchronized锁的。

　　Lock接口最常见的实现类是ReentrantLock

#### Sync和lock

- **存在层次：**syncronized是JAVA关键字，在jvm层面上，**Lock**是一个类
- **锁的释放：**
  - syncronized以获取锁的线程执行完同步代码，释放锁；线程执行发生异常，jvm会让线程释放锁；
  - Lock在finally中必须释放锁，不然容易造成线程死锁
- **锁的获取：**
  - syncronized假设A线程获得锁，B线程等待，如果A线程阻塞，B线程会一直等待
  - Lock分情况而定，Lock有多个锁获取的方式，大致可以尝试获取锁，线程可以不用一直等待
- **锁状态：**synchronized:无法判断**Lock:**可以判断
- **锁类型：**synchronized:可重入，不可中断，非公平**Lock**:可重入 可判断 可公平（两者皆可）
- **性能**synchroized:少量同步**Lock**：大量同步

#### AQS

AQS这个类在java.util.concurrent.locks包下，他是一个用来构建锁和同步器的框架，使用AQS能简单高效地构造出同步器，比如ReentrantLock、Semaphore。

#### AQS队列同步器

**队列同步器（AbstractQueuedSynchronizer）是用来构建锁或者其他同步组件的基础框架**，它使用了 一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源的获取线程的排队工作。

同步器的主要使用方式是继承，子类通过继承同步器并实现他的抽象方法来管理同步状态。

**同步器的设计是基于模板方法模式的**，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法（这些模板方法将会调用使用者重写的方法）。

同步器提供的模板方法基本上分为3类，独占式获取锁与释放同步状态，共享式获取与释放同步状态，查询同步队列中的等待线程情况。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义

———————————————————————————

**队列同步器的实现**

1. **同步队列**	-	同步器依赖内部的同步队列（一个FIFO双向队列），当前线程获取同步状态失败的时候，同步器会将当前线程以及等待状态等信息构造成一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。
2. **独占式同步状态获取与释放** -  通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中中断操作时，线程不会从同步队列中移除。
3. **共享式同步状态获取与释放** - 共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态，如果一个程序在对文件进行读操作，那么这一时刻对于该文件的写操作均被阻塞，而读操作能够同时进行。
4. **独占式超时获取同步状态** - 通过调用同步器的doAcquireNanos（int arg,long nanosTimeout）方法可以超时获取同步状态，即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则返回false，该方法提供了传统java同步操作所不具备的特性



#### 公平锁/非公平锁

​    公平锁指多个线程按照申请锁的顺序来依次获取锁。非公平锁指多个线程获取锁的顺序并不是按照申请锁的顺序来获取，有可能后申请锁的线程比先申请锁的线程优先获取到锁，此极大的可能会造成线程饥饿现象，迟迟获取不到锁。由于**ReentrantLock是通过AQS来实现线程调度，可以实现公平锁**，但是synchroized是非公平的，无法实现公平锁



#### 乐观锁与悲观锁

   不是指什么具体类型的锁，而是指在并发同步的角度。**悲观锁**认为对于共享资源的并发操作，一定是发生修改的，哪怕没有发生修改，也会认为是修改的，因此对于共享资源的操作，悲观锁采取加锁的方式，认为，不加锁的并发操作一定会出现问题。

**乐观锁：**认为对于共享资源的并发操作是不会发生修改的，在更新数据的时候，会采用尝试更新，不断重试的方式更新数据。乐观的认为，不加锁的并发操作共享资源是没问题的。



从上面的描述看除，乐观锁不加锁的并发操作会带来性能上的提升，悲观锁的使用就是利用synchroized关键字或者lock接口的特性。乐观锁在java中的使用，是无锁编程常常采用的是CAS自旋锁，典型的例子就是并发原子类，通过CAS自旋（spinLock）来更新值。

**悲观锁：**总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。再比如Java里面的同步原语synchronized关键字的实现也是悲观锁。



#### 独享锁与共享锁

**独享锁是指该锁一次只能被一个线程所持有。共享锁是指可被多个线程所持有**。在java中，对ReentrantLock对象以及synchroized关键字而言，是独享锁的。但是对于ReadWriteLock接口而言，其读是共享锁，其写操作是独享锁。读锁的共享锁是可保证并发读的效率，读写、写写、写读的过程中都是互斥的，独享的。独享锁与共享锁在Lock的实现中是通过 AQS（抽象队列同步器）来实现的。

#### 互斥锁与读写锁

互斥锁与读写锁就是具体的实现，互斥锁在java 中的体现就是synchronized关键字以及Lock接口实现类ReentrantLock，读写锁在java中的具体实现就是ReentrantReadWriteLock。

一次只有==一个线程==可以占有==写模式==的读写锁, 但是可以有==多个线程==同时占有==读模式==的读写锁. 正是因为这个特性,

当读写锁是==写加锁状态==时, 在这个锁被解锁之前, ==所有试图对这个锁加锁的线程都会被阻塞==.

当读写锁在==读加锁状态==时, 所有试图以读模式对它进行加锁的线程都可以==得到访问权==, 但是如果线程希望以写模式对此锁进行加锁, 它必须直到所有的线程释放锁.

通常, 当读写锁处于读模式锁住状态时, 如果有另外线程试图以写模式加锁, 读写锁通常会阻塞随后的读模式锁请求, 这样可以避免读模式锁长期占用, 而等待的写模式锁请求长期阻塞.

读写锁适合于对数据结构的读次数比写次数多得多的情况. 因为, 读模式锁定时可以共享, 以写模式锁住时意味着独占, 所以读写锁又叫共享-独占锁.

#### 可重入锁

又名递归锁，是指同一个线程在外层的方法获取到了锁，在进入内层方法会自动获取到锁。可重入就是说某个线程已经获得某个锁，可以再次获取锁而不会出现死锁。对于ReentrantLock和synchronized关键字都是可重入锁的。**最大的好处就是能够避免一定程度的死锁。**

ReentrantLock 和 synchronized 不一样，需要手动释放锁，所以使用 ReentrantLock的时候一定要**手动释放锁**，并且**加锁次数和释放次数要一样**。

#### 分段锁

分段锁其实是一种锁的设计，并不是具体的一种锁，**对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作**。我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，**ConcurrentHashMap中的分段锁称为Segment**，它即类似于HashMap（JDK7与JDK8中HashMap的实现）的结构，即**内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)**。

当需要put元素的时候，并不是对整个hashmap进行加锁，而是**先通过hashcode来知道他要放在那一个分段中，然后对这个分段进行加锁**，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。

但是，在统计size的时候，也就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。**分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。**



### CAS

**CAS是乐观锁，相关概念可以去查看乐观锁那里！！**

CAS是英文单词Compare And Swap的缩写，翻译过来就是**比较和交换**

**CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。**

更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。

CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。

CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。

更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。



ABA问题例：比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A,并且线程two进行了一些操作将值变成了B,然后线程two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后线程one操作成功。**尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。**



从思想上来说，**Synchronized属于悲观锁**，悲观地认为程序中的并发情况严重，所以严防死守。CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去尝试更新。



**CAS的缺点：**

1.CPU开销较大
 在并发量比较高的情况下，如果许多线程反复尝试更新某一个变量，却又一直更新不成功，循环往复，会给CPU带来很大的压力。

2.不能保证代码块的原子性
 CAS机制所保证的只是一个变量的原子性操作，而不能保证整个代码块的原子性。比如需要保证3个变量共同进行原子性的更新，就不得不使用Synchronized了。

3.ABA问题

### AQS

**AQS原理**
AQS：AbstractQuenedSynchronizer抽象的队列式同步器。是除了java自带的synchronized关键字之外的锁机制。
AQS的全称为（AbstractQueuedSynchronizer），这个类在java.util.concurrent.locks包

**AQS的核心思想**是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并将共享资源设置为锁定状态，如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。
CLH（Craig，Landin，and Hagersten）队列是一个虚拟的双向队列，虚拟的双向队列即不存在队列实例，仅存在节点之间的关联关系。
**AQS是将每一条请求共享资源的线程封装成一个CLH锁队列的一个结点（Node），来实现锁的分配。**

用大白话来说，AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒。

**注意：AQS是自旋锁：**在等待唤醒的时候，经常会使用自旋（while(!cas())）的方式，不停地尝试获取锁，直到被其他线程获取成功

**实现了AQS的锁有：自旋锁、互斥锁、读锁写锁、条件产量、信号量、栅栏都是AQS的衍生物**



## 多线程

### 为什么需要多线程

CPU、内存、I/O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为:

- CPU 增加了缓存，以均衡与内存的速度差异；// 导致 `可见性`问题
- 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I/O 设备的速度差异；// 导致 `原子性`问题
- 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。// 导致 `有序性`问题

### 并发编程的三个重要特性

1. **原子性** : 一个的操作或者多次操作，要么所有的操作全部都得到执行并且不会收到任何因素的干扰而中断，要么所有的操作都执行，要么都不执行。`synchronized` 可以保证代码片段的原子性。
2. **可见性** ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。`volatile` 关键字可以保证共享变量的可见性。
3. **有序性** ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。`volatile` 关键字可以禁止指令进行重排序优化。

### 并发三要素

可见性、原子性、有序性

#### 可见性: CPU缓存引起

可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到。

举个简单的例子，看下面这段代码：

```java
//线程1执行的代码
int i = 0;
i = 10;
 
//线程2执行的代码
j = i;
```

假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。

此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.

这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。

#### 原子性: 分时复用引起

原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。

经典的**转账问题**：比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元。

试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。

所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。

#### 有序性: 重排序引起

有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码：

```java
int i = 0;              
boolean flag = false;
i = 1;                //语句1  
flag = true;          //语句2
```

上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗? 不一定，为什么呢? 这里可能会发生指令重排序（Instruction Reorder）。

在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：

- ==编译器优化的重排序。==编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
- ==指令级并行的重排序。==现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
- ==内存系统的重排序。==由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：

 ![img](https://www.pdai.tech/_images/jvm/java-jmm-3.png) 

上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。

## 线程基础

### 程序、进程和线程

程序是指令和数据的有序集合, 其本身没有任何运行的含义，是一个静态的概念。
进程则是执行程序的一次执行过程，它是一个动态的概念。是系统资源分配的单位。
通常在一个进程中可以包含若干个线程， 当然一个进程中至少有一个线程,不然没有存在的意义。线程是CPU调度和执行的的单位。

#### 线程和进程的区别

进程是**程序的一次执行**，是系统进行**资源分配和调度的独立单位**，他的作用是是程序能够**并发执行提高资源利用率和吞吐率**。

由于进程是资源分配和调度的基本单位，因为**进程的创建、销毁、切换产生大量的时间和空间的开销，进程的数量不能太多**，而线程是比进程更小的能独立运行的基本单位，他是进程的一个实体，可以减少程序并发执行时的时间和空间开销，使得操作系统具有更好的并发性。

线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈。

1.进程是资源分配的最小单位，线程是程序执行的最小单位。

2.进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率 。

3.CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多，但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

#### 进程间通信方式有：

1. ==管道( pipe )==
    管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. ==有名管道 (namedpipe)==
    有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
3. ==信号量(semophore )==
    信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
4. ==消息队列( messagequeue )==
    消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
5. ==信号 (sinal )==
    信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
6. ==共享内存(shared memory )==
    共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。
7. ==套接字(socket )==
    套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

#### 线程间通信方式有：

- 共享内存
- 消息传递
- socket

### 线程使用（实现）方式

有三种使用线程的方法:

- 实现 Runnable 接口（ 不能返回执行结果 ）；
- 实现 Callable 接口（ 能返回执行结果 ）；
- 继承 Thread 类。
- 使用线程池例（如用Executor框架）

#### Runnable和Callable区别

- 区别1: 两者最大的区别，实现Callable接口的任务线程能返回执行结果，而实现Runnable接口的任务线程不能返回执行结果

注意点：Callable接口支持返回执行结果，此时需要调用FutureTask.get()方法实现，此方法会阻塞线程直到获取“将来”的结果，当不调用此方法时，主线程不会阻塞

- 区别2:Callable接口实现类中run()方法允许将异常向上抛出，也可以直接在内部处理(try...catch); 而Runnable接口实现类中run()方法的异常必须在内部处理掉，不能向上抛出

#### 实现接口 VS 继承 Thread

实现接口会更好一些，因为:

- Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口；
- 类可能只要求可执行就行，继承整个 Thread 类开销过大。

### 线程状态转换（六种）

![Java 线程的状态 ](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/19-1-29/Java%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81.png)

线程创建之后它将处于 **NEW（初始）** 状态，调用 `start()` 方法后开始运行，线程这时候处于 **READY（可运行）** 状态。可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 **RUNNING（运行）** 状态。

当线程执行 `wait()`方法之后，线程进入 **WAITING（等待）**状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而 **TIME_WAITING(超时等待)** 状态相当于在等待状态的基础上增加了超时限制，比如通过 `sleep（long millis）`方法或 `wait（long millis）`方法可以将 Java 线程置于 **TIMED WAITING（超时等待）**状态。当超时时间到达后 Java 线程将会返回到 **RUNNABLE（运行）**状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到 **BLOCKED（阻塞）** 状态。线程在执行 Runnable 的` run() `方法之后将会进入到 **TERMINATED（终止）** 状态。

线程执行 `wait()`方法之后线程进入Waiting状态，由于调用wait()时会释放占用的cpu资源和锁，所以当Waiting线程被其他线程调用Object.notify()唤醒之后，需要重新获取对象上的锁。这时候也会先进入Blocked状态等待获取锁。

#### sleep 和 wait 有什么区别？

- wait 必须搭配 synchronize 一起使用，而 sleep 不需要；
- 进入 wait 状态的线程能够被 notify 和 notifyAll 线程唤醒，而 sleep 状态的线程不能被 notify 方法唤醒；
- wait 通常有条件地执行，线程会一直处于 wait 状态，直到某个条件变为真，但是 sleep 仅仅让你的线程进入睡眠状态；
- wait 方法会释放对象锁，但 sleep 方法不会。
- 在调用 wait 方法之后，线程会变为 WATING（等待）状态，而调用 sleep 方法之后，线程会变为 TIMED_WAITING（超时等待）状态。

#### 为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？

new 一个 Thread，线程进入了新建状态;调用 start() 方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。 而直接执行 run() 方法，**会把 run 方法当成一个 main 线程下的普通方法去执行*，并不会在某个线程中执行它，所以这并不是多线程工作。

**总结： 调用 start 方法方可启动线程并使线程进入就绪状态，而 run 方法只是 thread 的一个普通方法调用，还是在主线程里执行。**

## ThreadLocal

ThreadLocal的==作用==就是：线程安全。

ThreadLocal的==本质==就是一个内部的静态的map，key是当前线程的句柄，value是需要保持的值。

由于是内部静态map，不提供遍历和查询的接口，每个线程只能获取自己线程的value。

Threadlocal是thread的一个字段.ThreadlocalMap Threadlocals = 一个threadlocalmap对象
threadlocalmap里面存的是（threadlocal，value）键值对

==流程：==

- 首先，在每个线程Thread内部有一个ThreadLocal.ThreadLocalMap类型的成员变量threadLocals，这个threadLocals就是用来存储实际的变量副本的，键值为当前ThreadLocal变量，value为变量副本（即T类型的变量）。
- 初始时，在Thread里面，threadLocals为空，当通过ThreadLocal变量调用get()方法或者set()方法，就会对Thread类中的threadLocals进行初始化，并且以当前ThreadLocal变量为键值，以ThreadLocal要保存的副本变量为value，存到threadLocals。
- 然后在当前线程里面，如果要使用副本变量，就可以通过get方法在threadLocals里面查找。

#### ThreadLocal内存泄漏分析与解决方案

**ThreadLocal造成内存泄漏的原因?**
ThreadLocalMap中使用的key为ThreadLocal的弱引用,而value是强引用。所以，如果ThreadLocal没有被外部强引用的情况下，在垃圾回收的时候，key会被清理掉，而value不会被清理掉。这样一来，ThreadLocalMap中就会出现key为null的Entry。假如我们不做任何措施的话,value永远无法被GC回收，这个时候就可能会产生内存泄露。ThreadLocalMap实现中已经考虑了这种情况，在调用set()、 get()、remove()方法的时候，会清理掉key为null的记录。使用完ThreadLocal方法后最好手动调用remove()方法

**ThreadLocal内存泄漏解决方案?**
每次使用完ThreadLocal，都调用它的remove()方法，清除数据。
在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁—样，用完就清理。

## volatile

#### volatile

volatile是java虚拟机提供的**轻量级**的同步机制

- 保证可见性   将自己的刷新到主内存，其他线程的声明失效JMM
- **不保证原子性**   原子性就是一个操作同时成功或失败，不可分割，i++底层执行了三个操作，最后的写回主内存可能出现覆盖。 解决方法：sync或者JUC下atomic的AtomicInteger（do。while循环+cas），底层通过CAS实现
- 保证顺序性  禁止指令重排序

#### volatile怎么实现禁止指令重排序

**我们先来了解一下happen-before规则**

虽然指令重排提高了并发的性能，但是Java虚拟机会对指令重排做出一些规则限制，并不能让所有的指令都随意的改变执行位置，主要有以下几点：

1. 单线程每个操作，happen-before于该线程中任意后续操作
2. volatile写happen-before与后续对这个变量的读
3. synchronized解锁happen-before后续对这个锁的加锁
4. final变量的写happen-before于final域对象的读，happen-before后续对final变量的读
5. 传递性规则，A先于B，B先于C，那么A一定先于C发生

**内存屏障**
内存屏障（memory barrier）是一个CPU指令。基本上，它是这样一条指令： a) 确保一些特定操作执行的顺序； b) 影响一些数据的可见性(可能是某些指令执行后的结果)。
编译器和CPU可以在保证输出结果一样的情况下对指令重排序，使性能得到优化。插入一个内存屏障，相当于告诉CPU和编译器先于这个命令的必须先执行，后于这个命令的必须后执行。使用volatile关键字就会插入一个内存屏障

**内存屏障**另一个作用是强制更新一次不同CPU的缓存。例如，一个写屏障会把这个屏障前写入的数据刷新到缓存，这样任何试图读取该数据的线程将得到最新值，而不用考虑到底是被哪个cpu核心或者哪颗CPU执行的。这是不是就是所谓的可见性～

因为内存屏障可以使一些指令按照特定顺序执行。
volatile禁止指令重排序的**规则**：
　1.当第二个操作是voaltile写时，无论第一个操作是什么，都不能进行重排序
　2.当地一个操作是volatile读时，不管第二个操作是什么，都不能进行重排序
　3.当第一个操作是volatile写时，第二个操作是volatile读时，不能进行重排序

#### 你在哪些地方用到过volatile？

- 单例模式DCL代码 ，必须加volatile禁止指令重排，new对象的时候底层编译会有三个步骤，有可能进行指令重排
- CAS底层源码

实例化一个对象其实可以分为三个步骤：

- 分配内存空间。
- 初始化对象。
- 将内存空间的地址赋值给对应的引用。

但是由于操作系统可以`对指令进行重排序`，所以上面的过程也可能会变成如下过程：

- 分配内存空间。
- 将内存空间的地址赋值给对应的引用。
- 初始化对象

如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。

## synchronized

synchronized关键字解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

另外，在 Java 早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的 synchronized 效率低的原因。然后在 Java 6 之后 Java 官方从 JVM 层面对synchronized 较大优化，所以现在的 synchronized 锁效率也优化得很不错了。

JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

### 说说自己是怎么使用 synchronized 关键字，在项目中用到了吗

**synchronized关键字最主要的三种使用方式：**

- **修饰实例方法:** 作用于当前对象实例加锁，进入同步代码前要获得当前对象实例的锁
- **修饰静态方法:** 也就是给当前类加锁，会作用于类的所有对象实例，因为静态成员不属于任何一个实例对象，是类成员（ static 表明这是该类的一个静态资源，不管new了多少个对象，只有一份）。所以如果一个线程A调用一个实例对象的非静态 synchronized 方法，而线程B需要调用这个实例对象所属类的静态 synchronized 方法，是允许的，不会发生互斥现象，**因为访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态 synchronized 方法占用的锁是当前实例对象锁**。
- **修饰代码块:** 指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。

**总结：** synchronized 关键字加到 static 静态方法和 synchronized(class)代码块上都是是给 Class 类上锁。synchronized 关键字加到实例方法上是给对象实例上锁。尽量不要使用 synchronized(String a) 因为JVM中，字符串常量池具有缓存功能！

### synchronized 关键字的底层原理

**① synchronized 同步语句块的情况**

**synchronized 同步语句块的实现使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。** 当执行 monitorenter 指令时，线程试图获取锁也就是获取 monitor 的持有权。（monitor对象存在于每个Java对象的对象头中，synchronized 锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因）当锁计数器为0则可以成功获取，获取后将锁计数器设为1也就是加1。相应的在执行 monitorexit 指令后，将锁计数器设为0，表明锁被释放。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

**② synchronized 修饰方法的的情况**

synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED标识，该标识指明了该方法是一个同步方法，JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。

### synchronized和volatile的区别

 synchronized关键字和volatile关键字比较

- **volatile关键字**是线程同步的**轻量级实现**，所以**volatile性能肯定比synchronized关键字要好**。但是**volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块**。synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，**实际开发中使用 synchronized 关键字的场景还是更多一些**。
- **多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞**
- **volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。**
- **volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。**

### synchronized和lock的区别

- synchronized是关键字，lock是接口
- synchronized可以锁代码块和方法，lock只能锁代码块
- synchronized不可得知是否拿到锁，lock可以得知是否拿到锁
- synchronized是不可中断的，lock既可以中断也可以不中断synchronized会自动释放锁，lock只能手动释放锁
- synchronized是非公平锁，lock既可以是非公平锁又可以是公平锁
- lock有一个读写锁，可以提高效率

### synchronized和ReentrantLock的区别

==相同点==:两者都是可重入锁
两者都是可重入锁。"可重入锁"概念是:自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此
时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为O时才能释放锁。
主要==区别==如下:

- ReentrantLock 使用起来比较灵活，但是必须有释放锁的配合动作;
- ReentrantLock 必须手动获取与释放锁，而synchronized不需要手动释放和开启锁;
- ReentrantLock 只适用于代码块锁，而synchronized可以修饰类、方法、变量等。
- 二者的锁机制其实也是不一样的。ReentrantLock底层调用的是Unsafe的park方法加锁，synchronized操作的应该是对象头中mark word

### sync锁升级

底层采用CAS来保证原子性，自旋锁获取锁的时候不会阻塞，而是通过不断的while循环的方式尝试获取锁。**优点：减少线程上下文切换的消耗，缺点是会消耗CPU。如果锁被占用的时间很短，自旋等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自旋的线程只会白白消耗处理器资源，而不会做任何有用的工作，反而会带来性能上的浪费。**

#### 偏向锁、轻量级锁、重量级锁

这三种锁是指锁的状态，并且是针对Synchronized，在java通过引入锁升级的机制来实现高效的synchronized。锁的状态是通过对象监视器在对象头中的字段来表明的。

**偏向锁：**指一段同步代码一直被同一个线程s所访问，那么该线程会自动的获取锁。降低获取锁的代价。

**轻量级锁：**当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，           不会阻塞，提高性能。

**重量级锁：**当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没获取到锁就会进入阻塞，该锁膨胀为重量级锁。重量级会让其他申请线程阻塞，性能降低。 

**偏向锁，轻量级锁都是乐观锁，重量级锁是悲观锁。**
一个对象刚开始实例化的时候，没有任何线程来访问它的时候。它是==可偏向的==，意味着，它现在认为只可能有一个线程来访问它，所以==当第一个线程来访问它的时候，它会偏向这个线程==，此时，对象持有偏向锁。偏向第一个线程，这个线程在==修改对象头==成为偏向锁的时候使用CAS操作，并将对象头中的ThreadID改成自己的ID，之后再次访问这个对象时，只需要对比ID，不需要再使用CAS在进行操作。
一旦有第二个线程访问这个对象，因为偏向锁不会主动释放，所以第二个线程可以看到对象时偏向状态，这时表明在这个对象上已经存在竞争了，检查原来持有该对象锁的线程是否依然存活，如果挂了，则可以将对象变为无锁状态，然后重新偏向新的线程，如果原来的线程依然存活，则马上执行那个线程的操作栈，检查该对象的使用情况，==如果仍然需要持有偏向锁，则偏向锁升级为轻量级锁==，（偏向锁就是这个时候升级为轻量级锁的）。如果不存在使用了，则可以将对象回复成无锁状态，然后重新偏向。
轻量级锁认为竞争存在，但是竞争的程度很轻，一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。 但是==当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁==，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。

## 线程池

创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创建的线程数有限。为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫工作线程。

### 为什么要用线程池？

1.可以减少创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。

2.可以根据系统的承受能力，调整线程池中工作线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。

> **池化技术相比大家已经屡见不鲜了，线程池、数据库连接池、Http 连接池等等都是对这个思想的应用。池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。**

这里借用《Java 并发编程的艺术》提到的来说一下**使用线程池的好处**：

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

![图解线程池实现原理](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/图解线程池实现原理.png)

### Executor 框架

#### 简介

Executor 框架是 Java5 之后引进的，在 Java 5 之后，通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题。

> 补充：this 逃逸是指在构造函数返回之前其他线程就持有该对象的引用. 调用尚未构造完全的对象的方法可能引发令人疑惑的错误。

Executor 框架不仅包括了线程池的管理，还提供了线程工厂、队列以及拒绝策略等，Executor 框架让并发编程变得更加简单。

#### Executor 框架结构(主要由三大部分组成)

##### 1) 任务(`Runnable` /`Callable`)

执行任务需要实现的 **`Runnable` 接口** 或 **`Callable`接口**。**`Runnable` 接口**或 **`Callable` 接口** 实现类都可以被 **`ThreadPoolExecutor`** 或 **`ScheduledThreadPoolExecutor`** 执行。

##### 2) 任务的执行(`Executor`)

如下图所示，包括任务执行机制的核心接口 **`Executor`** ，以及继承自 `Executor` 接口的 **`ExecutorService` 接口。`ThreadPoolExecutor`** 和 **`ScheduledThreadPoolExecutor`** 这两个关键类实现了 **ExecutorService 接口**。

**这里提了很多底层的类关系，但是，实际上我们需要更多关注的是 `ThreadPoolExecutor` 这个类，这个类在我们实际使用线程池的过程中，使用频率还是非常高的。**

> **注意：** 通过查看 `ScheduledThreadPoolExecutor` 源代码我们发现 `ScheduledThreadPoolExecutor` 实际上是继承了 `ThreadPoolExecutor` 并实现了 ScheduledExecutorService ，而 `ScheduledExecutorService` 又实现了 `ExecutorService`，正如我们下面给出的类关系图显示的一样。

**`ThreadPoolExecutor` 类描述:**

```java
//AbstractExecutorService实现了ExecutorService接口
public class ThreadPoolExecutor extends AbstractExecutorService
```

**`ScheduledThreadPoolExecutor` 类描述:**

```java
//ScheduledExecutorService实现了ExecutorService接口
public class ScheduledThreadPoolExecutor
        extends ThreadPoolExecutor
        implements ScheduledExecutorService
```

![任务的执行相关接口](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-7/任务的执行相关接口.png)

##### 3) 异步计算的结果(`Future`)

**`Future`** 接口以及 `Future` 接口的实现类 **`FutureTask`** 类都可以代表异步计算的结果。

当我们把 **`Runnable`接口** 或 **`Callable` 接口** 的实现类提交给 **`ThreadPoolExecutor`** 或 **`ScheduledThreadPoolExecutor`** 执行。（调用 `submit()` 方法时会返回一个 **`FutureTask`** 对象）

#### 2.3 Executor 框架的使用示意图

![Executor 框架的使用示意图](https://imgconvert.csdnimg.cn/aHR0cDovL215LWJsb2ctdG8tdXNlLm9zcy1jbi1iZWlqaW5nLmFsaXl1bmNzLmNvbS8xOC01LTMwLzg0ODIzMzMwLmpwZw?x-oss-process=image/format,png)

1. **主线程首先要创建实现 `Runnable` 或者 `Callable` 接口的任务对象。**
2. **把创建完成的实现 `Runnable`/`Callable`接口的 对象直接交给 `ExecutorService` 执行**: `ExecutorService.execute（Runnable command）`）或者也可以把 `Runnable` 对象或`Callable` 对象提交给 `ExecutorService` 执行（`ExecutorService.submit（Runnable task）`或 `ExecutorService.submit（Callable <T> task）`）。
3. **如果执行 `ExecutorService.submit（…）`，`ExecutorService` 将返回一个实现`Future`接口的对象**（我们刚刚也提到过了执行 `execute()`方法和 `submit()`方法的区别，`submit()`会返回一个 `FutureTask 对象）。由于 FutureTask` 实现了 `Runnable`，我们也可以创建 `FutureTask`，然后直接交给 `ExecutorService` 执行。
4. **最后，主线程可以执行 `FutureTask.get()`方法来等待任务执行完成。主线程也可以执行 `FutureTask.cancel（boolean mayInterruptIfRunning）`来取消此任务的执行。**

### 创建线程池的方式

**Executors**			**ThreadPoolExecutor**

使用ThreadPoolExecutor创建线程的话，更能了解线程池运行的规则，避免资源耗尽的风险

- newFixedThreadPool固定线程池
- newSingleThreadExecutor一个线程的线程池
- newCachedThreadPool缓存线程池
- newScedulePool创建一个定长线程池，支持定时及周期性任务执行。

#### 四个基本组成部分

**线程池管理器（ThreadPool）：**用于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务；
**工作线程（PoolWorker）：**线程池中线程，在没有任务时处于等待状态，可以循环的执行任务；
**任务接口（Task）：**每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等；
**任务队列（taskQueue）：**用于存放没有处理的任务。提供一种缓冲机制。

#### 常用的阻塞队列

LinkedBlockingQueue ：容量为 Integer.MAX_VALUE ，可以认为是无界队列。

SynchronousQueue  ：CachedThreadPool 是线程数可以无限扩展，所以 CachedThreadPool 线程池并不需要一个任务队列来存储任务。

DelayedWorkQueue ：按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构，也是无界队列。

#### 线程池参数

- **corePoolSize：核心线程数**
        \* 核心线程会一直存活，及时没有任务需要执行
        \* 当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理
        \* 设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭
    
- **queueCapacity：工作队列**
        \* 当核心线程数达到最大时，新任务会放在队列中排队等待执行 
    
- **maxPoolSize：最大线程数**
        \* 当线程数>=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务
        \* 当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常 
    
- **keepAliveTime：线程空闲时间**
        \* 当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize
        \* 如果allowCoreThreadTimeout=true，则会直到线程数量=0 
    
- **threadFactory 线程工厂**

- **allowCoreThreadTimeout： **是否允许核心线程空闲退出，默认值为false。 

- **handler：拒绝策略**
  
    四种拒绝策略
    
    1. AbortPolicy（默认）：丢弃任务并抛运行时异常（RejectedExecutionException）。 
    2. DiscardPolicy：丢弃任务，但是不抛出异常。
    3. DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务 
    4. CallerRunsPolicy：由提交任务的线程处理该任务 
    
      两种情况会拒绝处理任务：
      - 当线程数已经达到maxPoolSize，并且队列已满，会拒绝新任务
      - 当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务
        
        \* ThreadPoolExecutor类有几个内部实现类来处理这类情况：
          \- AbortPolicy 丢弃任务，抛运行时异常
          \- CallerRunsPolicy 执行任务
          \- DiscardPolicy 忽视，什么都不会发生
          \- DiscardOldestPolicy 从队列中踢出最先进入队列（最后一个执行）的任务
        \* 实现RejectedExecutionHandler接口，可自定义处理器 

线程池的重点，并不是 `ThreadPoolExecutor`怎么用或者是`Executors`怎么用，**而是在合适的场景下使用合适的线程池，所谓"合适的线程池"的意思就是，ThreadPoolExecutor 的构造方法传入不同的参数，构造出不同的线程池，以满足使用的需要。**

### 线程池大小设置

看应用是CPU密集型的还是IO密集型的，还是混合型的。

- CPU密集
    CPU密集型的话，一般配置CPU处理器个数+/-1个线程，所谓CPU密集型就是指系统大部分时间是在做程序正常的计算任务，例如数字运算、赋值、分配内存、内存拷贝、循环、查找、排序等，这些处理都需要CPU来完成。
- IO密集
    IO密集型的话，是指系统大部分时间在跟I/O交互，而这个时间线程不会占用CPU来处理，即在这个时间范围内，可以由其他线程来使用CPU，因而可以多配置一些线程。
- 混合型
    混合型的话，是指两者都占有一定的时间。

## JUC

主要包含

- Lock框架和Tools类(把图中这两个放到一起理解)
- Collections: 并发集合
- Atomic: 原子类
- Executors: 线程池

### Lock接口

#### Lock接口简介

　　Lock锁是一种工具，用来控制对共享资源的访问。

　　Lock锁和Synchronized锁两者各个有各自的使用场景，lock并不是来替换Synchronized锁的。

　　Lock接口最常见的实现类是ReentrantLock

#### Lock与synchronized的区别

首先synchronized是java内置关键字，在jvm层面，Lock是个java类；

synchronized会自动释放锁，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；

用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；

synchronized的锁可重入、不可中断()、非公平，而Lock锁可重入、可中断、可公平可非公平。

Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

synchronized只关联一个条件队列，Lock可以关联多个条件队列。


## Atomic 原子类

Atomic 翻译成中文是原子的意思。在化学上，我们知道原子是构成一般物质的最小单位，在化学反应中是不可分割的。在我们这里 Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。

所以，所谓原子类说简单点就是具有原子/原子操作特征的类。


并发包 `java.util.concurrent` 的原子类都存放在`java.util.concurrent.atomic`下,如下图所示。

![JUC原子类概览](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/JUC原子类概览.png)

### 5.2. JUC 包中的原子类是哪4类?

**基本类型** 

使用原子的方式更新基本类型

- AtomicInteger：整形原子类
- AtomicLong：长整型原子类
- AtomicBoolean：布尔型原子类

**数组类型**

使用原子的方式更新数组里的某个元素


- AtomicIntegerArray：整形数组原子类
- AtomicLongArray：长整形数组原子类
- AtomicReferenceArray：引用类型数组原子类

**引用类型**

- AtomicReference：引用类型原子类
- AtomicStampedReference：原子更新引用类型里的字段原子类
- AtomicMarkableReference ：原子更新带有标记位的引用类型

**对象的属性修改类型**

- AtomicIntegerFieldUpdater：原子更新整形字段的更新器
- AtomicLongFieldUpdater：原子更新长整形字段的更新器
- AtomicStampedReference：原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。


### 5.3. 讲讲 AtomicInteger 的使用

 **AtomicInteger 类常用方法**

```java
public final int get() //获取当前的值
public final int getAndSet(int newValue)//获取当前的值，并设置新的值
public final int getAndIncrement()//获取当前的值，并自增
public final int getAndDecrement() //获取当前的值，并自减
public final int getAndAdd(int delta) //获取当前的值，并加上预期的值
boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值设置为输入值（update）
public final void lazySet(int newValue)//最终设置为newValue,使用 lazySet 设置之后可能导致其他线程在之后的一小段时间内还是可以读到旧的值。
```

 **AtomicInteger 类的使用示例**

使用 AtomicInteger 之后，不用对 increment() 方法加锁也可以保证线程安全。

```java
class AtomicIntegerTest {
        private AtomicInteger count = new AtomicInteger();
      //使用AtomicInteger之后，不需要对该方法加锁，也可以实现线程安全。
        public void increment() {
                  count.incrementAndGet();
        }
     
       public int getCount() {
                return count.get();
        }
}

```

### 5.4. 能不能给我简单介绍一下 AtomicInteger 类的原理

AtomicInteger 线程安全原理简单分析

AtomicInteger 类的部分源码：

```java
    // setup to use Unsafe.compareAndSwapInt for updates（更新操作时提供“比较并替换”的作用）
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset
                (AtomicInteger.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }

    private volatile int value;
```

AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。

CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。

关于 Atomic 原子类这部分更多内容可以查看我的这篇文章：并发编程面试必备：[JUC 中的 Atomic 原子类总结](

## 线程安全的实现方法

### 什么是线程安全

**线程安全：**多个线程访问同一个对象，如果我们不用考虑线程运行时的调度和交替执行，不用做额外的同步，或者在调用时候不用进行协调操作，调用的结果总是正确的结果，那么这个对象是线程安全的”

线程安全的对象具有以下特征：对象本身已经封装了所有必要的正确性保障手段，对象的使用者不用考虑多线程的问题。

1、synchronized锁（偏向锁，轻量级锁，重量级锁）

2、volatile锁，只能保证线程之间的可见性，但不能保证数据的原子性

3、jdk1.5并发包中提供的Atomic原子类

4、Lock锁

## AQS

AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。

### AQS 核心思想

AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。

### AQS 对资源的共享方式

AQS定义两种资源共享方式

- Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 
    - 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
    - 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的
- Share(共享)：多个线程可同时执行，如Semaphore/CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。

ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。

不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等)，AQS已经在上层已经帮我们实现好了。

# JVM

 JVM（Java Virtual Machine），俗称Java虚拟机。它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。Java语言的一个非常重要的特点就是与平台的无关性。而使用Java虚拟机是实现这一特点的关键。 

JVM的内部体系结构分为三部分

- 类装载器（ClassLoader）子系统
- [运行时数据区](#JVM内存模型)
- 执行引擎

## Java创建一个对象

#### 对象的创建

- ==指针碰撞：==有一段连续的区间，边界是两个指针（假设左右指针），分配一个对象，分配的地方就移动一定的字节数。如果发现左指针移动一定量的字节数后已经跟边界的右指针接触越过了，就会分配失败。（左右是相对的）
- 一边分配，一边垃圾回收，肯定会产生空间碎片，空间碎片的大小可能有足够大的空间在里面在去分配其他的对象。那么空闲链表就是来记录这些碎片的。
- ==空闲链表：==记录空闲，可用的空间。初始状态下，整个堆不就是一大块空闲空间嘛。为什么空闲列表这么好有的垃圾回收器，或者jvm有一部分还用指针碰撞呢，原因很简单，越好用的东西，管理起来就越麻烦，浪费的时间的越多。

#### 内存分布

- Header（对象头）：存储对象的原数据（无法直接操作）

  - 自身运行时的数据（Mark Word）（根据对象的状态来复用自己的空间，效果下图显示的淋漓尽致，里面的信息不一定全部存进去，可以只存进一部分，用来显示当前状态）

    1. 偏向时间戳

    2. 偏向线程ID

    3. 线程持有的锁

    4. 锁状态标志

    5. GC分代年龄（涉及垃圾回收）

    6. 对象哈希码（native方法）。

       ![](https://img-blog.csdnimg.cn/20190916171540108.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1lEXzE2MjAzMQ==,size_16,color_FFFFFF,t_70)

  - 指针类型：找到对象实例的元数据（所谓的元数据是指描述类与其他代码关系的代码介绍链接：[传送门](https://www.cnblogs.com/liuqk/articles/2115778.html)）

  - 数组长度：数组才有

- instanceData(实例数据)

  - 相同的字节数的会放到一块，父类数据放在子类数据之前。
  - 注意局部变量放在局部变量表中，而且是在运行期间才会进行读写操作。

- Padding （对齐填充）：填充内存的作用

  - 虚拟机有位数要求的时候，如果对象数据没有占够位数/倍数，用padding填空

#### 访问定位

- ==直接引用：==java栈中找到本方法的实例的时候，reference（存在于栈->栈帧->局部变量表->第0个位置（数组从零开始））存放堆中实例的引用。直接引用就是对象的堆中的实际地址，描述一个类需要类实例，类的一些描述，这些类描述存在方法区中。所以，使用直接引用的话，类的实例需要存储一个指向类描述的指针。

- ==句柄池：==类似于链接的中介，存放类实例的地址，类描述的地址。reference只需要指向本类的句柄池的位置，就可以得到两个引用。但是句柄池需要在堆中开辟出一块单独的空间来进行存储这些信息。

- 直接指针当然是速度快，不用在堆中进行中转。

  类的位置是会改变的，垃圾回收的时候，为了保持拥有连续的空间。经常会进行位置的移动，那么就需要进行指针的改变。

  使用句柄池的话，只需要改变句柄池的指针即可，不需要到栈中改变。为什么同样是改变指针，为什么句柄池会快。因为一次对象的移动涉及到很多个类，况且栈结构遍历很麻烦，很耗时间。

  鉴于这两个优缺点，可以在堆中使用句柄池，在方法区中使用直接引用。有一些虚拟机是把老年代放在方法区中的。

  这样也可以理解为什么句柄池放在堆中了。

## Java类加载过程

![image-20210718215436649](https://gitee.com/shen1shen1/pic-md1/raw/master/20210718215438.png)

### 加载

类加载过程的一个阶段，ClassLoader通过一个类的完全限定名查找此类字节码文件，并利用字节码文件创建一个class对象。

> **加载.class文件的方式**
>
> - 从本地系统中直接加载
> - 通过网络下载.class文件
> - 从zip，jar等归档文件中加载.class文件
> - 从专有数据库中提取.class文件
> - 将Java源文件动态编译为.class文件

### 验证

验证是连接阶段的第一步，这一阶段的目的是为了确保加载的类符合 JVM 规范和安全，保证被校验类的方法在运行时不会做出危害虚拟机的事件，其实就是一个安全检查。验证阶段大致会完成4个阶段的检验动作:

- ==文件格式验证==: 验证字节流是否符合Class文件格式的规范；例如: 是否以`0xCAFEBABE`开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。
- ==元数据验证==: 对字节码描述的信息进行语义分析(注意: 对比`javac`编译阶段的语义分析)，以保证其描述的信息符合Java语言规范的要求；例如: 这个类是否有父类，除了`java.lang.Object`之外。
- ==字节码验证==: 通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。
- ==符号引用验证==: 确保解析动作能正确执行。

### 准备

为static变量在方法区中分配内存空间，设置变量的初始值，例如 static int a = 3 （注意：准备阶段只设置类中的静态变量（方法区中），不包括实例变量（堆内存中），实例变量是对象初始化时赋值的）

* 这个时候static int a=3; a的值是0 在接下来的初始化阶段才会赋值成3
* final修饰的会被赋值 final int b=4; //b

### 解析

虚拟机将常量池内的符号引用替换为直接引用的过程（符号引用比如我现在import java.util.ArrayList这就算符号引用，直接引用就是指针或者对象地址，注意引用对象一定是在内存进行）

**符号引用**就是一组符号来描述目标，可以是任何字面量。

**直接引用**就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。

### 初始化

初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式:

- 声明类变量是指定初始值
- 使用静态代码块为类变量指定初始值

**JVM初始化步骤**

- 假如这个类还没有被加载和连接，则程序先加载并连接该类
- 假如该类的直接父类还没有被初始化，则先初始化其直接父类
- 假如类中有初始化语句，则系统依次执行这些初始化语句

**类初始化时机**: 只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种:

- 创建类的实例，也就是new的方式
- 访问某个类或接口的静态变量，或者对该静态变量赋值
- 调用类的静态方法
- 反射(如Class.forName("com.pdai.jvm.Test"))
- 初始化某个类的子类，则其父类也会被初始化
- Java虚拟机启动时被标明为启动类的类(Java Test)，直接使用java.exe命令来运行某个主类

### 使用

类访问方法区内的数据结构的接口， 对象是Heap区的数据。

### 卸载

**Java虚拟机将结束生命周期的几种情况**

- 执行了System.exit()方法
- 程序正常执行结束
- 程序在执行过程中遇到了异常或错误而异常终止
- 由于操作系统出现错误而导致Java虚拟机进程终止

## 类加载器， JVM类加载机制

### 类加载器的层次

![img](https://www.pdai.tech/_images/jvm/java_jvm_classload_3.png)

类加载器可以大致划分为以下三类 :

- 启动类加载器（Bootstrap ClassLoader）：负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。*
- 扩展类加载器（Extension ClassLoader）：负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。
- 应用程序类加载器（ Application ClassLoader）：负责加载用户类路径(ClassPath)所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。

应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点：

- 在执行非置信代码之前，自动验证数字签名。
- 动态地创建符合用户特定需要的定制化构建类。
- 从特定的场所取得java class，例如数据库中和网络中

### 简述双亲委派机制

#### 工作原理

BootStrap

先检查有没有加载过这个类

如果一个类收到了类加载的请求，它并不会自己先去加载，而是把这个请求委托给父类加载器去执行，如果父类加载器还存在父类加载器，则进一步向上委托，依次递归，请求最后到达顶层的启动类加载器，如果父类能够完成类的加载任务，就会成功返回，倘若父类加载器无法完成任务，子类加载器才会尝试自己去加载，这就是双亲委派模式。

#### 优势

安全性和性能。

- 首先它可以**避免类的重复加载**，当父亲已经加载了该类的时候，就没有必要子类加载器（ClassLoader）再加载一次。
- 其次是考虑到安全因素，**Java核心API中定义类型不会被随意替换**，假设通过网路传递一个名为java.lang.Integer的类，通过双亲委派的的模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字类，发现该类已经被加载，并不会重新加载网络传递过来的java.lang.Integer.而之际返回已经加载过的Integer.class，这样便可以防止核心API库被随意篡改。

### 破坏双亲委派

#### 第一次被破坏

jdk1.0没有双亲委派，所以jdk1.2引入时做了妥协，用户自定义的加载模型，所以被破坏

jdbc引入了一个上下文类加载器

OSGi 

[双亲委派模型和破坏性双亲委派模型详解_Enjoy博客-CSDN博客_破坏双亲委派模型](https://blog.csdn.net/luoyang_java/article/details/92598142) 

#### JDBC为何要破坏双亲委派

**因为类加载器受到加载范围的限制，在某些情况下父类加载器无法加载到需要的文件，这时候就需要委托子类加载器去加载class文件。**

**JDBC的Driver接口定义在JDK中，其实现由各个数据库的服务商来提供，比如MySQL驱动包。**DriverManager 类中要加载各个实现了Driver接口的类，然后进行管理，但是DriverManager位于 $JAVA_HOME中jre/lib/rt.jar 包，由BootStrap类加载器加载，而其Driver接口的实现类是位于服务商提供的 Jar 包，**根据类加载机制，当被装载的类引用了另外一个类的时候，虚拟机就会使用装载第一个类的类装载器装载被引用的类。**也就是说BootStrap类加载器还要去加载jar包中的Driver接口的实现类。我们知道，BootStrap类加载器默认只负责加载 $JAVA_HOME中jre/lib/rt.jar 里所有的class，所以需要由子类加载器去加载Driver实现，这就破坏了双亲委派模型。

#### Tomcat为什么要破坏双亲委派

Tomcat是个web容器 ，我们可能需要在一个Tomcat上部署两个项目，不同的项目可能会依赖同一个第三方类库的不同版本，如果我们使用默认的类加载机制，是无法加载两个相同类库的不同版本的。

为了热加载jsp，简单的说就是机器不用重启，只要部署上就能用。

**commonLoader**：Tomcat最基本的类加载器，加载路径中的class可以被Tomcat容器本身以及各个Webapp访问；
**catalinaLoader**：Tomcat容器私有的类加载器，加载路径中的class对于Webapp不可见；
**sharedLoader**：各个Webapp共享的类加载器，加载路径中的class对于所有Webapp可见，但是对于Tomcat容器不可见；
**WebappClassLoader**：各个Webapp私有的类加载器，加载路径中的class只对当前Webapp可见；
从图中的委派关系中可以看出：

CommonClassLoader能加载的类都可以被Catalina ClassLoader和SharedClassLoader使用，从而实现了公有类库的共用，而CatalinaClassLoader和Shared ClassLoader自己能加载的类则与对方相互隔离。

WebAppClassLoader可以使用SharedClassLoader加载到的类，但各个WebAppClassLoader实例之间相互隔离。

而JasperLoader的加载范围仅仅是这个JSP文件所编译出来的那一个.Class文件，它出现的目的就是为了被丢弃：当Web容器检测到JSP文件被修改时，会替换掉目前的JasperLoader的实例，并通过再建立一个新的Jsp类加载器来实现JSP文件的HotSwap功能。

好了，至此，我们已经知道了tomcat为什么要这么设计，以及是如何设计的，那么，tomcat 违背了java 推荐的双亲委派模型了吗？答案是：违背了。 我们前面说过：

**双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应当由自己的父类加载器加载。**

很显然，tomcat 不是这样实现，tomcat 为了实现隔离性，没有遵守这个约定，每个webappClassLoader加载自己的目录下的class文件，不会传递给父类加载器。

我们扩展出一个问题：如果tomcat 的 Common ClassLoader 想加载 WebApp ClassLoader 中的类，该怎么办？
看了前面的关于破坏双亲委派模型的内容，我们心里有数了，我们可以使用线程上下文类加载器实现，使用线程上下文加载器，可以让父类加载器请求子类加载器去完成类加载的动作。牛逼吧。

## JVM内存模型

![img](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210813094938901.png)

==线程不安全区：==

**方法区**用于存储类信息，常量，静态变量等；

**堆**用于存放对象实例；

==线程安全区：==

程序计数器，本地方法栈，虚拟机栈是线程独享的。

**程序计数器**就是标记代码执行的行号，在线程切换后恢复到正确的执行位置；

**本地方法栈**是为虚拟机使用到的Native方法服务；

**虚拟机栈**描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。

### **本地方法栈和程序计数器**（线程独享）

比如说我们点开Thread类的源码，会看到它的start0方法有一个native关键字修饰，而且不存在方法体，这种用native修饰的方法就是本地方法，这是使用C来实现的，然后一般这些方法都会放到一个叫做**本地方法栈**的区域。

**程序计数器**其实就是一个指针，它指向了程序中下一句需要执行的指令，它也是内存区域中唯一一个不会出现OutOfMemoryError的区域，而且占用内存空间小到基本可以忽略不计。这个内存仅代表当前线程所执行的字节码的行号指示器，字节码解析器通过改变这个计数器的值选取下一条需要执行的字节码指令。

如果执行的是native方法，那这个指针就不工作了。

### **方法区**

方法区主要的作用就是存放类的元数据信息，常量和静态变量···等。当它存储的信息过大时，会在无法满足内存分配时报错。

### **虚拟机栈和堆**

#### 区别

他们俩的**区别**就是：栈管运行，堆管存储。则虚拟机栈负责运行代码，而虚拟机堆负责存储数据。

1、栈由系统自动分配，而堆是人为申请开辟; 

2、栈获得的空间较小，而堆获得的空间较大; 

3、栈由系统自动分配，速度较快,而堆一般速度比较慢;

4、栈是连续的空间，而堆是不连续的空间。

#### 虚拟机栈

它是Java方法执行的内存模型。里面会对局部变量，动态链表，方法出口，栈的操作（入栈和出栈）进行存储，且线程独享。同时如果我们听到局部变量表，那也是在说虚拟机栈。

##### 虚拟机栈存在的异常

如果线程请求的栈的深度大于虚拟机栈的最大深度，就会报 **StackOverflowError** （这种错误经常出现在递归中）。Java虚拟机也可以动态扩展，但随着扩展会不断地申请内存，当无法申请足够内存时就会报错 **OutOfMemoryError**。

**虚拟机栈的生命周期**

对于栈来说，不存在垃圾回收。只要程序运行结束，栈的空间自然就会释放了。栈的生命周期和所处的线程是一致的。

这里补充一句：8种基本类型的变量+对象的引用变量+实例方法都是在栈里面分配内存。

**局部变量的复用**

局部变量表用于存放方法参数和方法内部所定义的局部变量。它的容量是以Slot为最小单位，一个slot可以存放32位以内的数据类型。

虚拟机通过索引定位的方式使用局部变量表，范围为[0,局部变量表的slot的数量]。方法中的参数就会按一定顺序排列在这个局部变量表中，至于怎么排的我们可以先不关心。而为了节省栈帧空间，这些slot是可以复用的，当方法执行位置超过了某个变量，那么这个变量的slot可以被其它变量复用。当然如果需要复用，那我们的垃圾回收自然就不会去动这些内存。

#### 程序计数器

程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的**行号指示器**。

> - **使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？**
>
> 因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。
>
> - **PC寄存器为什么会被设定为线程私有的？**
>
> 多线程在一个特定的时间段内只会执行其中某一个线程方法，CPU会不停的做任务切换，这样必然会导致经常中断或恢复。为了能够准确的记录各个线程正在执行的当前字节码指令地址，所以为每个线程都分配了一个PC寄存器，每个线程都独立计算，不会互相影响。

#### 虚拟机栈

> Java 虚拟机栈(Java Virtual Machine Stacks)，早期也叫 Java 栈。每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），对应着一次次 Java 方法调用，是线程私有的，生命周期和线程一致。

**作用**：主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。

**特点**：

- 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器
- JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着**入栈**（进栈/压栈），方法执行结束**出栈**
- **栈不存在垃圾回收问题**

**栈中可能出现的异常**：

Java 虚拟机规范允许 **Java虚拟机栈的大小是动态的或者是固定不变的**

- 如果采用固定大小的 Java 虚拟机栈，那每个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 **StackOverflowError** 异常
- 如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个**OutOfMemoryError**异常

#### 堆

##### 对象在堆中的生命周期

1. 在 JVM 内存模型的堆中，堆被划分为新生代和老年代 
   - 新生代又被进一步划分为 **Eden区** 和 **Survivor区**，Survivor 区由 **From Survivor** 和 **To Survivor** 组成
2. 当创建一个对象时，对象会被优先分配到新生代的 Eden 区 
   - 此时 JVM 会给对象定义一个**对象年轻计数器**（`-XX:MaxTenuringThreshold`）
3. 当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） 
   - JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1
   - 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1
4. 如果分配的对象超过了`-XX:PetenureSizeThreshold`，对象会**直接被分配到老年代**

##### 对象的分配过程

为对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。

1. new 的对象先放在eden区，此区有大小限制
2. 当eden的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对eden区进行垃圾回收（Minor GC），将eden区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到eden园区
3. 然后将eden中的剩余对象移动到survivor 0 区
4. 如果再次触发垃圾回收，此时上次幸存下来的放到survivor 0 区，如果没有回收，就会放到survivor 1 区
5. 如果再次经历垃圾回收，此时会重新放回survivor 0 区，接着再去survivor 1 区
6. 什么时候才会去老年代呢？ 默认是 15 次回收标记,进入老年代
7. 在老年代，相对悠闲。当老年代内存不足时，再次触发 Major GC，进行老年代的内存清理
8. 若老年代执行了 Major GC  之后发现依然无法进行对象的保存，就会产生 OOM 异常

##### Minor GC、Major GC、Full GC

JVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。

针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full  GC）

- 部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： 
  - 新生代收集（Minor GC/Young GC）：只是新生代的垃圾收集
  - 老年代收集（Major GC/Old GC）：只是老年代的垃圾收集 
    - 目前，只有 CMS GC 会有单独收集老年代的行为
    - 很多时候 Major GC 会和 Full GC  混合使用，需要具体分辨是老年代回收还是整堆回收
  - 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 
    - 目前只有 G1 GC 会有这种行为
- 整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾

### JMM（Java内存模型）

#### 主内存与工作内存

Java内存模型规定了所有的变量都存储在==主内存==（Main Memory）中（此处的主内存与介绍物理 硬件时提到的主内存名字一样，两者也可以类比，但物理上它仅是虚拟机内存的一部分）。每条线程还有自己的==工作内存==（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用的变量的==主内存副本==，线程对变量的所有操作（读取、赋值等）都必须在工作内 存中进行，而不能直接读写主内存中的数据。不同的线程之间也无法直接访问对方工作内存中的变 量，线程间变量值的传递均需要通过主内存来完成，线程、主内存、工作内存三者的交互关系如图。

线程之间的共享变量存储在**主内存**中，每个线程都有一个私有的**本地内存**，本地内存中存储了该线程以读 / 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。 

线程 A 与线程 B 之间如要通信的话，必须要经历下面 2 个步骤：

1. 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。

2. 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。

   ![*image-20210814101226060*](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210814101226060.png)

这里所讲的==主内存、工作内存==与第2章所讲的Java内存区域中的==Java堆、栈、方法区0==等并不是同一个层次的对内存的划分，这两者基本上是没有任何关系的。如果两者一定要勉强对应起来，那么从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分，而工作内存 则对应于虚拟机栈中的部分区域。从更基础的层次上说，主内存直接对应于物理硬件的内存，而为了 获取更好的运行速度，虚拟机（或者是硬件、操作系统本身的优化措施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问的是工作内存。 

#### Happens-Before(先行发生原则)

先行发生是Java内存模型中定义的两项操作之间的==偏序关系==，比如说操作A先行发生于操作B，其实就是说在发生操作B之前，操作A产生的==影响==能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。

**规则：**

1、程序顺序规则：一个线程中的每个操作happens-before于该线程中的任意后续操作

2、监视器锁（同步）规则：对于一个监视器的解锁，happens-before于随后对这个监视器的加锁

`**程序顺序规则中所说的每个操作happens-before于该线程中的任意后续操作并不是说前一个操作必须要在后一个操作之前执行，而是指前一个操作的执行结果必须对后一个操作可见，如果不满足这个要求那就不允许这两个操作进行重排序**`



## JVM相关

### JVM参数

**-Xms**：JVM启动时申请的初始Heap值，默认为操作系统物理内存的1/64但小于1G。默认当空余堆内存大于70%时，JVM会减小heap的大小到-Xms指定的大小，可通过-XX:MaxHeapFreeRation=来指定这个比列。Server端JVM最好将-Xms和-Xmx设为相同值，避免每次垃圾回收完成后JVM重新分配内存；开发测试机JVM可以保留默认值。(例如：-Xms4g)

**-Xmx**：JVM可申请的最大Heap值，默认值为物理内存的1/4但小于1G，默认当空余堆内存小于40%时，JVM会增大Heap到-Xmx指定的大小，可通过-XX:MinHeapFreeRation=来指定这个比列。最佳设值应该视物理内存大小及计算机内其他内存开销而定。(例如：-Xmx4g)

**-Xmn**：Java Heap Young区大小。整个堆大小=年轻代大小 + 年老代大小 + 持久代大小(相对于HotSpot 类型的虚拟机来说)。持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。(例如：-Xmn2g)、**

### JVM工具

**jps**：与linux上的ps类似，用于查看有权访问的虚拟机的进程，可以查看本地运行着几个java程序，并显示他们的进程号。当未指定hostid时，默认查看本机jvm进程。

**jinfo**：可以输出并修改运行时的java 进程的一些参数。

**jstat**：可以用来监视jvm内存内的各种堆和非堆的大小及其内存使用量。

**jstack**：堆栈跟踪工具，一般用于查看某个进程包含线程的情况。

**jmap：**打印出某个java进程（使用pid）内存内的所有对象的情况。一般用于查看内存占用情况。

**jconsole**：一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视

### Tomcat和jvm的关系

1，JVM（虚拟机），相当于电脑安装系统一样，可以运行应用程序。让tomcat跑起来,就得有jdk，而jdk自带了JVM，安装完了jdk，把安装jkd的bin目录告诉tomca，就可以了。

2，有的web服务器不必安装jdk，因为自带了，如weblogic。

3，tomcat web容器，主要和有jsp和servlet有关， 没有tomcat， 通过一定技术是可以运行jsp和serlet，所以说JVM跑着tomcat，而没有JVM tomcat就废物了。

4，tomcat只是一个web容器，启动的时候，默认是不会去编译java及jsp code的，除非在你web工程的web.xml里配置了一些listener,然后在这些listner里，自己定义了一些关于jsp编译的操作。

 

前几天向unmi提问，今天他答复了。我觉得答复很清楚，在此记录下。总的来说 

1、一个tomcat是一个进程，其中有很多线程（与有多少个app无关） 

2、一个tomcat启动一个JVM，其中可以有很多APP 

3、一个tomcat中部署的多个app，虽然同处一个JVM里，但是由于无法相互调用，所以也可以认为是分布式的 

# MySQL

## 数据库三范式

第一范式：强调列的原子性，即数据库表的每一列都是不可分割的原子数据项。

第二范式：要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性。（消除部分依赖）

第三范式：任何非主属性不依赖于其他的非主属性。（消除传递依赖）

## utf8和unicode区别

1.**Unicode是一种字符集，而utf-8是一种编码方式。**Unicode字符集既可以用utf-8编码方式编成计算机能够识别的二进制数值，也可以用utf-16，utf-32等方式编码。

2.[Unicode](https://so.csdn.net/so/search?q=Unicode&spm=1001.2101.3001.7020)并不是用两个字节表示世界上所有的文字，实际上世界上所有的文字分为17个平面，每个平面都有65536个，也就是需要两个字节来存储的字符数，所以单纯的两个字节不足以来表示世界上所有的文字。

3.utf-8编码方式编出来的结果中第一个字节中连续的1表示这个字符占多少个字节，按照百度百科中的介绍，把Unicode字符集中的字符编码换算成2进制，再填入百科中那些XXXXX的地方，就变成了utf-8的编码结果。

4.为什么不用固定的两个字节去编码Unicode字符集中的字符，见2

5.因为utf-8中没有全为0的字符（至少要有1个连续的1，来表示这个字符占多少个字节，见3），所以**文本不会在第一个null字符时截断。而且由于utf-8中有一些固定的，有意义的（比如第一个字节中连续的1）二进制位，所以utf-8编码结果适合用于在网络中传输，因为他可以利用这些二进制位来纠错。**

## 关系型数据库和非关系型数据库

#### 关系型数据库

关系型数据库最典型的数据结构是表，由二维表及其之间的联系所组成的一个数据组织
**优点：**
1、易于维护：都是使用表结构，格式一致；
2、使用方便：SQL语言通用，可用于复杂查询；
3、复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询。
**缺点：**
1、读写性能比较差，尤其是海量数据的高效率读写；
2、固定的表结构，灵活度稍欠；
3、高并发读写需求，传统关系型数据库来说，硬盘I/O是一个很大的瓶颈。

**常用的关系型数据库：**mysql，sqlserver

#### 非关系型数据库

非关系型数据库严格上不是一种数据库，应该是一种数据结构化存储方法的集合，可以是文档或者键值对等。
**优点：**
1、格式灵活：存储数据的格式可以是key,value形式、文档形式、图片形式等等，文档形式、图片形式等等，使用灵活，应用场景广泛，而关系型数据库则只支持基础类型。
2、速度快：nosql可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘；
3、高扩展性；
4、成本低：nosql数据库部署简单，基本都是开源软件。

**解耦！**
1 、方便扩展（数据之间没有关系，很好扩展！）
2 、大数据量高性能（ Redis 一秒写 8 万次，读取 11 万， NoSQL 的缓存记录级，是一种细粒度的缓存，性 能会比较高！）
3 、数据类型是多样型的！（不需要事先设计数据库！随取随用！如果是数据量十分大的表，很多人就无法设计了！）

**缺点：**
1、不提供sql支持，学习和使用成本较高；
2、无事务处理；
3、数据结构相对复杂，复杂查询方面稍欠。

**常用的非关系型数据库**：redis,nosql

## 数据库设计原则（RBAC）

### RBAC是什么

 RBAC是基于角色的访问控制（`Role-Based Access Control` ）在[RBAC] 中，权限与角色相关联，用户通过成为适当角色的成员而得到这些角色的权限。这就极大地简化了权限的管理。这样管理都是层级相互依赖的，权限赋予给角色，而把角色又赋予用户，这样的权限设计很清楚，管理起来很方便。 

## 存储引擎

### InnoDB

是 MySQL 默认的事务型存储引擎，**只有在需要它不支持的特性时，才考虑使用其它存储引擎**。

实现了四个标准的隔离级别，默认级别是可重复读(REPEATABLE READ)。在可重复读隔离级别下，通过多版本并发控制(MVCC)+ 间隙锁(Next-Key Locking)防止幻影读。

主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。

内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。

支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

### MyISAM

设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。

提供了大量的特性，包括压缩表、空间数据索引等。

**不支持事务**。

不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入(CONCURRENT INSERT)。

可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。

如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。

### 比较

- 事务: InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发: MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键: InnoDB 支持外键。
- 备份: InnoDB 支持在线热备份。
- 崩溃恢复: MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性: MyISAM 支持压缩表和空间数据索引。

### InnoDB的七种锁

InnoDB共有七种类型的锁：

- 共享/排他锁(Shared and Exclusive Locks)
- 意向锁(Intention Locks)
- 记录锁(Record Locks)
- 间隙锁(Gap Locks)
- 临键锁(Next-key Locks)
- 插入意向锁(Insert Intention Locks)
- 自增锁(Auto-inc Locks)
    其中意向锁和自增锁是表锁, 其余都是行锁. 记录锁、间隙锁和临键锁是排他锁. 插入意向锁是间隙锁的一种. 下面是七种锁的详细介绍:

#### 共享/排他锁

InnoDB实现了两种标准的行锁, 分别是共享锁和排他锁.

事务拿到某一行记录的共享锁，才可以读取这一行.
事务拿到某一行记录的排它锁，才可以修改或者删除这一行.
共享锁和排他锁的兼容关系如下:

是否兼容	共享锁	排他锁
共享锁	是	否
排他锁	否	否

#### 意向锁

InnoDB支持多重粒度锁, 允许行锁和表锁共存. 意向锁是表锁, 包括意向共享锁(intention shared lock)和意向排他锁(intention exclusive lock).

意向锁仅仅表明意向, 并不会锁住数据. 当事务对一行记录加共享锁之前必须先添加意向共享锁, 同样, 在加排他锁之前要先添加意向排他锁. 他们的兼容关系如下:

是否兼容	共享锁	排他锁	意向共享锁	意向排他锁
共享锁	√	×	√	×
排他锁	×	×	×	×
意向共享锁	√	×	√	√
意向排他锁	×	×	√	√

#### 记录锁

记录锁封锁索引记录, 例如:

SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE
1
它会在c1=10的索引记录上加锁，以阻止其他事务插入, 更新, 删除这一行.

注意, 普通的查询是快照读, 不加锁:

```sql
SELECT c1 FROM t WHERE c1 = 10
```

#### 间隙锁

间隙锁封锁索引记录之间的间隔, 或者第一条索引记录之前的范围, 或者最后一条索引记录之后的范围. 例如一个索引包含10, 20:

```sql
SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE
```


上面这条语句封锁了c1在10和20之间的这个范围, 插入一个c1=15的数据就会失败.

#### 临键锁

临键锁是记录锁和间隙锁的组合, 临键锁会封锁索引记录和该索引记录之前的间隙. 例如有一个id索引包含10, 11, 13 和20, 临键锁可能封锁的区间如下:

```
(negative infinity, 10]	--封锁索引10时 
(10, 11]		--封锁索引11时
(11, 13]		--封锁索引13时
(13, 20]		--封锁索引20时
(20, positive infinity)		--封锁索引20时
```


当使用临建锁封锁20时, 因为20是最后一个索引值, 所以会封锁两个区间: (13, 20] 和 (20, positive infinity).

在REPEATABLE READ隔离级别下, InnoDB使用临键锁解决幻读的问题(MySQL 5.7版本, 可见官网), 如下所示

```
SELECT * FROM t WHERE id > 12 FOR UPDATE;
```


上面的这条语句会锁定(11, 13], (13, 20], (20, positive infinity) 三个区间, 这样其他事务就不能在这个范围内插入行了.

#### 插入意向锁

插入意向锁是间隙锁的一种, 是专门针对insert操作的. 在进行insert操作时, 会先在插入间隙加上插入意向锁, 然后对具体的插入行加上排他锁.

插入意向锁仅仅表示一种意向, 当多个事务在同一索引间隔内插入数据时, 如果插入的位置不冲突就不会阻塞彼此. 例如有一索引间隔[10,15]:

先执行事务A, 未提交:

insert into t values(11);
1
再执行事务B:

insert into t values(12);
1
因为两个事务插入的位置不冲突, 所以事务B并不会被阻塞.

#### 自增锁

自增锁是表锁, 针对AUTO_INCREMENT类型的列. 例如主键ID是AUTO_INCREMENT类型的, 如果一个事务正在往表中插入记录, 其他所有事务的插入必须等待, 以便第一个事务插入的行拥有连续的主键值.

### 聚簇索引和非聚簇索引

- 聚簇索引：将数据存储与索引放到了一块，找到索引也就找到了数据

- 非聚簇索引：将数据存储于索引分开结构，索引结构的叶子节点指向了数据的对应行，myisam通过key_buffer把索引先缓存到内存中，当需要访问数据时（通过索引访问数据），在内存中直接搜索索引，然后通过索引找到磁盘相应数据，这也就是为什么索引不在key buffer命中时，速度慢的原因

### 何时使用聚簇索引与非聚簇索引

![img](https://upload-images.jianshu.io/upload_images/10154499-d53a5ce9cecf22f3.png?imageMogr2/auto-orient/strip|imageView2/2/w/864/format/webp)

#### 聚簇索引具有唯一性

由于聚簇索引是将数据跟索引结构放到一块，因此一个表仅有一个聚簇索引

### 聚簇索引的优缺点

优点：

1.数据访问更快，因为聚簇索引将索引和数据保存在同一个B+树中，因此从聚簇索引中获取数据比非聚簇索引更快

2.聚簇索引对于主键的排序查找和范围查找速度非常快
缺点：

1.插入速度严重依赖于插入顺序，按照主键的**顺序插入**是最快的方式，否则将会出现页分裂，严重影响性能。因此，对于InnoDB表，我们一般都会定义一个**自增的ID列为主键**
2.**更新主键的代价很高**，因为将会导致被更新的行移动。因此，对于InnoDB表，我们一般定义主键为不可更新。
3.二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。



## MySQL 索引（数据结构）

### 1. B+Tree 索引

是大多数 MySQL 存储引擎的默认索引类型。

因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。除了用于查找，还可以用于排序和分组。

可以指定多个列作为索引列，多个索引列共同组成键。

适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。

InnoDB 的 B+Tree 索引分为主索引和辅助索引。

主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为**聚簇索引**。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。

 ![img](https://www.pdai.tech/_images/mysql/c28c6fbc-2bc1-47d9-9b2e-cf3d4034f877.jpg) 

辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。

 ![img](https://www.pdai.tech/_images/mysql/7ab8ca28-2a41-4adf-9502-cc0a21e63b51.jpg) 

### 2. 哈希索引

哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制:

- 无法用于排序与分组；
- 只支持精确查找，无法用于部分查找和范围查找。

InnoDB 存储引擎有一个特殊的功能叫“**自适应哈希索引**”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。

MySQL索引使用的数据结构主要有**BTree索引** 和 **哈希索引** 。对于哈希索引来说，底层的数据结构就是哈希表，因此在绝大多数需求为单条记录查询的时候，可以选择哈希索引，查询性能最快；其余大部分场景，建议选择BTree索引。

### 对聚簇索引的理解

聚簇索引是对磁盘上实际数据᯿新组织以按指定的⼀个或多个列的值排序的算法。特点是存储数据的顺序和索引顺序⼀致。⼀般情况下主键会默认创建聚簇索引，且⼀张表只允许存在⼀个聚簇索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为**聚簇索引**。

**聚簇索引和非聚簇索引的区别：**

聚簇索引的叶⼦节点就是数据节点，⽽⾮聚簇索引的叶⼦节点仍然是索引节点，只不过有指向对应数据块的指针

### MySQL数据库为什么大多使用B+树，而不是用Hash存储索引

**对于B+树，相比于Hash好处：**

1.利用Hash需要把数据全部加载到内存中，如果数据量大，是一件很消耗内存的事，而采用B+树，是基于按照节点分段加载，由此减少内存消耗。

2.和业务场景有段，对于唯一查找（查找一个值），Hash确实更快，但数据库中经常查询多条数据，这时候由于B+数据的有序性，与叶子节点又有链表相连，他的查询效率会比Hash快的多。

### B+树和skipList的时间复杂度都是O(log n)，为什么数据库底层要用B+树而不用skipList？

因为B+tree比跳跃表的检索效率更高，数据分部的更均匀。

跳跃表是通过二路分治的方式实现logN。
B+Tree是通过多路分治的方式实现logN。

当数据表的数据足够多的时候，B+tree的根节点～任何一块叶子节点的路径是固定的。而skiplist的头节点～目标节点的路径是不固定的。所以检索的value越大，skiplist的路径就越深，磁盘的io次数就越多。

B+tree的所有叶子节点构成了一个双向循环链表，每一块叶子节点可以存储一条或者多条数据。这种结构不管是一条记录、还是多条记录查询都能节省磁盘IO。

skiplist的每一个节点只存储一条记录，对于一条记录的查询是比较节省磁盘io，对于多条记录的查询，skiplist的磁盘IO次数会比B+tree要多。

一切都是减少io耗时为目的

### 为什么使用B+树而不适用B树

**B+树**只有**叶子结点存储数据**，并形成链表（范围查找加快），其他节点只存索引，所以其他节点的体积小，硬盘一次加载的节点多，查找效率就快

**B树**是所有节点都存数据，所以体积大，硬盘一次加载的节点少，查找就慢

B+树的中间节点没有卫星数据，所以同样大小的磁盘页可以容纳更多的节点元素。这就意味着，数据量相同的情况下，B+树的结构比B-树更加“矮胖“因此查询时IO次数也更少。

B+树的查询必须最终查找到叶子节点，而B-树只要找到匹配元素即可，无论匹配元素处于中间节点还是叶子节点。

因此，B-树的查找性能并不稳定（最好情况是只查根节点，最坏情况是查到叶子节点）。而 B+ 树的每次查找都是稳定的。

引申：B*树  B+树所有节点都能形成链表

**B树：**二叉树，每个结点只存储一个关键字，等于则命中，小于走左结点，大于走右结点；

**B-树：**多路搜索树，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的子结点；所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；

**B+树：**在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中；

**B\*树：** 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3；

### 何时使用数据库索引

1、表的主键、外键必须有索引;

2、数据量超过300的表应该有索引;

3、经常与其他表进行连接的表，在连接字段上应该建立索引;

4、经常出现在Where子句中的字段，特别是大表的字段，应该建立索引;

5、索引应该建在选择性高的字段上;

6、索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引;

7、复合索引的建立需要进行仔细分析;尽量考虑用单字段索引代替：

### 为什么要用索引

1. 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
2. 可以大大加快 数据的检索速度（大大减少的检索的数据量）,  这也是创建索引的最主要的原因。 
3. 帮助服务器避免排序和临时表。
4. 将随机IO变为顺序IO
5. 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。

### 索引这么多优点，为什么不对表中的每一个列创建一个索引呢？

1. 当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 
2. 索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 
3. 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 

## 索引优化

### 1. 独立的列

在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。

例如下面的查询不能使用 actor_id 列的索引:

```sql
SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;
```

### 2. 多列索引

在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。

```sql
SELECT film_id, actor_ id FROM sakila.film_actor
WHERE actor_id = 1 AND film_id = 1;
```

### 3. 索引列的顺序

让选择性最强的索引列放在前面，索引的选择性是指: 不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，查询效率也越高。

例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。

```sql
SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,
COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,
COUNT(*)
FROM payment;
```

```html
   staff_id_selectivity: 0.0001
customer_id_selectivity: 0.0373
               COUNT(*): 16049
```

### 4. 前缀索引

对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。

对于前缀长度的选取需要根据索引选择性来确定。

### 5.联合索引

对于多个字段同时建立的索引（其中存在顺序，例如ABC与ACB就是完全不同的两种联合索引。MySQL中的索引可以以一定顺序引用多列，这种索引叫作联合索引。如User表的name和city加联合索引就是(name,city)

**最左匹配原则。**

(A,B,C) 这样3列，mysql会首先匹配A，然后再B，C.

如果用(B,C)这样的数据来检索的话，就会找不到A使得索引失效。如果使用(A,C)这样的数据来检索的话，就会先找到所有A的值然后匹配C，此时联合索引是失效的。

把最常用的，筛选数据最多的字段放在左侧。

最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，则此列就可以被用到。如下：        

```                                                                                       
select * from user where name=xx and city=xx ; ／／可以命中索引
select * from user where name=xx ; // 可以命中索引
select * from user where city=xx ; // 无法命中索引            
```

这里需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 `city= xx and name ＝xx`，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。

由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑字段值去重之后的个数，较多的放前面。ORDER BY子句也遵循此规则。

a,b,c

where a=xx and b>443 and c=32;

where c=32 and b =-123 and a =123;

### 6. 覆盖索引

索引包含所有需要查询的字段的值。不用回表。

具有以下优点:

- 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。
- 一些存储引擎(例如 MyISAM)在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用(通常比较费时)。
- 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。

**实例**

现在我创建了索引(username,age)，我们执行下面的 sql 语句

```sql
select username , age from user where username = 'Java' and age = 22
```

在查询数据的时候：要查询出的列在叶子节点都存在！所以，就不用回表。

## 索引的优点

- 大大减少了服务器需要扫描的数据行数。
- 帮助服务器避免进行排序和分组，也就不需要创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表）。
- 将随机 I/O 变为顺序 I/O(B+Tree 索引是有序的，也就将相邻的数据都存储在一起

## 索引的使用场景

- 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。
- 对于中到大型的表，索引就非常有效。
- 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。

## 索引失效问题

- like以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效
- or语句前后没有同时使用索引。当or左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，才会生效
- 联合索引，不是使用第一列的索引，索引失效
- 数据类型出现隐式转化。如varchar不加单引号的话可能自动转换为int类型，使索引无效，产生全表扫描
- 在索引字段上使用not，<>,!=。不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。优化方法：key<>0改为key<0 or key >0
- 对索引字段进行计算操作、字段上使用函数
- 当全表扫描速度比索引速度快，mysql会使用全表扫描，此时索引失效
- 索引列不要参与计算
- or的两侧要么都索引列，要么都不是索引列
- 模糊匹配的时候%不要在头部啦等等

## 注意避免冗余索引

冗余索引指的是索引的功能相同，能够命中 就肯定能命中 ，那么 就是冗余索引如（name,city ）和（name ）这两个索引就是冗余索引，能够命中后者的查询肯定是能够命中前者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

MySQL 5.7 版本后，可以通过查询 sys 库的 `schema_redundant_indexes` 表来查看冗余索引   

## 事务、隔离级别

事务特性以及实现原理：https://www.cnblogs.com/kismetv/p/10331633.html

### 什么是事务?

**事务是逻辑上的一组操作，要么都执行，要么都不执行。**

事务最经典也经常被拿出来说例子就是转账了。假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。

### 事务的四大特性(ACID)

![事物的特性](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-6/事务特性.png)

1. **原子性（Atomicity）：** 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；（undolog回滚日志）
2. **一致性（Consistency）：** 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
3. **隔离性（Isolation）：** 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；（锁机制，）
4. **持久性（Durability）：** 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。（redolog重做日志）

### 并发事务带来哪些问题?

在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对同一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

- **脏读（Dirty read）:** 一个事务对数据进行了增删改查，但是未提交事务。另一个事物可以读取到未提交的数据，如果第一个事务进行了回滚，那么第二个事务就读到了脏数据。依据“脏数据”所做的操作可能是不正确的。

  例子：领导给张三发工资，10000元已打到张三账户，但该事务还未提交，正好这时候张三去查询工资，发现10000元已到账。这时领导发现张三工资算多了5000元，于是回滚了事务，修改了金额后将事务提交。最后张三实际到账的只有5000元。

- **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。	

  例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。

- **不可重复读（Unrepeatableread）:** 一次事务发生了两次读操作，两个读操作之间发生了另一个事务对数据修改操作，这时候第一次和第二次读到的数据不一致。

  *不可重复度关注点在数据更新和删除，通过**行级锁**可以实现可重复读的隔离级别。*

- **幻读（Phantom read）:** 幻读，指的是当某个事务在读取某个范围内的记录时，另外一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行。

  相对于不可重复读，幻读更关注其它事务的新增数据。通过行级锁可以避免不可重复读，但无法解决幻读的问题，想要解决幻读，只能通过Serializable隔离级别来实现。

**不可重复读和幻读区别：**

不可重复读的重点是修改比如多次读取一条记录发现其中某些列的值被修改，幻读的重点在于新增或者删除比如多次读取一条记录发现记录增多或减少了。

### 事务隔离级别有哪些?MySQL的默认隔离级别是?

**SQL 标准定义了四个隔离级别：**

- **READ-UNCOMMITTED(读取未提交)：**  MySQL 事务隔离其实是依靠锁来实现的，加锁自然会带来性能的损失。而读未提交隔离级别是不加锁的，所以它的性能是最好的，没有加锁、解锁带来的性能开销。但有利就有弊，这基本上就相当于裸奔啊，所以它连脏读的问题都没办法解决   。

- **READ-COMMITTED(读取已提交)：**（ **Oracle默认隔离级别**）既然读未提交没办法解决脏数据问题，那么就有了读提交。读提交就是一个事务只能读到其他事务已经提交过的数据，也就是其他事务调用 commit 命令之后的数据。那脏数据问题迎刃而解了。
- **REPEATABLE-READ(可重复读)：**（**InnoDB默认隔离级别**） 事务不会读到其他事务对已有数据的修改，即使其他事务已提交，也就是说，事务开始时读到的已有数据是什么，在事务提交前的任意时刻，这些数据的值都是一样的。但是，对于其他事务新插入的数据是可以读到的，这也就引发了幻读问题。 
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。性能很低，谨慎使用。

------

|     隔离级别     | 脏读 | 不可重复读 | 幻影读 |
| :--------------: | :--: | :--------: | :----: |
| READ-UNCOMMITTED |  √   |     √      |   √    |
|  READ-COMMITTED  |  ×   |     √      |   √    |
| REPEATABLE-READ  |  ×   |     ×      |   √    |
|   SERIALIZABLE   |  ×   |     ×      |   ×    |

MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。



这里需要注意的是：与 SQL 标准不同的地方在于 InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 
事务隔离级别下使用的是Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统(如 SQL Server)
是不同的。所以说InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** 已经可以完全保证事务的隔离性要求，即达到了 SQL标准的 **SERIALIZABLE(可串行化)** 隔离级别。因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是 **READ-COMMITTED(读取提交内容)** ，但是你要知道的是InnoDB 存储引擎默认使用 **REPEAaTABLE-READ（可重读）** 并不会有任何性能损失。

InnoDB 存储引擎在 **分布式事务** 的情况下一般会用到 **SERIALIZABLE(可串行化)** 隔离级别。

## MVCC

MVCC，（Multi-Version Concurrency Control）即多版本并发控制。

MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。

#### 什么是当前读和快照读？

>  在学习MVCC多版本并发控制之前，我们必须先了解一下，什么是MySQL InnoDB下的当前读和快照读? 

- **当前读**

像select lock in share mode(共享锁), select for update ; update, insert ,delete(排他锁)这些操作都是一种当前读，它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁

- **快照读**

像不加锁的select操作就是快照读，即不加锁的非阻塞读；快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；之所以出现快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，即MVCC,可以认为MVCC是行锁的一个变种，但它在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本

>  说白了**MVCC就是为了实现读-写冲突不加锁**，而这个读指的就是**快照读**, 而非当前读，当**前读实际上是一种加锁的操作，是悲观锁的实现** 

#### 当前读，快照读和MVCC的关系

> 当前读，快照读和MVCC之间是什么关系呢？

- 准确的说，MVCC多版本并发控制指的是 “维持一个数据的多个版本，使得读写操作没有冲突” 这么一个概念。仅仅是一个理想概念
- 而在MySQL中，实现这么一个MVCC理想概念，我们就需要MySQL提供具体的功能去实现它，而快照读就是MySQL为我们实现MVCC理想模型的其中一个具体非阻塞读功能。而相对而言，当前读就是悲观锁的具体功能实现
- 要说的再细致一些，快照读本身也是一个抽象概念，再深入研究。MVCC模型在MySQL中的具体实现则是由 **4个隐式字段**，**undo日志** ，**Read View** 等去完成的，具体可以看下面的MVCC实现原理

#### MVCC能解决什么问题，好处是？

#### 数据库并发场景?

有三种, 分别为：

- **读-读**：不存在任何问题，也不需要并发控制
- **读-写**：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
- **写-写**：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

#### MVCC工作过程

InnoDB的MVCC，是通过在每行纪录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建版本号，一个保存了行的删除版本号。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行纪录的版本号进行比较。在REPEATABLE READ隔离级别下，MVCC具体的操作如下：

**undo log**
在不考虑redo log 的情况下利用undo log工作的简化过程为：

![img](https://pic2.zhimg.com/80/v2-7648358eb02dc2771bc654f5d79415e7_720w.jpg)

1）为了保证数据的持久性数据要在事务提交之前持久化
2）undo log的持久化必须在在数据持久化之前，这样才能保证系统崩溃时，可以用undo log来回滚事务


**Innodb中的隐藏列**

Innodb通过undo log保存了已更改行的旧版本的信息的快照。
InnoDB的内部实现中为每一行数据增加了三个隐藏列用于实现MVCC。

![img](https://pic1.zhimg.com/80/v2-a663705bc898674ead75d30acc253624_720w.jpg)


***SELECT\***

InnoDB会根据以下两个条件检查每行纪录：

1. InnoDB只查找版本早于当前事务版本的数据行，即，行的系统版本号小于或等于事务的系统版本号，这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。
2. 行的删除版本，要么未定义，要么大于当前事务版本号。这样可以确保事务读取到的行，在事务开始之前未被删除。

只有符合上述两个条件的纪录，才能作为查询结果返回。

***INSERT\***

InnoDB为插入的每一行保存当前系统版本号作为行版本号。

***DELETE\***

InnoDB为删除的每一行保存当前系统版本号作为行删除标识。

***UPDATE\***

InnoDB为插入一行新纪录，保存当前系统版本号作为行版本号，同时，保存当前系统版本号到原来的行作为行删除标识。

#### MVCC优缺点

**MVCC**带来的好处是？

多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。 所以MVCC可以为数据库解决以下问题

在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能 同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但不能解决更新丢失问题

MVCC在大多数情况下代替了行锁，实现了**对读的非阻塞**，读不加锁，读写不冲突。缺点是每行记录都需要额外的存储空间，需要做更多的行维护和检查工作。

**补充：**

1.MVCC手段只适用于Msyql隔离级别中的读已提交（Read committed）和可重复读（Repeatable Read）。

2.Read uncimmitted由于存在脏读，即能读到未提交事务的数据行，所以不适用MVCC.

原因是MVCC的创建版本和删除版本只要在事务提交后才会产生。

3.串行化由于是会对所涉及到的表加锁，并非行锁，自然也就不存在行的版本控制问题。

4.通过以上总结，可知，MVCC主要作用于事务性的，有行锁控制的数据库模型。

对MVCC的了解就先说这些（未完待续），后面会有对read view介绍。

## MySQL的两个引擎	

**MyISAM**

MyISAM是MySQL关系数据库管理系统的默认储存引擎(5.5之前)。这种MySQL表存储结构从旧的ISAM代码扩展 出许多有用的功能。在新版本的MySQL中，InnoDB引擎由于其对事务，参照完整性，以及更高的并发性等优点开始广泛的取代MyISAM。
每一个MyISAM表都对应于硬盘上的三个文件。这三个文件有一样的文件名，但是有不同的扩展名以指示其类型用途：.frm文件保存表的定义，但是这个文件并不是MyISAM引擎的一部分，而是服务器的一部分；.MYD保存表的数据；.MYI是表的索引文件。

**InnoDB**

InnoDB是一个事务型的存储引擎，支持回滚，设计目标是处理大数量数据时提供高性能的服务，它在运行时会在内存中建立缓冲池，用于缓冲数据和索引。

优点

```
1、支持事务处理、ACID事务特性；

2、实现了SQL标准的四种隔离级别；

3、支持行级锁和外键约束；

4、可以利用事务日志进行数据恢复。

5、锁级别为行锁，行锁优点是适用于高并发的频繁表修改，高并发是性能优于 MyISAM。缺点是系统消耗较大。

6、索引不仅缓存自身，也缓存数据，相比 MyISAM 需要更大的内存。
```



InnoDB缺点

**因为它没有保存表的行数，当使用COUNT统计时会扫描全表。**

### MySQL事务四大特性

**1、原子性（Atomicity）**

　　原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

**2、一致性（Consistency）**

　　一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。
　　拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。

**3、隔离性（Isolation）**

　　隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。
　　即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。

**4、持久性（Durability）**

　　持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。
　　例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，
即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。



![在这里插入图片描述](https://img-blog.csdnimg.cn/20190902085808644.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM3NDMyMTc0,size_16,color_FFFFFF,t_70)



**1、脏读：一个事务可以读取另一个未提交事务的数据。需要注意的是这里针对的是数据本身，可以理解为针对单笔数据。**



**2、不可重复读：一个事务进行读取，分别读取到了不同的数据。需要注意的是这里针对的是数据本身，可以理解为针对单笔数据，重点是对数据的修改和删除，所以对行加锁就可以解决。**



**3、幻读：一个事务进行读取，分别读取到了不同的数据。需要注意的是这里针对的是数据条数，可以理解为针对多笔数据是个数据集，重点是对数据的新增，所以对表加锁就可以解决。**



### 几种语句（DDL，DML，DCL）

**DDL（Data Definition Languages）语句：**数据定义语言，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象的定义。常用的语句关键字主要包括 **create、drop、alter**等。

**DML（Data Manipulation Language）语句：**数据操纵语句，用于添加、删除、更新和查询数据库记录，并检查数据完整性，常用的语句关键字主要包括 **insert、delete、udpate 和select 等。(增添改查）**

**DCL（Data Control Language）语句：**数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的语句关键字包括 **grant、revoke** 等。

### 左、右、内链接

　　left join （**左连接**）：返回包括左表中的所有记录  和  右表中连接字段相等的记录。
　　right join （**右连接**）：返回包括右表中的所有记录和左表中连接字段相等的记录。
　　inner join （等值连接或者叫**内连接**）：只返回两个表中连接字段相等的行。
　　full join （**全外连接**）：返回左右表中所有的记录和左右表中连接字段相等的记录。

##### 内联

如果想把用户信息、积分、等级都列出来，那么一般会这样写： **select * from T1, T3 where T1.userid = T3.userid** 

（其实这样的结果等同于**select * from T1 inner join T3 on T1.userid=T3.userid** ）。

 把两个表中都存在userid的行拼成一行（即内联），但后者的效率会比前者高很多，建议用后者（内联）的写法。 

SQL语句： select * from T1 **inner join** T2 on T1.userid = T2.userid

##### 左连

**显示左表T1中的所有行，并把右表T2中符合条件加到左表T1中**； 右表T2中不符合条件，就不用加入结果表中，并且NULL表示。 

SQL语句： select * from T1 **left outer join** T2 on T1.userid = T2.userid

##### 右连

**显示右表T2中的所有行，并把左表T1中符合条件加到右表T2中；** 左表T1中不符合条件，就不用加入结果表中，并且NULL表示。 SQL语句： select * from T1 **right outer join** T2 on T1.userid = T2.userid

##### 全连接

**显示左表T1、右表T2两边中的所有行，即把左联结果表 + 右联结果表组合在一起，然后过滤掉重复的**。 SQL语句：

 select * from T1 **full outer join** T2 on T1.userid = T2.userid







## MySQL性能优化

### 使用 Explain 进行分析

Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

比较重要的字段有:

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 扫描的行数

### 优化数据访问

#### 1. 减少请求的数据量

- 只返回必要的列: 最好不要使用 SELECT * 语句。
- 只返回必要的行: 使用 LIMIT 语句来限制返回的数据。
- 缓存重复查询的数据: 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。

#### 2. 减少服务器端扫描的行数

最有效的方式是使用索引来覆盖查询。

### 重构查询方式

#### 1. 切分大查询

一个大查询如果一次性执行的话，可能一次锁住很多数据、占满整个事务日志、耗尽系统资源、阻塞很多小的但重要的查询。

```sql
DELEFT FROM messages WHERE create < DATE_SUB(NOW(), INTERVAL 3 MONTH);
```

```sql
rows_affected = 0
do {
    rows_affected = do_query(
    "DELETE FROM messages WHERE create  < DATE_SUB(NOW(), INTERVAL 3 MONTH) LIMIT 10000")
} while rows_affected > 0
```

#### 2. 分解大连接查询

将一个大连接查询分解成对每一个表进行一次单表查询，然后将结果在应用程序中进行关联，这样做的好处有:

- 让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
- 分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记录的查询。
- 减少锁竞争；
- 在应用层进行连接，可以更容易对数据库进行拆分，从而更容易做到高性能和可伸缩。
- 查询本身效率也可能会有所提升。例如下面的例子中，使用 IN() 代替连接查询，可以让 MySQL 按照 ID 顺序进行查询，这可能比随机的连接要更高效。

```sql
SELECT * FROM tab
JOIN tag_post ON tag_post.tag_id=tag.id
JOIN post ON tag_post.post_id=post.id
WHERE tag.tag='mysql';
```

```sql
SELECT * FROM tag WHERE tag='mysql';
SELECT * FROM tag_post WHERE tag_id=1234;
SELECT * FROM post WHERE post.id IN (123,456,567,9098,8904);
```

## MySQL锁机制

[MySQL的锁机制和加锁原理](https://blog.csdn.net/qq_38238296/article/details/88362999)

首先对mysql锁进行划分：

- 基于锁的粒度划分：==行锁、表锁、页锁==
- 按照锁的使用方式划分：==共享锁、排它锁==（悲观锁的一种实现）
- 还有两种思想上的锁：==悲观锁、乐观锁==
- InnoDB中有几种行级锁的类型：`Record Lock`(在索引记录上加锁)、`Gap Lock`(间隙锁)、`Next-key Lock`(Record Lock + Gap Lock)

### 基于Mysql的分布式锁（基于表记录）

- 要实现分布式锁，最简单的方式可能就是直接创建一张锁表，然后通过操作该表中的数据来实现了。当我们想要获得锁的时候，就可以在该表中增加一条记录，想要释放锁的时候就删除这条记录

### 乐观锁和悲观锁

 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。

 无论是悲观锁还是乐观锁，都是人们定义出来的概念，可以认为是一种思想。其实不仅仅是关系型数据库系统中有乐观锁和悲观锁的概念，像memcache、hibernate、tair等都有类似的概念。

 针对于不同的业务场景，应该选用不同的并发控制方式。所以，不要把乐观并发控制和悲观并发控制狭义的理解为DBMS中的概念，更不要把他们和数据中提供的锁机制（行锁、表锁、排他锁、共享锁）混为一谈。其实，在DBMS中，悲观锁正是利用数据库本身提供的锁机制来实现的。

#### 乐观锁

- 顾名思义，系统认为数据的更新在大多数情况下是不会产生冲突的，只在数据库更新操作提交的时候才对数据作冲突检测。如果检测的结果出现了与预期数据不一致的情况，则返回失败信息。（适用于读操作较多的情况）

  乐观锁大多数是基于数据版本(version)的记录机制实现的。何谓数据版本号？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表添加一个 “version”字段来实现读取出数据时，将此版本号一同读出，之后更新时，对此版本号加1。在更新过程中，会对版本号进行比较，如果是一致的，没有发生改变，则会成功执行本次操作；如果版本号不一致，则会更新失败。（借助更新时间戳也可以，类似版本号）

- ==优点：==由于在检测数据冲突时并不依赖数据库本身的锁机制，不会影响请求的性能，当产生并发且并发量较小的时候只有少部分请求会失败。

- ==缺点：==需要对表的设计增加额外的字段，增加了数据库的冗余，另外，当应用并发量高的时候，version值在频繁变化，则会导致大量请求失败，影响系统的可用性。我们通过上述sql语句还可以看到，数据库锁都是作用于同一行数据记录上，这就导致一个明显的缺点，在一些特殊场景，如大促、秒杀等活动开展的时候，大量的请求同时请求同一条记录的行锁，会对数据库产生很大的写压力。所以综合数据库乐观锁的优缺点，乐观锁比较适合并发量不高，并且写操作不频繁的场景。

#### 悲观锁

- ==定义：==借助数据库中自带的锁来实现分布式锁。在查询语句后面增加FOR UPDATE，数据库会在查询过程中给数据库表增加悲观锁，也称排他锁。当某条记录被加上悲观锁之后，其它线程也就无法再改行上增加悲观锁。

  悲观锁，与乐观锁相反，总是假设最坏的情况，它认为数据的更新在大多数情况下是会产生冲突的。

- 在悲观锁中，每一次行数据的访问都是独占的，只有当正在访问该行数据的请求事务提交以后，其他请求才能依次访问该数据，否则将阻塞等待锁的获取。

- 悲观锁可以严格保证数据访问的安全。但是==缺点==也明显，即每次请求都会额外产生加锁的开销且未获取到锁的请求将会阻塞等待锁的获取，在高并发环境下，容易造成大量请求阻塞，影响系统可用性。另外，悲观锁使用不当还可能产生死锁的情况

### 表级锁，行级锁，页面锁

相对其他数据库而言，MySQL的锁机制比较简单，其最 显著的特点是不同的存储引擎支持不同的锁机制。比如，MyISAM和MEMORY存储引擎采用的是==表级锁（table-level locking）==；BDB存储引擎采用的是==页面锁（page-level locking）==，但也支持表级锁；==InnoDB存储==引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。
**表级锁：**开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
**行级锁：**开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
**页面锁：**开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般
从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适！仅从锁的角度 来说：表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有 并发查询的应用，如一些在线事务处理（OLTP）系统。

#### 行锁

行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。**行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。有可能会出现死锁的情况。** 行级锁按照使用方式分为共享锁和排他锁。

==共享锁用法（S锁 读锁）：==

 若事务T对数据对象A加上S锁，则事务T可以读A但不能修改A，其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。

```mysql
select ... lock in share mode;
```

共享锁就是允许多个线程同时获取一个锁，一个锁可以同时被多个线程拥有。

==排它锁用法（X 锁 写锁）：==

 若事务T对数据对象A加上X锁，事务T可以读A也可以修改A，其他事务不能再对A加任何锁，直到T释放A上的锁。这保证了其他事务在T释放A上的锁之前不能再读取和修改A。

```mysql
select ... for update
```

排它锁，也称作独占锁，一个锁在某一时刻只能被一个线程占有，其它线程必须等待锁被释放之后才可能获取到锁。

##### Record Lock记录锁

 单条索引上加锁，record lock 永远锁的是==索引==，而非数据本身，如果innodb表中没有索引，那么会自动创建一个隐藏的聚集索引，锁住的就是这个聚集索引。所以说当一条sql没有走任何索引时，那么将会在每一条聚集索引后面加X锁，这个类似于表锁，但原理上和表锁应该是完全不同的。

##### Gap Lock间隙锁

间隙锁，是在索引的间隙之间加上锁，这是为什么Repeatable Read隔离级别下能防止幻读的主要原因。

- 什么是间隙锁

当我们采用范围条件查询数据时，InnoDB 会对这个范围内的数据进行加锁。比如有 id 为：1、3、5、7 的 4 条数据，我们查找 1-7 范围的数据。那么 1-7 都会被加上锁。2、4、6 也在 1-7 的范围中，但是不存在这些数据记录，这些 2、4、6 就被称为间隙。

- 间隙锁的危害

范围查找时，会把整个范围的数据全部锁定住，即便这个范围内不存在的一些数据，也会被无辜的锁定住，比如我要在 1、3、5、7 中插入 2，这个时候 1-7 都被锁定住了，根本无法插入 2。在某些场景下会对性能产生很大的影响

##### NextKey临界锁

这个锁机制其实就是前面两个锁相结合的机制，既锁住记录本身还锁住索引之间的间隙。

#### 表级锁

MySQL的表级锁有两种模式：==表共享读锁（Table Read Lock）==和表独占写锁==（Table Write Lock）==。
对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；对 MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；MyISAM表的读操作与写操作之间，以及写操作之间是串行的！根据如表20-2所示的 例子可以知道，当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。

表级锁是mysql锁中粒度最大的一种锁，表示当前的操作对整张表加锁，资源开销比行锁少，不会出现死锁的情况，但是发生锁冲突的概率很大。被大部分的mysql引擎支持，MyISAM和InnoDB都支持表级锁，但是InnoDB默认的是行级锁。

共享锁用法：

```mysql
LOCK TABLE table_name [ AS alias_name ] READ
```

排它锁用法：

```mysql
LOCK TABLE table_name [AS alias_name][ LOW_PRIORITY ] WRITE
```

解锁用法：

```mysql
unlock tables;
```

#### 页锁

 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁

## MySql日志

#### [MySQL中常见的几种日志](https://zhuanlan.zhihu.com/p/150105821?from_voters_page=true)

#### 重做日志redo log

确保事务的持久性，防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性

redo log通常是物理日志，记录的是数据页的物理修改，而不是某一行或某几行修改成怎样怎样，它用来恢复提交后的物理数据页（恢复数据页，且只能恢复到最后一次提交的位置）

和大多数关系型数据库一样，InnoDB 记录了对数据文件的物理更改，并保证总是日志先行，也就是所谓的 WAL，即在持久化数据文件前，保证之前的 redo 日志已经写到磁盘。由于 redo log 是顺序整块写入，所以性能要更好。

重做日志两部分组成：一是内存中的重做日志缓冲(redo log buffer)，是易失的；二是重做日志文件(redo log file)，是持久的。redo log 记录事务操作的变化，记录的是数据修改之后的值，不管事务是否提交都会记录下来。

#### 回滚日志 undo log

保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也叫非锁定读

undo log一般是逻辑日志，根据每行记录进行记录。

undo log 有两个作用：提供回滚和多版本并发控制下的读(MVCC)，也即非锁定读

在数据修改的时候，不仅记录了redo，还记录了相对应的 undo，如果因为某些原因导致事务失败或回滚了，可以借助该 undo 进行回滚。

undo log 和 redo log 记录物理日志不一样，它是逻辑日志。可以认为当 delete 一条记录时，undo log 中会记录一条对应的 insert 记录，反之亦然，当 update 一条记录时，它记录一条对应相反的 update 记录。

有时候应用到行版本控制的时候，也是通过 undo log 来实现的：当读取的某一行被其他事务锁定时，它可以从 undo log 中分析出该行记录以前的数据是什么，从而提供该行版本信息，让用户实现非锁定一致性读取。

undo log 是采用段(segment)的方式来记录的，每个 undo 操作在记录的时候占用一个 undo log segment**。**

另外，undo log 也会产生 redo log，因为 undo log 也要实现持久性保护。

当事务提交的时候，InnoDB 不会立即删除 undo log，因为后续还可能会用到 undo log，如隔离级别为 repeatable read 时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即 undo log 不能删除。

当事务提交之后，undo log 并不能立马被删除，而是放入待清理的链表，由 purge 线程判断是否有其他事务在使用 undo 段中表的上一个事务之前的版本信息，决定是否可以清理 undo log 的日志空间。

在 MySQL 5.7 之前，undo log 存储在共享表空间中，因此有可能大大增加表空间的占用，5.7 之后可以通过配置选择存储在独立的表空间中。

#### 二进制日志bin log

最早接触 binlog 是做数据库主从同步的时候，知道是通过同步 binlog 实现的。binlog 是 没有 MySQL sever 层维护的一种二进制日志，与 innodb 引擎中的 redo/undo log 是完全不同的日志。其主要是用来记录对 MySQL 数据更新或潜在发生更新的 SQL 语句，并以 “事务”的形式保存在磁盘中。

用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。

用于数据库的基于时间点的还原。

**binlog主要有以下作用：**

- 复制：MySQL主从复制在Master端开启binlog,Master把它的二进制日志传给slaves并回放来达到master-slave数据一致的目的
- 数据恢复：通过mysqlbinlog工具恢复数据
- 增量备份

**几个知识点：**

- binlog不会记录不修改数据的语句，比如==select==或者==show==
- binlog会重写日志中的密码，保证不以纯文本的形式出现
- MySQL8之后的版本对binlog进行加密
- 具体的写入时间：在事务提交的时候，数据库会把==binlog cache==写入==binlog==文件中，但并没有执行`fsync()`操作，即只将文件内容写入到 OS 缓存中。随后根据配置判断是否执行 fsync。
- 删除时间：保持时间由参数`expire_logs_days`配置，也就是说对于非活动的日志文件，在生成时间超过`expire_logs_days`配置的天数之后，会被自动删除。

#### 三种日志总结

首先InnoDB完成一次更新操作的具体步骤：

1. 开启事务
2. 查询待更新的记录到内存，并加X锁
3. 记录undo log到内存buffer
4. 记录redo log到内存buffer
5. 更改内存中的数据记录
6. 提交记录，触发redo log刷盘
7. 记录bin log
8. 事务结束

#### 错误日志error log

在MySQL数据库中，错误日志功能是默认开启的，而且无法被关闭。默认情况，错误日志存储在mysql数据库的数据文件中。错误日志文件通常的名称为hostname.err（hostname表示服务器的主机名）。

错误日志可以**自己配置**，错误日志可以通过log-error和log-warnings来定义，其中log-error：配置是否启用错误日志功能和错误日志的存储位置？log-warning：配置是否将警告信息也定义至错误日志中？

**错误日志记录信息：**服务器启动关闭信息、运行错误信息、时间调度器运行一个事件时产生的信息、在服务器上启动进程产生的信息。

#### 慢查询日志slow query log

#### 一般查询日志general log

#### 中继日志relay log



## 一条SQL语句执行得很慢的原因有哪些

这个可以分情况讨论

**1、大多数情况是正常的，只是偶尔会出现很慢的情况。**

**2、在数据量不变的情况下，这条SQL语句一直以来都执行的很慢。**

##### 一、针对偶尔很慢的情况

一条 SQL 大多数情况正常，偶尔才能出现很慢的情况，针对这种情况，我觉得这条SQL语句的书写本身是没什么问题的，而是其他原因导致的，那会是什么原因呢？

###### 1、数据库在刷新脏页（flush）

当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在**内存**中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到**磁盘**中去，而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到**磁盘**中去。

> 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

**刷脏页有下面4种场景（后两种不用太关注“性能”问题）：**

- **redolog写满了：**redo log 里的容量是有限的，如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，**就会导致我们平时正常的SQL语句突然执行的很慢**，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。
- **内存不够用了：**如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页。
- **MySQL 认为系统“空闲”的时候：**这时系统没什么压力。
- **MySQL 正常关闭的时候：**这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

###### 2、拿不到锁我能怎么办

这个就比较容易想到了，我们要执行的这条语句，刚好这条语句涉及到的**表**，别人在用，并且加锁了，我们拿不到锁，只能慢慢等待别人释放锁了。或者，表没有加锁，但要使用到的某个一行被加锁了，这个时候，我也没办法啊。

如果要判断是否真的在等待锁，我们可以用 **show processlist**这个命令来查看当前的状态哦，这里我要提醒一下，有些命令最好记录一下，反正，我被问了好几个命令，都不知道怎么写，呵呵。

下来我们来访分析下第二种情况，我觉得第二种情况的分析才是最重要的

##### 二、针对一直都这么慢的情况

如果在数据量一样大的情况下，这条 SQL 语句每次都执行的这么慢，那就就要好好考虑下你的 SQL 书写了，下面我们来分析下哪些原因会导致我们的 SQL 语句执行的很不理想。

我们先来假设我们有一个表，表里有下面两个字段,分别是主键 id，和两个普通字段 c 和 d。

```
mysql> CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;
```

###### 1、扎心了，没用到索引

没有用上索引，我觉得这个原因是很多人都能想到的，例如你要查询这条语句

```
select * from t where 100 <c and c < 100000;
```

**（1）、字段没有索引**

刚好你的 c 字段上没有索引，那么抱歉，只能走全表扫描了，你就体验不会索引带来的乐趣了，所以，这回导致这条查询语句很慢。

**（2）、字段有索引，但却没有用索引**

好吧，这个时候你给 c 这个字段加上了索引，然后又查询了一条语句

```
select * from t where c - 1 = 1000;
```

我想问大家一个问题，这样子在查询的时候会用索引查询吗？

答是不会，如果我们在字段的左边做了运算，那么很抱歉，在查询的时候，就不会用上索引了，所以呢，大家要注意这种**字段上有索引，但由于自己的疏忽，导致系统没有使用索引**的情况了。

正确的查询应该如下

```
select * from t where c = 1000 + 1;
```

有人可能会说，右边有运算就能用上索引？难道数据库就不会自动帮我们优化一下，自动把 c - 1=1000 自动转换为 c = 1000+1。

不好意思，确实不会帮你，所以，你要注意了。

**（3）、函数操作导致没有用上索引**

如果我们在查询的时候，对字段进行了函数操作，也是会导致没有用上索引的，例如

```
select * from t where pow(c,2) = 1000;
```

这里我只是做一个例子，假设函数 pow 是求 c 的 n 次方，实际上可能并没有 pow(c,2)这个函数。其实这个和上面在左边做运算也是很类似的。

所以呢，一条语句执行都很慢的时候，可能是该语句没有用上索引了，不过具体是啥原因导致没有用上索引的呢，你就要会分析了，我上面列举的三个原因，应该是出现的比较多的吧。

###### 2、呵呵，数据库自己选错索引了

我们在进行查询操作的时候，例如

```
select * from t where 100 < c and c < 100000;
```

我们知道，主键索引和非主键索引是有区别的，主键索引存放的值是**整行字段的数据**，而非主键索引上存放的值不是整行字段的数据，而且存放**主键字段的值**。不大懂的可以看这篇文章： [【思维导图-索引篇】搞定数据库索引就是这么简单](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247484848&idx=1&sn=77a0e6e82944ec385f5df17e91ce3bf2&chksm=cea24a7bf9d5c36d4b289cccb017292f9f36da9f3c887fd2b93ecd6af021fcf30121ba09799f&token=1082669959&lang=zh_CN&scene=21#wechat_redirect) 里面有说到主键索引和非主键索引的区别

也就是说，我们如果走 c 这个字段的索引的话，最后会查询到对应主键的值，然后，再根据主键的值走主键索引，查询到整行数据返回。

好吧扯了这么多，其实我就是想告诉你，就算你在 c 字段上有索引，系统也并不一定会走 c 这个字段上的索引，而是有可能会直接扫描扫描全表，找出所有符合 100 < c and c < 100000 的数据。

## 一条select查询流程

![image-20220316171706356](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220316171708.png)

连接器

　　我们和数据库进行交互的话，首先要进行连接。服务端校验账号密码无误后，就意味着一个用户成功建立连接，可以进行各种操作了。在连接的过程中，账号权限发生了改变也是感知不到的，必须重新连接才能获取账号最新权限。

缓存

　　建立完连接后，现在执行select就来到了第二步:查询缓存，就是以sql为key，去内存中查询结果，如果能够在缓存中找到 value，就会直接返回给客户端。如果不在缓存中，就继续往后执行，然后将结果存在内存中。不过考虑到时效性，查询mysql缓存并不是一个比较好的方案，所以在mysql8.0+直接把 缓存模板 给删掉了。

解析器

　　如果没有命中缓存，就要开始真正执行语句了。首先会讲我们输入的字符串进行“词法解析” 识别出 表名和字段 ；然后进行 “语法分析” 看看是否符合sql语法规范。

优化器

　　前面识别完语法后，现在mysql就要对你的sql进行预处理了，比如你的sql有多个索引，用哪个比较好；比如关联查询表的连接顺序、以哪个做驱动表比较好。

执行器

　　现在离正真执行sql就差临门一脚了。他会判断你对表有没有操作权限。然后权限就直接返回异常提示；[有权限就会交给引擎去执行了。](https://www.cnblogs.com/wlwl/p/9465583.html)



# Redis

### 为什么要用 redis/为什么要用缓存

主要从“高性能”和“高并发”这两点来看待这个问题。

**高性能：**

假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！

**高并发：**

直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

### 为什么redis的zset用跳表不用红黑树

共同点：两者**插入删除，删除，查找以及迭代输出**时间复杂度红黑树和跳表的时间复杂度是一样的

跳表在区间查询的时候效率是高于红黑树的，跳表进行查找O(logn)的时间复杂度定位到区间的起点，然后在原始链表往后遍历就可以了 ，其他插入和单个条件查询，更新两者的复杂度都是相同的O(logn)
跳表的代码实现相对于红黑树更容易实现，
跳表更加灵活，他可以通过改变索引构建策略，有效平衡执行效率和内存消耗。（红黑树的平衡是通过左旋转和有旋转来进行平衡）

### redis 的线程模型

> 参考地址:https://www.javazhiyin.com/22943.html

redis 内部使用文件事件处理器 `file event handler`，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- 多个 socket
- IO 多路复用程序
- 文件事件分派器
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。


###  redis 和 memcached 的区别

对于 redis 和 memcached 我总结了下面四点。现在公司一般都是用 redis 来实现缓存，而且 redis 自身也越来越强大了！

1. **redis支持更丰富的数据类型（支持更复杂的应用场景）**：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。memcache支持简单的数据类型，String。
2. **Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而Memecache把数据全部存在内存之中。**
3. **集群模式**：memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.
4. **Memcached是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。**


> 来自网络上的一张图，这里分享给大家！

![redis 和 memcached 的区别](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-24/61603179.jpg)



### Redis操作多个key

- 原生命令mset,mget，具有原子性

- pipeline:使用pipeline的命令个数不能太多，不然数据量过大，增加客户端的等待时间，可能会网络堵塞，可以将大量命令的拆分多个小的pipeline命令来完成。通过redis事务保证原子性。

  步骤：

  - 获取Jedis对象（一般从连接池中获取）
  - 获取Jedis对象的pipeline对象
  - 添加指令
  - 执行指令

### redis分布式锁实现原理redlock

抽奖，统计奖品数量，保证一个人抽到以后其他人能看到数量-1

#### 特性

Redis 官方站这篇文章提出了一种权威的基于 Redis 实现分布式锁的方式名叫 Redlock，此种方式比原先的单节点的方法更安全。

<!-- more -->

它可以保证以下特性：

1. 安全特性：互斥访问，即永远只有一个 client 能拿到锁
2. 避免死锁：最终 client 都可能拿到锁，不会出现死锁的情况，即使原本锁住某资源的 client crash 了或者出现了网络分区
3. 容错性：只要大部分 Redis 节点存活就可以正常提供服务

#### 怎么在单节点上实现分布式锁

> SET resource_name my_random_value NX PX 30000

主要依靠上述命令NX，该命令仅当 Key 不存在时（NX保证）set 值，并且设置过期时间 3000ms （PX保证），值 my_random_value 必须是所有 client 和所有锁请求发生期间唯一的，释放锁的逻辑是：

```lua
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

上述实现可以避免释放另一个client创建的锁，如果只有 del 命令的话，那么如果 client1 拿到 lock1 之后因为某些操作阻塞了很长时间，此时 Redis 端 lock1 已经过期了并且已经被重新分配给了 client2，那么 client1 此时再去释放这把锁就会造成 client2 原本获取到的锁被 client1 无故释放了，但现在为每个 client 分配一个 unique 的 string 值可以避免这个问题。至于如何去生成这个 unique string，方法很多随意选择一种就行了。

#### Redlock 算法

算法很易懂，起 5 个 master 节点，分布在不同的机房尽量保证可用性。为了获得锁，client 会进行如下操作：

1. 得到当前的时间，微秒单位
2. 尝试顺序地在 5 个实例上申请锁，当然需要使用相同的 key 和 random value，这里一个 client 需要合理设置与 master 节点沟通的 timeout 大小，避免长时间和一个 fail 了的节点浪费时间
3. 当 client 在大于等于 3 个 master 上成功申请到锁的时候，且它会计算申请锁消耗了多少时间，这部分消耗的时间采用获得锁的当下时间减去第一步获得的时间戳得到，如果锁的持续时长（lock validity time）比流逝的时间多的话，那么锁就真正获取到了。
4. 如果锁申请到了，那么锁真正的 lock validity time 应该是 origin（lock validity time） - 申请锁期间流逝的时间
5. 如果 client 申请锁失败了，那么它就会在少部分申请成功锁的 master 节点上执行释放锁的操作，重置状态

#### 失败重试

如果一个 client 申请锁失败了，那么它需要稍等一会在重试避免多个 client 同时申请锁的情况，最好的情况是一个 client 需要几乎同时向 5 个 master 发起锁申请。另外就是如果 client 申请锁失败了它需要尽快在它曾经申请到锁的 master 上执行 unlock 操作，便于其他 client 获得这把锁，避免这些锁过期造成的时间浪费，当然如果这时候网络分区使得 client 无法联系上这些 master，那么这种浪费就是不得不付出的代价了。

#### 放锁

放锁操作很简单，就是依次释放所有节点上的锁就行了

#### 性能、崩溃恢复和 fsync

如果我们的节点没有持久化机制，client 从 5 个 master 中的 3 个处获得了锁，然后其中一个重启了，这是注意 **整个环境中又出现了 3 个 master 可供另一个 client 申请同一把锁！** 违反了互斥性。如果我们开启了 AOF 持久化那么情况会稍微好转一些，因为 Redis 的过期机制是语义层面实现的，所以在 server 挂了的时候时间依旧在流逝，重启之后锁状态不会受到污染。但是考虑断电之后呢，AOF部分命令没来得及刷回磁盘直接丢失了，除非我们配置刷回策略为 fsnyc = always，但这会损伤性能。解决这个问题的方法是，当一个节点重启之后，我们规定在 max TTL 期间它是不可用的，这样它就不会干扰原本已经申请到的锁，等到它 crash 前的那部分锁都过期了，环境不存在历史锁了，那么再把这个节点加进来正常工作。

### redis缓存更新策略

1. LRU（最近最少使用，首先淘汰最长时间未被使用的页面）/LFU(最近不常用 淘汰一定时间内不常使用的页面)/FIFO(先进出去)算法的剔除：例如maxmemory-policy
2. 超时剔除：例如expire
3. 主动更新：开发控制生命周期

![image-20220316170501120](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220316170503.png)

低一致性：最大内存和淘汰策略

高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底

## Redis数据类型

string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。

**String（字符串）**

 String是redis中最基本的数据类型，一个key对应一个value。 

string 类型是二进制安全的。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。

string 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。

**实战场景**

- **缓存**：经典使用场景，把常用信息，字符串，图片或者视频等信息放到redis中，redis作为缓存层，mysql做持久化层，降低mysql的读写压力。
- **计数器**：redis是单线程模型，一个命令执行完才会执行下一个，同时数据可以一步落地到其他的数据源。
- **session**：常见方案spring session + redis实现session共享，

**List（列表）**

Redis中的List其实就是链表（Redis用双端链表实现List）。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。

**实战场景**

- **微博TimeLine**: 有人发布微博，用lpush加入时间轴，展示新的列表信息。
- **消息队列**

**Hash（哈希）**

Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。 

Redis hash 是一个键值(key=>value)对集合。

**实战场景**

- **缓存**： 能直观，相比string更节省空间，的维护缓存信息，如用户信息，视频信息等 

**Set（集合）**

Redis 的 Set 是 string 类型的无序集合， 集合中不能出现重复的数据 。

集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。

比如：在微博应用中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。

**实战场景**

- **标签**（tag）,给用户添加标签，或者用户给消息添加标签，这样有同一标签或者类似标签的可以给推荐关注的事或者关注的人。
- **点赞，或点踩，收藏等**，可以放到set中实现

**zset(sorted set：有序集合)**

Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。

zset的成员是唯一的,但分数(score)却可以重复。

**实战场景**

- **排行榜**：例如小说视频等网站需要对用户上传的小说视频做排行榜，榜单可以按照用户关注数，更新时间，字数等打分，做排行。

## 缓存模式

#### Cache-Aside

Chche-Aside是最广泛使用的缓存模式之一，如果能正确使用Cache-Aside的话，能极大的提升应用性能。Cache-Aside可用来读或写操作。

读操作

我们先来看下读操作的数据流：

- 1、程序接收数据查询的请求
- 2、程序检查要查询的数据是否在缓存上
  - 如果存在（cache hit），从缓存上查询出来
  - 如果不存在（cache miss），从数据库中检索数据并存入缓存中
- 3、程序返回要查询的数据

![image-20220316163902538](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220316163904.png)

在Spring中，可如下实现，当`getRecordForSearch()`方法被调用的时候，如果缓存中存在对应key的数据，那就会自动的从缓存中获取（此时方法体不会被执行），当缓存中不存在key对应数据的时候，会执行方法体从数据库中查询数据并设置到缓存中去。

```java
@Cacheable("default", key="#search.keyword)
public Record getRecordForSearch(Search search)
```

更新操作

如果程序需要更新数据库中的数据且该数据也在缓存上，此时缓存中的数据也需要做相应的处理。为了解决这个不同步的问题来确认数据的一致性和操作性能，有两个方式可按需使用。

- 缓存失效

该情况下，当请求需要更新数据库数据的时候，缓存中的值需要被删除掉（删除掉就表示旧值不可用了），当下次该key被再次查询到就去数据库中查出最新的数据，在Spring中可实现如下：

```java
@CacheEvict("default", key="#search.keyword)
public Record updateRecordForSearch(Search search)
```

- 缓存更新

缓存数据也可以在数据库更新的时候被更新，从而在一次操作中让之后的查询有更快的查询体验和更好的数据一致性，在Spring中可实现如下：

```java
@CachePut("default", key="#search.keyword)
public Record updateRecordForSearch(Search search)
```

**为了应对不用类型的数据需要，有以下缓存加载策略可被选择：**

- **使用时加载缓存**：当需要使用缓存数据时，就从数据库中把它查询出来，第一次查询之后，接下来的请求都能从缓存中查询到数据。
- **预加载缓存**：在项目启动的时候，预加载类似“国家信息、货币信息、用户信息，新闻信息”等不是经常变更的数据。

#### Read-Through

Read-Through和Cache-Aside相似，不同点在于程序不需要再去管理从哪去读数据（缓存还是数据库）。相反它会直接从缓存中读数据，该场景下是缓存去决定去哪查询数据。当我们比较两者的时候这是一个优势因为它会让程序代码变得更简洁。

![image-20220316163215511](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220316163225.png)

#### Write Through

`Write-Through`下所有的写操作都经过缓存，每次我们向缓存中写数据的时候，缓存会把数据持久化到对应的数据库中去，且这两个操作都在一个事务中完成。因此，只有两次都写成功了才是最终写成功了。这的确带来了一些写延迟但是它保证了数据一致性。

同时，因为程序只和缓存交互，编码会变得更加简单和整洁，当你需要在多处复用相同逻辑的时候这点变的格外明显。

![image-20220316163409000](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220316163411.png)

当使用`Write-Through`的时候一般都配合使用`Read-Through`。

`Write-Through`适用情况有：

- 需要频繁读取相同数据
- 不能忍受数据丢失（相对`Write-Behind`而言）和数据不一致

**`Write-Through`的潜在使用例子是银行系统。**

#### Write Behind

`Write-Behind`和`Write-Through`在“程序只和缓存交互且只能通过缓存写数据”这一点上很相似。不同点在于`Write-Through`会把数据立即写入数据库中，而`Write-Behind`会在一段时间之后（或是被其他方式触发）把数据一起写入数据库，这个异步写操作是`Write-Behind`的最大特点。

数据库写操作可以用不同的方式完成，其中一个方式就是收集所有的写操作并在某一时间点（比如数据库负载低的时候）批量写入。另一种方式就是合并几个写操作成为一个小批次操作，接着缓存收集写操作（比如5个）一起批量写入。

异步写操作极大的降低了请求延迟并减轻了数据库的负担。同时也放大了数据不一致的。比如有人此时直接从数据库中查询数据，但是更新的数据还未被写入数据库，此时查询到的数据就不是最新的数据。

## Redis事务

### Redis事务命令

![image-20210918110338308](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20210918110347.png)

## 过期策略

Redis中有个设置时间过期的功能，即对存储在 redis 数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如我们一般项目中的 token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。

我们 set key 的时候，都可以给一个 expire time，就是过期时间，通过过期时间我们可以指定这个 key 可以存活的时间。

如果假设你设置了一批 key 只能存活1个小时，那么接下来1小时后，redis是怎么对这批key进行删除的？

**定期删除+惰性删除。**

通过名字大概就能猜出这两个删除方式的意思了。

- **定期删除**：redis默认是每隔 100ms 就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？你想一想假如 redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载！
- **惰性删除** ：定期删除可能会导致很多过期 key 到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被redis给删除掉。这就是所谓的惰性删除，也是够懒的哈！


但是仅仅通过设置过期时间还是有问题的。我们想一下：如果定期删除漏掉了很多过期 key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？ **redis 内存淘汰机制。**

### redis 内存淘汰机制(MySQL里有2000w数据，Redis中只存20w的数据，如何保证Redis中的数据都是热点数据?)

redis 配置文件 redis.conf 中有相关注释，我这里就不贴了，大家可以自行查阅或者通过这个网址查看： [http://download.redis.io/redis-stable/redis.conf](http://download.redis.io/redis-stable/redis.conf)

**redis 提供 6种数据淘汰策略：**

1. **volatile-lru**（常见）：从已设置过期时间的数据集（server.db[i].expires）中挑选最近使用最少的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru**（常见）：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0版本后增加以下两种：

7. **volatile-lfu**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
8. **allkeys-lfu**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key

**备注： 关于 redis 设置过期时间以及内存淘汰机制，我这里只是简单的总结一下，后面会专门写一篇文章来总结！**



## 缓存穿透、缓存击穿和缓存雪崩

### 缓存穿透

缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。

如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

- **解决方案**

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
3. 布隆过滤器。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。布隆过滤器的关键就在于hash算法和容器大小。

### 缓存击穿

缓存击穿是指**缓存中没有但数据库中有的数据**（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

- **解决方案**

1、设置热点数据永远不过期。

2、接口限流与熔断，降级。重要的接口一定要做好限流策略，防止用户恶意刷接口，同时要降级准备，当接口中的某些服务不可用时候，进行熔断，失败快速返回机制。

3、加互斥锁

### 缓存雪崩

缓存雪崩是指缓存中**数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至宕机**。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 

**有哪些解决办法？**

（中华石杉老师在他的视频中提到过，视频地址在最后一个问题中有提到）：

- 事前：尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
- 事中：本地ehcache缓存 + hystrix限流&降级，避免MySQL崩掉
- 事后：利用 redis 持久化机制保存的数据尽快恢复缓存

![](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-9-25/6078367.jpg)

**解决方案**

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
3. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。

## 如何解决 Redis 的并发竞争 Key 问题

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对一个 key 进行操作，但是最后执行的顺序和我们期望的顺序不同，这样也就导致了结果的不同！

推荐一种方案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使用分布式锁，这样会影响性能）

基于zookeeper临时有序节点可以实现的分布式锁。大致思想为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。完成业务流程后，删除对应的子节点释放锁。

在实践中，当然是从以可靠性为主。所以首推Zookeeper。

## Redis和mysql数据一致性问题

1. 采用双删策略

   1. 先删除缓存
   2. 再写数据库
   3. 休眠500毫秒（根据具体的业务时间来定）
   4. 再次删除缓存

2. 设置缓存过期时间

   理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。

## Redis持久化

http://redisdoc.com/topic/persistence.html

**Redis 提供了多种不同级别的持久化方式：**

- RDB 持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。
- AOF 持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite），使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。
- Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。
- 你甚至可以关闭持久化功能，让数据只在服务器运行时存在。

了解 RDB 持久化和 AOF 持久化之间的异同是非常重要的， 以下几个小节将详细地介绍这这两种持久化功能， 并对它们的相同和不同之处进行说明。

### 快照RDB持久化

Redis可以通过创建[快照](snapshottin)来获得存储在内存里面的数据在某个时间点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构，主要用来提高Redis性能），还可以将快照留在原地以便重启服务器的时候使用。

**快照持久化是Redis默认采用的持久化方式**，在redis.conf配置文件中默认有此下配置：

```
save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。

save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。
```

根据配置，快照将被写入dbfilename选项指定的文件里面，并存储在dir选项指定的路径上面。如果在新的快照文件创建完毕之前，Redis、系统或者硬件这三者中的任意一个崩溃了，那么Redis将丢失最近一次创建快照写入的所有数据。

举个例子：假设Redis的上一个快照是2：35开始创建的，并且已经创建成功。下午3：06时，Redis又开始创建新的快照，并且在下午3：08快照创建完毕之前，有35个键进行了更新。如果在下午3：06到3：08期间，系统发生了崩溃，导致Redis无法完成新快照的创建工作，那么Redis将丢失下午2：35之后写入的所有数据。另一方面，如果系统恰好在新的快照文件创建完毕之后崩溃，那么Redis将丢失35个键的更新数据。

##### 创建快照的办法有如下几种：

- **BGSAVE命令：** 客户端向Redis发送 **BGSAVE命令** 来创建一个快照。对于支持BGSAVE命令的平台来说（基本上所有平台支持，除了Windows平台），Redis会调用fork来创建一个子进程，然后子进程负责将快照写入硬盘，而父进程则继续处理命令请求。
- **SAVE命令：** 客户端还可以向Redis发送 **SAVE命令** 来创建一个快照，接到SAVE命令的Redis服务器在快照创建完毕之前不会再响应任何其他命令。SAVE命令不常用，我们通常只会在没有足够内存去执行BGSAVE命令的情况下，又或者即使等待持久化操作执行完毕也无所谓的情况下，才会使用这个命令。
- **save选项：** 如果用户设置了save选项（一般会默认设置），比如 **save 60 10000**，那么从Redis最近一次创建快照之后开始算起，当“60秒之内有10000次写入”这个条件被满足时，Redis就会自动触发BGSAVE命令。
- **SHUTDOWN命令：**  当Redis通过SHUTDOWN命令接收到关闭服务器的请求时，或者接收到标准TERM信号时，会执行一个SAVE命令，阻塞所有客户端，不再执行客户端发送的任何命令，并在SAVE命令执行完毕之后关闭服务器。
- **一个Redis服务器连接到另一个Redis服务器：** 当一个Redis服务器连接到另一个Redis服务器，并向对方发送SYNC命令来开始一次复制操作的时候，如果主服务器目前没有执行BGSAVE操作，或者主服务器并非刚刚执行完BGSAVE操作，那么主服务器就会执行BGSAVE命令

##### RDB 的优点

- RDB 是一个非常紧凑（compact）的文件，它保存了 Redis 在某个时间点上的数据集。 这种文件非常适合用于进行备份： 比如说，你可以在最近的 24 小时内，每小时备份一次 RDB 文件，并且在每个月的每一天，也备份一个 RDB 文件。 这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。
- RDB 非常适用于灾难恢复（disaster recovery）：它只有一个文件，并且内容都非常紧凑，可以（在加密后）将它传送到别的数据中心，或者亚马逊 S3 中。
- RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 `fork` 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。
- RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

##### RDB 的缺点

- 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据。
- 每次保存 RDB 的时候，Redis 都要 `fork()` 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， `fork()` 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 `fork()` ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。

### AOF持久化

与快照持久化相比，[AOF持久化](append-only file) 的实时性更好，因此已成为主流的持久化方案。默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：

```
appendonly yes
```

开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof。

**在Redis的配置文件中存在三种同步方式，它们分别是：**

```
appendfsync always     #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度
appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘
appendfsync no      #让操作系统决定何时进行同步
```

**appendfsync always** 可以实现将数据丢失减到最少，不过这种方式需要对硬盘进行大量的写入而且每次只写入一个命令，十分影响Redis的速度。另外使用固态硬盘的用户谨慎使用appendfsync always选项，因为这会明显降低固态硬盘的使用寿命。

为了兼顾数据和写入性能，用户可以考虑 **appendfsync everysec选项** ，让Redis每秒同步一次AOF文件，Redis性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。


**appendfsync no**  选项一般不推荐，这种方案会使Redis丢失不定量的数据而且如果用户的硬盘处理写入操作的速度不够的话，那么当缓冲区被等待写入的数据填满时，Redis的写入操作将被阻塞，这会导致Redis的请求速度变慢。

**虽然AOF持久化非常灵活地提供了多种不同的选项来满足不同应用程序对数据安全的不同要求，但AOF持久化也有缺陷——AOF文件的体积太大。**

##### AOF 的优点

- 使用 AOF 持久化会让 Redis 变得非常耐久（much more durable）：你可以设置不同的 `fsync` 策略，比如无 `fsync` ，每秒钟一次 `fsync` ，或者每次执行写入命令时 `fsync` 。 AOF 的默认策略为每秒钟 `fsync` 一次，在这种配置下，Redis 仍然可以保持良好的性能，并且就算发生故障停机，也最多只会丢失一秒钟的数据（ `fsync` 会在后台线程执行，所以主线程可以继续努力地处理命令请求）。
- AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 `seek` ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， `redis-check-aof` 工具也可以轻易地修复这种问题。
- Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。
- AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 [FLUSHALL](http://redisdoc.com/database/flushall.html#flushall) 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 [FLUSHALL](http://redisdoc.com/database/flushall.html#flushall) 命令， 并重启 Redis ， 就可以将数据集恢复到 [FLUSHALL](http://redisdoc.com/database/flushall.html#flushall) 执行之前的状态。

##### AOF 的缺点

- 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。
- 根据所使用的 `fsync` 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 `fsync` 的性能依然非常高， 而关闭 `fsync` 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。
- AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样。 （举个例子，阻塞命令 [BRPOPLPUSH source destination timeout](http://redisdoc.com/list/brpoplpush.html#brpoplpush) 就曾经引起过这样的 bug 。） 测试套件里为这种情况添加了测试： 它们会自动生成随机的、复杂的数据集， 并通过重新载入这些数据来确保一切正常。 虽然这种 bug 在 AOF 文件中并不常见， 但是对比来说， RDB 几乎是不可能出现这种 bug 的。

##### 重写/压缩AOF

AOF虽然在某个角度可以将数据丢失降低到最小而且对性能影响也很小，但是极端的情况下，体积不断增大的AOF文件很可能会用完硬盘空间。另外，如果AOF体积过大，那么还原操作执行时间就可能会非常长。

为了解决AOF体积过大的问题，用户可以向Redis发送 **BGREWRITEAOF命令** ，这个命令会通过移除AOF文件中的冗余命令来重写（rewrite）AOF文件来减小AOF文件的体积。BGREWRITEAOF命令和BGSAVE创建快照原理十分相似，所以AOF文件重写也需要用到子进程，这样会导致性能问题和内存占用问题，和快照持久化一样。更糟糕的是，如果不加以控制的话，AOF文件的体积可能会比快照文件大好几倍。

**文件重写流程：**

![文件重写流程](https://user-gold-cdn.xitu.io/2018/6/13/163f97f9bd0eea50?w=380&h=345&f=jpeg&s=14501)
和快照持久化可以通过设置save选项来自动执行BGSAVE一样，AOF持久化也可以通过设置

```
auto-aof-rewrite-percentage
```

选项和

```
auto-aof-rewrite-min-size
```

选项自动执行BGREWRITEAOF命令。举例：假设用户对Redis设置了如下配置选项并且启用了AOF持久化。那么当AOF文件体积大于64mb，并且AOF的体积比上一次重写0之后的体积大了至少一倍（100%）的时候，Redis将执行BGREWRITEAOF命令。

```
auto-aof-rewrite-percentage 100  
auto-aof-rewrite-min-size 64mb
```

无论是AOF持久化还是快照持久化，将数据持久化到硬盘上都是非常有必要的，但除了进行持久化外，用户还必须对持久化得到的文件进行备份（最好是备份到不同的地方），这样才能尽量避免数据丢失事故发生。如果条件允许的话，最好能将快照文件和重新重写的AOF文件备份到不同的服务器上面。

随着负载量的上升，或者数据的完整性变得 越来越重要时，用户可能需要使用到复制特性。

### Redis 4.0 对于持久化机制的优化

Redis 4.0 开始支持 RDB 和 AOF 的**混合持久化**（默认关闭，可以通过配置项 `aof-use-rdb-preamble` 开启）。

如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分就是压缩格式不再是 AOF 格式，可读性较差。

## 缓存冷启动问题和缓存预热

缓存冷启动就是缓存中没有数据，由于缓存冷启动一点数据都没有，如果直接就对外提供服务了，那么并发量上来mysql就裸奔挂掉了。
因此需要通过缓存预热的方案，提前给 redis 灌入部分数据后再提供服务。

#### 缓存冷启动场景

系统第一次上线启动，或者系统在 redis 故障的情况下重新启动，这时在高并发的场景下就会出现所有的流量 都会打到 mysql（原始数据库） 上去，导致 mysql 崩溃。

- 新系统第一次上线，此时在缓存里是没有数据的。
- 系统在线上稳定运行着，但是突然redis 缓存崩了，而且不幸的是，数据全都无法找回来。

#### 缓存预热解决方案

##### 缓存预热问题

- 数据量太大的话，无法将所有数据放入 redis 中：耗费时间过长或 redis 根本无法容纳下所有的数据；
- 需要根据当天的具体访问情况，实时统计出访问频率较高的热数据；
- 将访问频率较高的热数据写入 redis 中，肯定数据也比较多， 我们也得多个服务并行读取数据去写，并行的分布式缓存预热。

##### 缓存预热大致思路

- nginx +lua 将访问流量上报到 kafka 中，统计出当前最新的实时的热数据，将商品详情页访问的请求对应的流量日志实时上报到 kafka 中；
- storm 从 kafka 中消费数据，实时统计访问次数；
- 访问次数基于 LRU 内存数据结构的存储方案。

由于storm中读写数据频繁，并且数据量大，需要采用LRU内存架构；这种场合不适合采用redis或mysql

- redis 可能会出现故障，会影响 storm 的稳定性；
- mysql扛不住高并发读写；
- hbase：hadoop 生态组合还是不错的，但是维护太重了；
  实际场景就是：统计出最近一段时间访问最频繁的商品，进行访问计数， 同时维护出一个前 N 个访问最多的商品 list 即可。
- 也就是热数据：最近一段时间（如最近 1 小时、5 分钟），1 万个商品请求， - 统计这段时间内每个商品的访问次数，排序后做出一个 top n 列表。
- 计算好每个 task 大致要存放的商品访问次数的数量，计算出大小， 然后构建一个 LRU MAP，它能够给你一个剩下访问次数最多的商品列表，访问高的才能存活。
  LRU MAP 有开源的实现，apach commons collections 中有提供，设置好 map 的最大大小， 就会自动根据 LRU 算法去剔除多余的数据，保证内存使用限制， 即时有部分数据被干掉了，下次会从 0 开始统计，也没有关系，因为被 LRU 算法干掉了， 就表示它不是热数据，说明最近一段时间都很少访问了，热度下降了。

##### 分布式并行缓存预热解决方案

- 每个 Storm task 启动时，基于 zk 分布式锁，将自己的 ID 写入 zk 同一个节点中：
  这个 id 写到一个固定节点中，形成一个 task id 列表， 后续可以通过这个 id 列表去拿到对于 task 存储在 zk node 上的 topn 列表。
- 每个 Storm task 负责完成自己这里的热数据统计。
  比如每隔一段时间，就遍历下这个 map，维护并更新一个前 n 个商品的 list。
- 定时同步到 zk 中去。
  写一个后台线程，每隔一段时间，比如 1 分钟，将这个 task 所有的商品排名算一次 将排名前 n 的热数据 list 同步到 zk 中去。
- 需要一个服务，根据 top n 列表在 mysql 中获取数据往 redis 中存
  这个服务有会部署多个实例，在启动时会拉取 storm task id 列表， 然后通过 zk 分布式锁，基于 id 去加锁，获取到这个 task id 节点中存储的 topn 列表， 然后读取 mysql 中的数据，存储在 redis 中。
  这个服务可以是单独的服务，也可以放在缓存服务中。

#### 总结

冷启动是说缓存中没有数据但是缓存短时间又恢复正常后的流量被大量打到 mysql。
 那么通过缓存预热来解决缓存冷启动问题：

- 使用 stom 实时计算出最近一段时间内的 n 个 topn 列表，并存储在 zk task id 节点上。
- 多服务通过 task id 进行分布式锁，获取 topn 列表，去 mysql 拉取数据放入 redis 中。
  利用storm 创建大量并行的 task 和数据分组策略， 让大量的访问日志分发到 n 个 task 中，让 storm 这种抗住大量并发访问量的计算能力， 这里是计算出 n 个 topn 列表，也就是大量的热数据。而不是唯一的一份 topn 列表， 而且是最近一段时间内的（通过这种分而治之方式 + 分段时间来重复计算自己负责的部分结果数据实现的）。



## 布隆过滤器

### 定义

我们可以把它看作由二进制向量（或者说位数组）和一系列随机映射函数（哈希函数）两部分组成的数据结构。相比于我们平时常用的的 List、Map 、Set 等数据结构，它占用空间更少并且效率更高，但是缺点是其返回的结果是概率性的，而不是非常准确的。理论情况下添加到集合中的元素越多，误报的可能性就越大。并且，存放在布隆过滤器的数据不容易删除。 

### 原理

**当一个元素加入布隆过滤器中的时候，会进行如下操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行如下操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

当字符串存储要加入到布隆过滤器中时，该字符串首先由多个哈希函数生成不同的哈希值，然后将对应的位数组的下标设置为 1（当位数组初始化时，所有位置均为0）。当第二次存储相同字符串时，因为先前的对应位置已设置为 1，所以很容易知道此值已经存在（去重非常方便）。

如果我们需要判断某个字符串是否在布隆过滤器中时，只需要对给定字符串再次进行相同的哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

**不同的字符串可能哈希出来的位置相同，这种情况我们可以适当增加位数组大小或者调整我们的哈希函数。**

综上，我们可以得出：**布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

# 计算机网络

## OSI与TCP/IP各层的结构与功能,都有哪些协议?

学习计算机网络时我们一般采用折中的办法，也就是中和 OSI 和 TCP/IP 的优点，采用一种只有五层协议的体系结构，这样既简洁又能将概念阐述清楚。

![五层体系结构](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/五层体系结构.png)

结合互联网的情况，自上而下地，非常简要的介绍一下各层的作用。

**1.1 应用层**

**应用层(application-layer）的任务是通过应用进程间的交互来完成特定网络应用。**应用层协议定义的是应用进程（进程：主机中正在运行的程序）间的通信和交互的规则。对于不同的网络应用需要不同的应用层协议。在互联网中应用层协议很多，如**域名系统DNS**，支持万维网应用的 **HTTP协议**，支持电子邮件的 **SMTP协议**等等。我们把应用层交互的数据单元称为**报文**。

**1.2 运输层**

**运输层(transport layer)的主要任务就是负责向两台主机进程之间的通信提供通用的数据传输服务**。应用进程利用该服务传送应用层报文。==“通用的”==是指并不针对某一个特定的网络应用，而是多种应用可以使用同一个运输层服务。由于一台主机可同时运行多个线程，因此运输层有复用和分用的功能。所谓复用就是指多个应用层进程可同时使用下面运输层的服务，分用和复用相反，是运输层把收到的信息分别交付上面应用层中的相应进程。传输的数据单元是**段**

**运输层主要使用以下两种协议:**

1. **传输控制协议 TCP**（Transmission Control Protocol）--提供**面向连接**的，**可靠的**数据传输服务。
2. **用户数据协议 UDP**（User Datagram Protocol）--提供**无连接**的，尽最大努力的数据传输服务（**不保证数据传输的可靠性**）。

**1.3 网络层**

**在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。** 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 **IP 协议**，因此分组也叫 **IP 数据报** ，简称 **数据报**。网络层传输的数据单元是**包**

这里要注意：**不要把运输层的“用户数据报 UDP ”和网络层的“ IP 数据报”弄混**。另外，无论是哪一层的数据单元，都可笼统地用“分组”来表示。

这里强调指出，网络层中的“网络”二字已经不是我们通常谈到的具体网络，而是指计算机网络体系结构模型中第三层的名称.

互联网是由大量的异构（heterogeneous）网络通过路由器（router）相互连接起来的。互联网使用的网络层协议是无连接的网际协议（Intert Protocol）和许多路由选择协议，因此互联网的网络层也叫做**网际层**或**IP层**。

**1.4 数据链路层**

**数据链路层(data link layer)通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。** 在两个相邻节点之间传送数据时，**数据链路层将网络层交下来的 IP 数据报组装成帧**，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。

在接收数据时，控制信息使接收端能够知道一个帧从哪个比特开始和到哪个比特结束。这样，数据链路层在收到一个帧后，就可从中提出数据部分，上交给网络层。
控制信息还使接收端能够检测到所收到的帧中有误差错。如果发现差错，数据链路层就简单地丢弃这个出了差错的帧，以避免继续在网络中传送下去白白浪费网络资源。如果需要改正数据在链路层传输时出现差错（这就是说，数据链路层不仅要检错，而且还要纠错），那么就要采用可靠性传输协议来纠正出现的差错。这种方法会使链路层的协议复杂些。

首先==Ethernet、IEEE802.3、PPP和HDLC==都是数据链路层的协议，只不过后面三个不常用而已，数据链路层最常用的协议是Etnernet（以太网协议）。

**1.5 物理层**

在物理层上所传送的数据单位是比特。
 **物理层(physical layer)的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。** 使其上面的数据链路层不必考虑网络的具体传输介质是什么。“透明传送比特流”表示经实际电路传送后的比特流没有发生变化，对传送的比特流来说，这个电路好像是看不见的。

在互联网使用的各种协中最重要和最著名的就是 TCP/IP 两个协议。现在人们经常提到的TCP/IP并不一定单指TCP和IP这两个具体的协议，而往往表示互联网所使用的整个TCP/IP协议族。

**1.6 总结一下**

上面我们对计算机网络的五层体系结构有了初步的了解，下面附送一张七层体系结构图总结一下（图片来源于网络）。

## TCP/IP分层的优势

- **各层之间是独立的。**某一层并不需要知道它的下一层是如何实现的，而仅仅需要知道该层通过层间的接口（即界面）所提供的服务。由于每一层只实现一种相对独立的功能，因而可将一个难以处理的复杂问题分解为若干个较容易处理的更小一些的问题。这样，整个问题的复杂程度就下降了。
- **灵活性好。**当任何一层发生变化时（例如由于技术的变化），只要层间接口关系保持不变，则在这层以上或以下各层均不受影响。此外，对某一层提供的服务还可进行修改。
- 当某层提供的服务不再需要时，甚至可以将这层取消。
- **结构上可分割开**。各层都可以采用最合适的技术来实现。
- **易于实现和维护**。这种结构使得实现和调试一个庞大而又复杂的系统变得易于处理，因为整个的系统已被分解为若干个相对独立的子系统。
- 能促进标准化工作。因为每一层的功能及其所提供的服务都已有了精确的说明。

## HTTP状态码

![状态码](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/状态码.png)

| 100     | Continue            | 继续。[客户端](http://www.dreamdu.com/webbuild/client_vs_server/)应继续其请求 |
| ------- | ------------------- | ------------------------------------------------------------ |
| 101     | Switching Protocols | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
|         |                     |                                                              |
| **200** | **OK**              | **请求成功。一般用于GET与POST请求**                          |
| 201     | Created             | 已创建。成功请求并创建了新的资源                             |
| 202     | Accepted            | 已接受。已经接受请求，但未处理完成                           |



| 300  | Multiple Choices  | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| ---- | ----------------- | ------------------------------------------------------------ |
| 301  | Moved Permanently | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |
| 302  | Found             | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
| 303  | See Other         | 查看其它地址。与301类似。使用GET和POST请求查看               |
| 304  | Not Modified      | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 305  | Use Proxy         | 使用代理。所请求的资源必须通过代理访问                       |

| 400  | Bad Request      | 客户端请求的语法错误，服务器无法理解                         |
| ---- | ---------------- | ------------------------------------------------------------ |
| 401  | Unauthorized     | 请求要求用户的身份认证                                       |
| 402  | Payment Required | 保留，将来使用                                               |
| 403  | Forbidden        | 服务器理解请求客户端的请求，但是拒绝执行此请求               |
| 404  | Not Found        | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |

| 501  | Not Implemented            | 服务器不支持请求的功能，无法完成请求                         |
| ---- | -------------------------- | ------------------------------------------------------------ |
| 502  | Bad Gateway                | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |
| 503  | Service Unavailable        | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |
| 504  | Gateway Time-out           | 充当网关或代理的服务器，未及时从远端服务器获取请求           |
| 505  | HTTP Version not supported | 服务                                                         |



## TCP UDP的区别

![TCP、UDP协议的区别](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)

**TCP与UDP区别总结**：

```
1、TCP面向连接（如打电话要先拨号建立连接）;UDP是无连接的，即发送数据之前不需要建立连接
2、TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付
3、TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP是面向报文的
UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
4、每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信
5、TCP首部开销20字节;UDP的首部开销小，只有8个字节
6、TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道
```

## TCP怎么保证可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。 
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 
4. TCP 的接收端会丢弃重复的数据。 
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 

**TCP的优点**： 可靠，稳定 TCP的可靠体现在TCP在传递数据之前，会有三次握手来建立连接，而且在数据传递时，有确认、窗口、重传、拥塞控制机制，在数据传完后，还会断开连接用来节约系统资源。 TCP的缺点： 慢，效率低，占用系统资源高，易被攻击 TCP在传递数据之前，要先建连接，这会消耗时间，而且在数据传递时，确认机制、重传机制、拥塞控制机制等都会消耗大量的时间，而且要在每台设备上维护所有的传输连接，事实上，每个连接都会占用系统的CPU、内存等硬件资源。 而且，因为TCP有确认机制、三次握手机制，这些也导致TCP容易被人利用，实现DOS、DDOS、CC等攻击。

**UDP的优点**： 快，比TCP稍安全 UDP没有TCP的握手、确认、窗口、重传、拥塞控制等机制，UDP是一个无状态的传输协议，所以它在传递数据时非常快。没有TCP的这些机制，UDP较TCP被攻击者利用的漏洞就要少一些。但UDP也是无法避免攻击的，比如：UDP Flood攻击…… UDP的缺点： 不可靠，不稳定 因为UDP没有TCP那些可靠的机制，在数据传递时，如果网络质量不好，就会很容易丢包。 基于上面的优缺点，那么： 什么时候应该使用TCP： 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 在日常生活中，常见使用TCP协议的应用如下： 浏览器，用的HTTP FlashFXP，用的FTP Outlook，用的POP、SMTP Putty，用的Telnet、SSH QQ文件传输 ………… 什么时候应该使用UDP： 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 比如，日常生活中，常见使用UDP协议的应用如下： QQ语音 QQ视频 TFTP ……

有些应用场景对可靠性要求不高会用到UPD，比如长视频，要求速率

**UDP实现TCP**

添加seq/ack机制，确保数据发送到对端
添加发送和接收缓冲区，主要是用户超时重传
添加超时重传机制
详细说明：发送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。

**DNS为啥用UDP不用TCP**

1.UDP快，只需要一问一答，TCP需要三次握手四次挥手
2.DNS报文一般比较小，用一个UDP包可以装的下
3.UDP不需要建立连接，减小DNS服务器的负担 

## TCP三次握手四次挥手

### 三次握手过程

报文主要段的意思

　　　　**序号**：表示发送的数据字节流，确保TCP传输有序，对每个字节编号

　　　　**确认序号**：发送方期待接收的下一序列号，接收成功后的数据字节序列号加 1。只有ACK=1时才有效。

　　　　**ACK**：确认序号的标志，ACK=1表示确认号有效，ACK=0表示报文不含确认序号信息

　　　　**SYN**：连接请求序号标志，用于建立连接，SYN=1表示请求连接

　　　　**FIN**：结束标志，用于释放连接，为1表示关闭本方数据流

![TCP三次握手](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019/7/三次握手.png)

 

第一次握手：建立连接时，客户端发送syn包（syn=x）到服务器，并进入**SYN_SENT**状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。

第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入**SYN_RECV**状态；

第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1），此包发送完毕，客户端和服务器进入**ESTABLISHED**（TCP连接成功）状态，完成三次握手。



• 第一次：客户端发送请求到服务器，服务器知道客户端发送，自己接收正常。SYN=1,seq=x

• 第二次：服务器发给客户端，客户端知道自己发送、接收正常，服务器接收、发送正常。ACK=1,ack=x+1,SYN=1,seq=y

• 第三次：客户端发给服务器：服务器知道客户端发送，接收正常，自己接收，发送也正常.seq=x+1,ACK=1,ack=y+1

### 为什么要三次握手

**三次握手的目的是建立可靠的通信信道，也就是双方确认自己与对方的发送与接收是正常的。**

第一次握手：Client 什么都不能确认；Server 确认了对方发送正常，自己接收正常

第二次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：对方发送正常，自己接收正常

第三次握手：Client 确认了：自己发送、接收正常，对方发送、接收正常；Server 确认了：自己发送、接收正常，对方发送、接收正常

所以三次握手就能确认双发收发功能都正常，缺一不可。

**为什么连接建立需要三次握手，而不是两次握手？**
防止失效的连接请求报文段被服务端接收，从而产生错误。

PS：失效的连接请求：若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时，上一个连接请求就是『失效的』。

若建立连接只需两次握手，客户端并没有太大的变化，仍然需要获得服务端的应答后才进入ESTABLISHED状态，而服务端在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的连接请求迟迟到不了服务端，客户端便超时重发请求，如果服务端正确接收并确认应答，双方便开始通信，通信结束后释放连接。此时，如果那个失效的连接请求抵达了服务端，由于只有两次握手，服务端收到请求就会进入ESTABLISHED状态，等待发送数据或主动发送数据。但此时的客户端早已进入CLOSED状态，服务端将会一直等待下去，这样浪费服务端连接资源。

### 四次挥手过程理解 

![img](https://img-blog.csdn.net/20180717204202563?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4OTUwMzE2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



• 第一次：**客户端A**请求断开FIN,seq=u

• 第二次：**服务器B**确认客户端A的断开请求ACK,ack=u+1,seq=v

• 第三次：**服务器B**请求断开FIN,seq=w,ACK,ack=u+1

• 第四次：**客户端A**确认服务器B的断开ACK,ack=w+1,seq=u+1



1）**客户端进程发出连接释放报文，并且停止发送数据。**释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2）**服务器收到连接释放报文，发出确认报文，**ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3）**客户端收到服务器的确认请求后**，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4）**服务器将最后的数据发送完毕后，就向客户端发送连接释放报文**，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5）**客户端收到服务器的连接释放报文后，必须发出确认，**ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6）**服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。**可以看到，服务器结束TCP连接的时间要比客户端早一些。

### 常见面试题

**为什么不能用两次握手进行连接？**

防止失效的连接请求报文段被服务端接收，从而产生错误。

PS：失效的连接请求：若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时，上一个连接请求就是『失效的』。

若建立连接只需两次握手，客户端并没有太大的变化，仍然需要获得服务端的应答后才进入ESTABLISHED状态，而服务端在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的连接请求迟迟到不了服务端，客户端便超时重发请求，如果服务端正确接收并确认应答，双方便开始通信，通信结束后释放连接。此时，如果那个失效的连接请求抵达了服务端，由于只有两次握手，服务端收到请求就会进入ESTABLISHED状态，等待发送数据或主动发送数据。但此时的客户端早已进入CLOSED状态，服务端将会一直等待下去，这样浪费服务端连接资源。

**为什么连接的时候是三次握手，关闭的时候却是四次握手？**

答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

**为什么要四次挥手**

任何一方都可以在数据传送结束后发出连接释放的通知，待对方确认后进入半关闭状态。当另一方也没有数据再发送的时候，则发出连接释放通知，对方确认后就完全关闭了TCP连接。

举个例子：A 和 B 打电话，通话即将结束后，A 说“我没啥要说的了”，B回答“我知道了”，但是 B 可能还会有要说的话，A 不能要求 B 跟着自己的节奏结束通话，于是 B 可能又巴拉巴拉说了一通，最后 B 说“我说完了”，A 回答“知道了”，这样通话才算结束。

 **为什么A要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？**
为了保证B能收到A的确认应答。
若A发完确认应答后直接进入CLOSED状态，那么如果该应答丢失，B等待超时后就会重新发送连接释放请求，但此时A已经关闭了，不会作出任何响应，因此B永远无法正常关闭 

**为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？**

答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

**如果已经建立了连接，但是客户端突然出现故障了怎么办？**

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。



## Cookie和Session区别和作用

**Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，**但是两者的应用场景不太一样。

 **Cookie 一般用来保存用户信息** 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了，这是因为用户登录的时候我们可以存放了一个 Token 在 Cookie 中，下次登录的时候只需要根据 Token 值来查找用户即可(为了安全考虑，重新登录一般要将 Token 重写)；③登录一次网站后访问网站其他页面不需要重新登录。**Session 的主要作用就是通过服务端记录用户的状态。** 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

Cookie 数据保存在客户端(浏览器端)，Session 数据保存在服务器端。

Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高。如果要在 Cookie 中存储一些敏感信息，不要直接写入 Cookie 中，最好能将 Cookie 信息加密然后使用到的时候再去服务器端解密。

**区别：**

- cookie数据存放在客户的浏览器上，session数据放在服务器上
- cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session
- session会在一定时间内保存在服务器上。当访问增多，会比较占用服务器的性能。考虑到减轻服务器性能方面，应当使用cookie。
- 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。

**联系**

- session是通过cookie来工作的

- session和cookie之间是通过$_COOKIE['PHPSESSID']

  来联系的，通过$_COOKIE['PHPSESSID']可以知道session的id，从而获取到其他的信息。在

- 购物网站中通常将用户加入购物车的商品联通session_id记录到数据库中，当用户再次访问是，通过sessionid就可以查找到用户上次加入购物车的商品。因为sessionid是唯一的，记录到数据库中就可以根据这个查找了。

## HTTP和HTTPS

### HTTP请求报文

 HTTP请求报文由3部分组成（**请求行+请求头+请求体**） 

 HTTP请求信息由3部分组成：

- 请求方法URI协议/版本
- 请求头(Request Header)
- 请求正文

HTTP响应
HTTP应答与HTTP请求相似，HTTP响应也由3个部分构成，分别是：

- 状态行
- 响应头(Response Header)
- 响应正文

在接收和解释请求消息后，服务器会返回一个HTTP响应消息。

状态行由协议版本、数字形式的状态代码、及相应的状态描述，各元素之间以空格分隔。

格式: HTTP-Version Status-Code Reason-Phrase CRLF 

>请求头字段的具体含义
>Accept：浏览器可接受的MIME类型。
>Accept-Charset：浏览器可接受的字符集。
>Accept-Encoding：浏览器能够进行解码的数据编码方式，比如gzip。
>Accept-Language：浏览器所希望的语言种类，当服务器能够提供一种以上的语言版本时要用到。
>Authorization：授权信息，通常出现在对服务器发送的WWW-Authenticate头的应答中。
>Connection：表示是否需要持久连接。如果Servlet看到这里的值为“Keep-Alive”，或者看到请求使用的是HTTP 1.1（HTTP 1.1默认进行持久连接），它就可以利用持久连接的优点，当页面包含多个元素时（例如Applet，图片），显著地减少下载所需要的时间。要实现这一点，Servlet需要在应答中发送一个Content-Length头，最简单的实现方法是：先把内容写入ByteArrayOutputStream，然后在正式写出内容之前计算它的大小。
>Content-Length：表示请求消息正文的长度。
>Cookie：设置cookie,这是最重要的请求头信息之一
>From：请求发送者的email地址，由一些特殊的Web客户程序使用，浏览器不会用到它。
>Host：初始URL中的主机和端口。
>If-Modified-Since：只有当所请求的内容在指定的日期之后又经过修改才返回它，否则返回304“Not Modified”应答。
>Pragma：指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝。
>Referer：包含一个URL，用户从该URL代表的页面出发访问当前请求的页面。
>User-Agent：浏览器类型，如果Servlet返回的内容与浏览器类型有关则该值非常有用。
>UA-Pixels，UA-Color，UA-OS，UA-CPU：由某些版本的IE浏览器所发送的非标准的请求头，表示屏幕大小、颜色深度、操作系统和CPU

### http和https的区别

1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

**安全性和资源消耗：** **HTTP协议运行在TCP之上，所有传输的内容都是明文**，客户端和服务器端都无法验证对方的身份。**HTTPS是运行在SSL/TLS之上的HTTP协议，SSL/TLS 运行在TCP之上**。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

- **对称加密**：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；
- **非对称加密**：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等

### HTTPS的一次请求流程

1. 客户端发起HTTPS请求
2. 服务端的配置
   采用HTTPS协议的服务器必须要有一套数字证书，可以是自己制作或者CA证书。区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用CA证书则不会弹出提示页面。这套证书其实就是一对公钥和私钥。公钥给别人加密使用，私钥给自己解密使用。
3. 传送证书
   这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等。
4. 客户端解析证书
   这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等，如果发现异常，则会弹出一个警告框，提示证书存在问题。如果证书没有问题，那么就生成一个随即值，然后用证书对该随机值进行加密。
5. 传送加密信息
   这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。
6. 服务段解密信息
   服务端用私钥解密后，得到了客户端传过来的随机值(私钥)，然后把内容通过该值进行对称加密。所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。
7. 传输加密后的信息
   这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。
8. 客户端解密信息
   客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容。

### HTTP 1.0和HTTP 1.1的主要区别是什么?

> 这部分回答引用这篇文章 <https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?> 的一些内容。

HTTP1.0最早在网页中使用是在1996年，那个时候只是使用一些较为简单的网页上和网络请求上，而HTTP1.1则在1999年才开始广泛应用于现在的各大浏览器网络请求中，同时HTTP1.1也是当前使用最为广泛的HTTP协议。 主要区别主要体现在：

1. **长连接** : **在HTTP/1.0中，默认使用的是短连接**，也就是说每次请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的,每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用个长连接来发多个请求。**HTTP 1.1起，默认使用长连接** ,默认开启Connection： keep-alive。 **HTTP/1.1的持续连接有非流水线方式和流水线方式** 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文。与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。
1. **错误状态响应码** :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。
1. **缓存处理** :在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。
1. **带宽优化及网络连接的使用** :HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

## HTTP1.0 HTTP1.1和HTTP2.0的区别

#### HTTP1.0、HTTP 1.1、HTTP 2.0之间的主要区别

- HTTP1.0与HTTP 1.1的主要区别 

    1. 长连接 ：HTTP 1.0需要使用**keep-alive**参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。

        ​        HTTP是基于TCP/IP协议的，创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接，可以用个长连接来发多个请求。

    2. 节约带宽：HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接收到100，才开始把请求body发送到服务器。

    3. HOST域：在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname），HTTP1.0没有host域。

- HTTP1.1与HTTP 2.0的主要区别 

    1. 多路复用：HTTP2.0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。HTTP1.1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。

    2. 二进制分帧：在应用层（HTTP/2）和传输层（TCP or UDP）之间增加一个二进制分帧层。

    3. 首部压缩： 在HTTP1.1中，HTTP请求和响应都是由状态行、请求/响应头部、消息主体三部分组成。HTTP2.0使用HPACK算法对header的数据进行压缩，

    4. 服务器推送：服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。**在HTTP1.1中这些资源每一个都必须明确地请求**。这是一个很慢的过程。浏览器从获取HTML开始，然后在它解析和评估页面的时候，增量地获取更多的资源。因为服务器必须等待浏览器做每一个请求，网络经常是空闲的和未充分使用的。

        ​    为了改善延迟，**HTTP2.0引入了server push**，它允许服务端推送资源给浏览器，在浏览器明确地请求之前，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。

## URI和URL的区别是什么?

- URI(Uniform Resource Identifier) 是统一资源标志符，可以**唯一标识一个资源。**
- URL(Uniform Resource Location) 是统一资源定位符，可以提供**该资源的路径。它是一种具体的 URI**，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。

## get和post的区别

1. Get是不安全的，因为在传输过程，数据被放在请求的URL中；Post的所有操作对用户来说都是不可见的。    
2. Get传送的数据量较小，这主要是因为受URL长度限制；Post传送的数据量较大，一般被默认为不受限制。    
3. Get限制Form表单的数据集的值必须为ASCII字符；而Post支持整个ISO10646字符集。    
4. Get执行效率却比Post方法好。Get是form提交的默认方法。

## 浏览器输入网址之后的做了什么

<img src="https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/url输入到展示出来的过程.jpg" style="zoom:50%;" />

1. DNS解析
2. TCP连接
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 连接结束

1、浏览器发起DNS查询请求

**在广域网中是基于IP地址进行通信的。但通常客户访问的是一个网址，为此需要先得到网址对应的IP地址，**这就需要域名服务系统将域名转换成IP地址。在客户端浏览器中输入网址时，浏览器会根据本地客户端DNS服务器配置，向DNS服务器获取域名对应的IP地址。
       域名解析服务器是基于UDP协议实现的一个应用程序，通常通过监听53端口来获取客户端的域名解析请求。
       **DNS查找过程为：**
       浏览器缓存->系统缓存->路由器缓存->ISP DNS缓存->递归搜索
       **递归搜索过程为：**从根域名服务器到顶级域名服务器到所查询的域名服务器。

2、**域名服务器向客户端返回查询结果域名，从而完成域名到IP地址的转换。**

3、**客户端向web服务器发送HTTP请求**（三次握手过程）

​	得到了域名对应的IP地址后客户端便可向真正的web服务器发生HTTP请求。

4、**服务器给浏览器进行一个301永久重定向响应。**

   IP对应的服务器很可能是代理服务器，比如输入“http://baidu.com”，而不是“http://www.baidu.com”，这两个网址对应的是同一个网页，因此通过代理服务器的方式进行重定向响应，让这两个网址访问的同一个网页。 浏览器根据重定向地址再次进行HTTP请求。

5、**发送响应数据给客户端**
      Web服务器通常通过监听80端口来获取客户端的HTTP请求。与客户端建立好TCP连接后，Web服务器开始接受客户端发来的数据，并通过HTTP解码，从接受到的网络数据中解析出请求的url信息以前其他诸如Accept-Encoding、Accept-Language等信息。

6、**浏览器响应过程**（最后一步 四次挥手）

浏览器收到响应内容之后，生成主页框架，同时向服务端继续发送请求，请求的内容是主页里的一些资源，比如说图片、视频等。 对于静态的页面内容，浏览器通常进行缓存，对于动态的内容通常不缓存，缓存的时间也是有期限的。

 浏览器向服务器发送异步请求，因为有些页面显示完成之后客户端仍需要与服务端保持联系。

整个过程结束之后，浏览器关闭TCP连接。





### DNS域名解析过程

1、在浏览器中输入www.qq.com域名，**操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。** 

2、**如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。** 

3、**如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器**，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 

4、**如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析**，此解析不具有权威性。 

5、**如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，**如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 

6、**如果用的是转发模式**，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。

## timewait和closewait的区别

ESTABLISHED 表示正在通信，TIME_WAIT 表示主动关闭，CLOSE_WAIT 表示被动关闭。

- TIME_WAIT 

  TIME_WAIT 是主动关闭链接时形成的，等待2MSL时间，约4分钟。主要是防止最后一个ACK丢失。  由于TIME_WAIT 的时间会非常长，因此server端应尽量减少主动关闭连接

- CLOSE_WAIT
  CLOSE_WAIT是被动关闭连接是形成的。根据TCP状态机，服务器端收到客户端发送的FIN，则按照TCP实现发送ACK，因此进入CLOSE_WAIT状态。但如果服务器端不执行close()，就不能由CLOSE_WAIT迁移到LAST_ACK，则系统中会存在很多CLOSE_WAIT状态的连接。此时，可能是系统忙于处理读、写操作，而未将已收到FIN的连接，进行close。此时，[recv](https://so.csdn.net/so/search?q=recv&spm=1001.2101.3001.7020)/read已收到FIN的连接socket，会返回0。

## 对称加密和非对称加密

#### 对称加密

对称加密指的就是加密和解密使用同一个秘钥，所以叫做对称加密。对称加密只有一个秘钥，作为私钥。

常见的对称加密算法：DES，AES，3DES

#### 非对称加密

非对称加密指的是，加密和解密使用不同的秘钥，一把作为公开的公钥，另一把作为私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。

常见的非对称加密算法：RSA，ECC

#### 对称加密和非对称加密的区别

（1） 对称加密加密与解密使用的是同样的密钥，所以速度快，但由于需要将密钥在网络传输，所以安全性不高。

（2） 非对称加密使用了一对密钥，公钥与私钥，所以安全性高，但加密与解密速度慢。

（3） 解决的办法是将对称加密的密钥使用非对称加密的公钥进行加密，然后发送出去，接收方使用私钥进行解密得到对称加密的密钥，然后双方可以使用对称加密来进行沟通。

# 操作系统

#### 死锁概念和原理

   **概念：** 多个并发进程因争夺系统资源而产生相互等待的现象。

   **原理：** 当一组进程中的每个进程都在等待某个事件发生，而只有这组进程中的其他进程才能触发该事件，这就称这组进程发生了死锁。

   **本质原因：**

​     1）、系统资源有限。

​     2）、进程推进顺序不合理。

#### 死锁的必要条件

  **1、互斥：** 某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。

  **2、请求保持：** 一个进程本身占有资源（一种或多种），同时还有资源未得到满足，正在等待其他进程释放该资源。

  **3、不可剥夺：** 别人已经占有了某项资源，你不能因为自己也需要该资源，就去把别人的资源抢过来。

  **4、循环等待：** 存在一个进程链，使得每个进程都占有下一个进程所需的至少一种资源。

​    当以上四个条件均满足，必然会造成死锁，发生死锁的进程无法进行下去，它们所持有的资源也无法释放。这样会导致CPU的吞吐量下降。所以死锁情况是会浪费系统资源和影响计算机的使用性能的。那么，解决死锁问题就是相当有必要的了。

#### **避免死锁的方法**

**1、死锁预防 ----- 确保系统永远不会进入死锁状态**

   产生死锁需要四个条件，那么，只要这四个条件中至少有一个条件得不到满足，就不可能发生死锁了。由于互斥条件是非共享资源所必须的，不仅不能改变，还应加以保证，所以，主要是破坏产生死锁的其他三个条件。

**a、破坏“占有且等待”条件**

   方法1：所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。

​      优点：简单易实施且安全。

​      缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。

​          使进程经常发生饥饿现象。

   方法2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。这样的话，资源的利用率会得到提高，也会减少进程的饥饿问题。

**b、破坏“不可抢占”条件**

   当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂地释放或者说是被抢占了。

​    该种方法实现起来比较复杂，且代价也比较大。释放已经保持的资源很有可能会导致进程之前的工作实效等，反复的申请和释放资源会导致进程的执行被无限的推迟，这不仅会延长进程的周转周期，还会影响系统的吞吐量。

**c、破坏“循环等待”条件**

   可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为i的资源时，那么它下一次申请资源只能申请编号大于i的资源。如图所示：

![img](https://img-blog.csdn.net/2018051322430635)

这样虽然避免了循环等待，但是这种方法是比较低效的，资源的执行速度回变慢，并且可能在没有必要的情况下拒绝资源的访问，比如说，进程c想要申请资源1，如果资源1并没有被其他进程占有，此时将它分配个进程c是没有问题的，但是为了避免产生循环等待，该申请会被拒绝，这样就降低了资源的利用率

**2、避免死锁 ----- 在使用前进行判断，只允许不会产生死锁的进程申请资源**

的死锁避免是利用额外的检验信息，在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。

两种避免办法：

  1、如果一个进程的请求会导致死锁，则不启动该进程

  2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。

避免死锁的具体实现通常利用银行家算法

####    **银行家算法**

a、**银行家算法的相关数据结构**

  **可利用资源向量Available：**用于表示系统里边各种资源剩余的数目。由于系统里边拥有的资源通常都是有很多种（假设有m种），所以，我们用一个有m个元素的数组来表示各种资源。数组元素的初始值为系统里边所配置的该类全部可用资源的数目，其数值随着该类资源的分配与回收动态地改变。

  **最大需求矩阵Max：**用于表示各个进程对各种资源的额最大需求量。进程可能会有很多个（假设为n个），那么，我们就可以用一个nxm的矩阵来表示各个进程多各种资源的最大需求量

  **分配矩阵Allocation：**顾名思义，就是用于表示已经分配给各个进程的各种资源的数目。也是一个nxm的矩阵。

  **需求矩阵Need：**用于表示进程仍然需要的资源数目，用一个nxm的矩阵表示。系统可能没法一下就满足了某个进程的最大需求（通常进程对资源的最大需求也是只它在整个运行周期中需要的资源数目，并不是每一个时刻都需要这么多），于是，为了进程的执行能够向前推进，通常，系统会先分配个进程一部分资源保证进程能够执行起来。那么，进程的最大需求减去已经分配给进程的数目，就得到了进程仍然需要的资源数目了。

**银行家算法通过对进程需求、占有和系统拥有资源的实时统计，确保系统在分配给进程资源不会造成死锁才会给与分配。**

**死锁避免的优点：**不需要死锁预防中的抢占和重新运行进程，并且比死锁预防的限制要少。

**死锁避免的限制：**

  必须事先声明每个进程请求的最大资源量

  考虑的进程必须无关的，也就是说，它们执行的顺序必须没有任何同步要求的限制

  分配的资源数目必须是固定的。

  在占有资源时，进程不能退出

**3、死锁检测与解除 ----- 在检测到运行系统进入死锁，进行恢复。**

   允许系统进入到死锁状态

####   死锁检测

下图截自《操作系统--精髓与设计原理》

![](https://img-blog.csdn.net/20180513224342642)

####   死锁的解除

如果利用死锁检测算法检测出系统已经出现了死锁 ，那么，此时就需要对系统采取相应的措施。常用的解除死锁的方法：

1、==抢占资源==：从一个或多个进程中抢占足够数量的资源分配给死锁进程，以解除死锁状态。

2、==终止（或撤销）进程==：终止或撤销系统中的一个或多个死锁进程，直至打破死锁状态。

  a、终止所有的死锁进程。这种方式简单粗暴，但是代价很大，很有可能会导致一些已经运行了很久的进程前功尽弃。

   b、逐个终止进程，直至死锁状态解除。该方法的代价也很大，因为每终止一个进程就需要使用死锁检测来检测系统当前是否处于死锁状态。另外，每次终止进程的时候终止那个进程呢？每次都应该采用最优策略来选择一个“代价最小”的进程来解除死锁状态。**一般根据如下几个方面来决定终止哪个进程**：

  进程的优先级

  进程已运行时间以及运行完成还需要的时间

  进程已占用系统资源

  进程运行完成还需要的资源

  终止进程数目

  进程是交互还是批处理



#### 生产消费者模型

生产者消费者模型具体来讲，就是在一个系统中，存在生产者和消费者两种角色，他们通过内存缓冲区进行通信，生产者生产消费者需要的资料，消费者把资料做成产品。生产消费者模式如下图。

　　　　　　　　　　　　![img](https://images2015.cnblogs.com/blog/868641/201703/868641-20170303152707641-1755807475.png)　　

　　　　在日益发展的服务类型中，譬如注册用户这种服务，它可能解耦成好几种独立的服务（账号验证，邮箱验证码，手机短信码等）。它们作为消费者，等待用户输入数据，在前台数据提交之后会经过分解并发送到各个服务所在的url，分发的那个角色就相当于生产者。消费者在获取数据时候有可能一次不能处理完，那么它们各自有一个请求队列，那就是内存缓冲区了。做这项工作的框架叫做消息队列。

- **生产者消费者模型的实现**

　　　　生产者是一堆线程，消费者是另一堆线程，内存缓冲区可以使用List数组队列，数据类型只需要定义一个简单的类就好。关键是如何处理多线程之间的协作。这其实也是多线程通信的一个范例。

　　　　在这个模型中，最关键就是内存缓冲区为空的时候消费者必须等待，而内存缓冲区满的时候，生产者必须等待。其他时候可以是个动态平衡。值得注意的是多线程对临界区资源的操作时候必须保证在读写中只能存在一个线程，所以需要设计锁的策略。

#### 简单说下你对并行和并发的理解

==并行==是指两个或者多个事件在同一时刻发生；而==并发==是指两个或多个事件在同一时间间隔发生； 

==并行==是在不同实体上的多个事件，==并发==是在同一实体上的多个事件；

#### 同步、异步、阻塞、非阻塞的概念

==同步：==当一个同步调用发出后，调用者要一直等待返回结果。通知后，才能进行后续的执行。 

==异步：==当一个异步过程调用发出后，调用者不能立刻得到返回结果。实际处理这个调用的部件在完成后，通过状态、通知和回调来通知调用者。 

==阻塞：==是指调用结果返回前，当前线程会被挂起，即阻塞。 

==非阻塞：==是指即使调用结果没返回，也不会阻塞当前线程。

#### 进程和线程的基本概念

进程：进程是系统进行资源分配和调度的一个独立单位，是系统中的并发执行的单位。 

线程：线程是进程的一个实体，也是 CPU 调度和分派的基本单位，它是比进程更小的能独立运行的基本单位，有时又被称为轻权进程或轻量级进程。

#### 进程和线程的区别

1. 进程是资源分配的最小单位，而线程是 CPU 调度的最小单位； 
2. 创建进程或撤销进程，系统都要为之分配或回收资源，操作系统开销远大于创建或撤销线程时的开销； 
3. 不同进程地址空间相互独立，同一进程内的线程共享同一地址空间。一个进程的线程在另一个进程内是不可见的； 
4. 进程间不会相互影响，而一个线程挂掉将可能导致整个进程挂掉；

#### 为什么有了进程，还要有线程呢

进程可以使多个程序并发执行，以提高资源的利用率和系统的吞吐量，但是其带来了一些缺点： 

- 进程在同一时间只能干一件事情； 
- 进程在执行的过程中如果阻塞，整个进程就会被挂起，即使进程中有些工作不依赖与等待的资源，仍然不会执行。 

基于以上的缺点，操作系统引入了比进程粒度更小的线程，作为并发执行的基本单位，从而减少程序在并发执行时所付出的时间和空间开销，提高并发性能。

#### 进程的状态转换

进程包括三种状态：**就绪态、运行态和阻塞态**

- **就绪 —> 执行：**对就绪状态的进程，当进程调度程序按一种选定的策略从中选中一个就绪进程，为之分配了处理机后，该进程便由就绪状态变为执行状态； 
- **执行 —> 阻塞：**正在执行的进程因发生某等待事件而无法执行，则进程由执行状态变为阻塞状态，如进程提出输入/输出请求而变成等待外部设备传输信息的状态，进程申请资源（主存空间或外部设备）得不到满足时变成等待资源状态，进程运行中出现了故障（程序出错或主存储器读写错等）变成等待干预状态等等； 
- **阻塞 —> 就绪：**处于阻塞状态的进程，在其等待的事件已经发生，如输入/输出完成，资源得到满足或错误处理完毕时，处于等待状态的进程并不马上转入执行状态，而是先转入就绪状态，然后再由系统进程调度程序在适当的时候将该进程转为执行状态； 
- **执行 —> 就绪：**正在执行的进程，因时间片用完而被暂停执行，或在采用抢先式优先级调度算法的系统中,当有更高优先级的进程要运行而被迫让出处理机时，该进程便由执行状态转变为就绪状态。

#### 进程间的通信方式

进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。IPC 的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams 等。其中 Socket 和 Streams 支持不同主机上的两个进程 IPC。 

**管道** 

- 它是半双工的，具有固定的读端和写端； 
- 它只能用于父子进程或者兄弟进程之间的进程的通信； 
- 它可以看成是一种特殊的文件，对于它的读写也可以使用普通的 read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。 

**命名管道** 

- FIFO 可以在无关的进程之间交换数据，与无名管道不同； 
- FIFO 有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。 

**消息队列** 

- 消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符 ID 来标识； 
- 消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级； 
- 消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除； 
- 消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。 

**信号量** 

- 信号量（semaphore）是一个计数器。用于实现进程间的互斥与同步，而不是用于存储进程间通信数据； 
- 信号量用于进程间同步，若要在进程间传递数据需要结合共享内存； 
- 信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作； 
- 每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数； 
- 支持信号量组。 

**共享内存** 

- 共享内存（Shared Memory），指两个或多个进程共享一个给定的存储区；
- 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。

#### 进程调度算法

调度算法是指：根据系统的资源分配策略所规定的资源分配算法。常用的调度算法有：**先来先服务调度算法、时间片轮转调度法、短作业优先调度算法、最短剩余时间优先、高响应比优先调度算法、优先级调度算法等等。** 

**先来先服务调度算法** 

先来先服务调度算法是一种最简单的调度算法，也称为先进先出或严格排队方案。当每个进程就绪后，它加入就绪队列。当前正运行的进程停止执行，选择在就绪队列中存在时间最长的进程运行。该算法既可以用于作业调度，也可以用于进程调度。先来先去服务比较适合于常作业（进程），而不利于段作业（进程）。 

**时间片轮转调度算法** 

时间片轮转调度算法主要适用于分时系统。在这种算法中，系统将所有就绪进程按到达时间的先后次序排成一个队列，进程调度程序总是选择就绪队列中第一个进程执行，即先来先服务的原则，但仅能运行一个时间片。 

**短作业优先调度算法** 

短作业优先调度算法是指对短作业优先调度的算法，从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。 短作业优先调度算法是一个非抢占策略，他的原则是下一次选择预计处理时间最短的进程，因此短进程将会越过长作业，跳至队列头。 

**最短剩余时间优先调度算法** 

最短剩余时间是针对最短进程优先增加了抢占机制的版本。在这种情况下，进程调度总是选择预期剩余时间最短的进程。当一个进程加入到就绪队列时，他可能比当前运行的进程具有更短的剩余时间，因此只要新进程就绪，调度程序就能可能抢占当前正在运行的进程。像最短进程优先一样，调度程序正在执行选择函数是必须有关于处理时间的估计，并且存在长进程饥饿的危险。 

**高响应比优先调度算法** 

高响应比优先调度算法主要用于作业调度，该算法是对 先来先服务调度算法和短作业优先调度算法的一种综合平衡，同时考虑每个作业的等待时间和估计的运行时间。在每次进行作业调度时，先计算后备作业队列中每个作业的响应比，从中选出响应比最高的作业投入运行。 

**优先级调度算法** 

优先级调度算法每次从后备作业队列中选择优先级最髙的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。在进程调度中，优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。

#### 什么是死锁

死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。 如下图所示：如果此时有一个线程 A，已经持有了锁 A，但是试图获取锁 B，线程 B 持有锁 B，而试图获取锁 A，这种情况下就会产生死锁。
![](https://gitee.com/iamshuaidi/picture/raw/master/picture/image-20210607160841587.png)

#### 产生死锁的原因

由于系统中存在一些不可剥夺资源，而当两个或两个以上进程占有自身资源，并请求对方资源时，会导致每个进程都无法向前推进，这就是死锁。 

- **竞争资源** 

  例如：系统中只有一台打印机，可供进程 A 使用，假定 A 已占用了打印机，若 B 继续要求打印机打印将被阻塞。 

系统中的资源可以分为两类：

可剥夺资源：是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺，CPU 和主存均属于可剥夺性资源； 

不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。 

- **进程推进顺序不当** 

例如：进程 A 和 进程 B 互相等待对方的数据。

#### 死锁产生的必要条件

1. 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。 
2. 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。 
3. 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。 
4. 环路等待条件：在发生死锁时，必然存在一个进程–资源的环形链。

#### 解决死锁的基本方法

预防死锁，避免死锁，检测死锁，解除死锁

#### 怎么预防死锁

- 破坏请求条件：一次性分配所有资源，这样就不会再有请求了； 
- 破坏请保持条件：只要有一个资源得不到分配，也不给这个进程分配其他的资源： 
- 破坏不可剥夺条件：当某进程获得了部分资源，但得不到其它资源，则释放已占有的资源； 
- 破坏环路等待条件：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反。

#### 怎么避免死锁

- **安全状态** 

  ![](https://gitee.com/iamshuaidi/picture/raw/master/picture/ed523051-608f-4c3f-b343-383e2d194470.png)

  图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。 

  定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。 

  安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。 

- **单个资源的银行家算法** 

  一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配。 

  ![](https://gitee.com/iamshuaidi/picture/raw/master/picture/d160ec2e-cfe2-4640-bda7-62f53e58b8c0.png)

  上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。 

- **多个资源的银行家算法** 

  ![](https://gitee.com/iamshuaidi/picture/raw/master/picture/62e0dd4f-44c3-43ee-bb6e-fedb9e068519.png)

  上图中有五个进程，四个资源。左边的图表示已经分配的资源，右边的图表示还需要分配的资源。最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。 

  检查一个状态是否安全的算法如下： 

  - 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。 
  - 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。 
  - 重复以上两步，直到所有进程都标记为终止，则状态时安全的。 

  如果一个状态不是安全的，需要拒绝进入这个状态

#### 怎么解除死锁

- 资源剥夺：挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他死锁进程（但应该防止被挂起的进程长时间得不到资源）； 
- 撤销进程：强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源（撤销的原则可以按进程优先级和撤销进程代价的高低进行）； 
- 进程回退：让一个或多个进程回退到足以避免死锁的地步。进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

#### 什么是缓冲区溢出？有什么危害

缓冲区为暂时置放输出或输入资料的内存。缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入是否合理。

计算机中，缓冲区溢出会造成的危害主要有以下两点：程序崩溃导致拒绝服务和跳转并且执行一段恶意代码。

#### 分页和分段的区别

1. 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的； 
2. 段的大小不固定，有它所完成的功能决定；页的大小固定，由系统决定； 
3. 段向用户提供二维地址空间；页向用户提供的是一维地址空间； 
4. 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制

#### 物理地址、逻辑地址、虚拟内存

1. **物理地址：**它是地址转换的最终地址，进程在运行时执行指令和访问数据最后都要通过物理地址从主存中存取，是内存单元真正的地址。 
2. **逻辑地址：**是指计算机用户看到的地址。例如：当创建一个长度为 100 的整型数组时，操作系统返回一个逻辑上的连续空间：指针指向数组第一个元素的内存地址。由于整型元素的大小为 4 个字节，故第二个元素的地址时起始地址加 4，以此类推。事实上，逻辑地址并不一定是元素存储的真实地址，即数组元素的物理地址（在内存条中所处的位置），并非是连续的，只是操作系统通过地址映射，将逻辑地址映射成连续的，这样更符合人们的直观思维。 
3. **虚拟内存：**是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

#### 页面置换算法

请求调页，也称按需调页，即对不在内存中的“页”，当进程执行时要用时才调入，否则有可能到程序结束时也不会调入。而内存中给页面留的位置是有限的，在内存中以帧为单位放置页面。为了防止请求调页的过程出现过多的内存页面错误（即需要的页面当前不在内存中，需要从硬盘中读数据，也即需要做页面的替换）而使得程序执行效率下降，我们需要设计一些页面置换算法，页面按照这些算法进行相互替换时，可以尽量达到较低的错误率。常用的页面置换算法如下： 

- ==先进先出置换算法（FIFO）== 先进先出，即淘汰最早调入的页面。 
- ==最佳置换算法（OPT）== 选未来最远将使用的页淘汰，是一种最优的方案，可以证明缺页数最小。 
- ==最近最久未使用（LRU）算法== 即选择最近最久未使用的页面予以淘汰 
- ==时钟（Clock）置换算法== 时钟置换算法也叫最近未用算法 NRU（Not RecentlyUsed）。该算法为每个页面设置一位访问位，将内存中的所有页面都通过链接指针链成一个循环队列。

#### 对动态链接库和静态链接库的理解

静态链接就是在编译链接时直接将需要的执行代码拷贝到调用处，优点就是在程序发布的时候就不需要的依赖库，也就是不再需要带着库一块发布，程序可以独立执行，但是体积可能会相对大一些。 

动态链接就是在编译的时候不直接拷贝可执行代码，而是通过记录一系列符号和参数，在程序运行或加载时将这些信息传递给操作系统，操作系统负责将需要的动态库加载到内存中，然后程序在运行到指定的代码时，去共享执行内存中已经加载的动态库可执行代码，最终达到运行时连接的目的。优点是多个程序可以共享同一段代码，而不需要在磁盘上存储多个拷贝，缺点是由于是运行时加载，可能会影响程序的前期执行性能

#### 外中断和异常有什么区别

外中断是指由 CPU 执行指令以外的事件引起，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。 

而异常时由 CPU 执行指令的内部事件引起，如非法操作码、地址越界、算术溢出等。

#### 一个程序从开始运行到结束的完整过程，你能说出来多少

四个过程： 

**预编译** 主要处理源代码文件中的以“#”开头的预编译指令。处理规则见下 

- 删除所有的#define，展开所有的宏定义。 
- 处理所有的条件预编译指令，如“#if”、“#endif”、“#ifdef”、“#elif”和“#else”。 
- 处理“#include”预编译指令，将文件内容替换到它的位置，这个过程是递归进行的，文件中包含其他 文件。 
- 删除所有的注释，“//”和“/**/”。 
- 保留所有的#pragma 编译器指令，编译器需要用到他们，如：#pragma once 是为了防止有文件被重 复引用。 
- 添加行号和文件标识，便于编译时编译器产生调试用的行号信息，和编译时产生编译错误或警告是 能够显示行号。 

**编译** 把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应的汇编代码文件。 

- 词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分割成一系列的记号。 
- 语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的语法树是一种以表达式为节点的树。 
- 语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定的语义。 
- 优化：源代码级别的一个优化过程。 
- 目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言表示。 
- 目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移来替代乘法运算、删除多余的指令等。 

**汇编** 

将汇编代码转变成机器可以执行的指令(机器码文件)。 汇编器的汇编过程相对于编译器来说更简单，没有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过来，汇编过程有汇编器as完成。 

经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Linux下)、xxx.obj(Windows下)。 

**链接** 

将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。链接分为静态链接和动态链接： 

- ==静态链接：== 函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。 空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本； 更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。 

  运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。 

- ==动态链接：== 动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。 

  共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副本，而是这多个程序在执行时共享同一份副本； 

  更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。 

  性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。

#### 用户态和内核态定义

用户态和内核态是操作系统的两种运行状态。 

- ==内核态：==处于内核态的 CPU 可以访问任意的数据，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况，一般处于特权级 0 的状态我们称之为内核态。 
- ==用户态：==处于用户态的 CPU 只能受限的访问内存，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。 

> 那么为什么要有用户态和内核态呢？ 

这个主要是访问能力的限制的考量，计算机中有一些比较危险的操作，比如设置时钟、内存清理，这些都需要在内核态下完成，如果随意进行这些操作，那你的系统得崩溃多少次。

#### 用户态和内核态是如何切换的

所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种模式下的转换，即用户态 -> 内核态 -> 用户态，而唯一能够做这些操作的只有 `系统调用`，而能够执行系统调用的就只有 `操作系统`。 

一般用户态 -> 内核态的转换我们都称之为 trap 进内核，也被称之为 `陷阱指令(trap instruction)`。 

他们的工作流程如下：

 ![](https://gitee.com/iamshuaidi/picture/raw/master/picture/v2-1dfd23c107cca552b4e511ed526f75c4_720w.jpg)

- 首先用户程序会调用 glibc 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。 
- glibc 库知道针对不同体系结构调用系统调用的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。 
- 然后，glibc 库调用软件中断指令(SWI) ，这个指令通过更新 CPSR 寄存器将模式改为超级用户模式，然后跳转到地址 0x08 处。 
- 到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问 
- 从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 vector_swi()。 
- 在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 sys_call_table 的索引，调转到系统调用函数。 
- 执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。

#### 进程的终止方式

**进程的终止** 

进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的 

- 正常退出(自愿的) 
- 错误退出(自愿的) 严
- 重错误(非自愿的) 
- 被其他进程杀死(非自愿的) 

**正常退出** 

多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 exit ，在 Windows 中是 ExitProcess。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它锁打开的任何临时文件，然后终止。 

**错误退出** 

进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令 

```tex
cc foo.c 
```

为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。 

**严重错误** 

进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。 

**被其他进程杀死** 

第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 TerminateProcess（注意不是系统调用）。

#### 守护进程、僵尸进程和孤儿进程

**守护进程** 

指在后台运行的，没有控制终端与之相连的进程。它独立于控制终端，周期性地执行某种任务。Linux的大多数服务器就是用守护进程的方式实现的，如web服务器进程http等 

创建守护进程要点： 

- 让程序在后台执行。方法是调用fork（）产生一个子进程，然后使父进程退出。 
- 调用setsid（）创建一个新对话期。控制终端、登录会话和进程组通常是从父进程继承下来的，守护进程要摆脱它们，不受它们的影响，方法是调用setsid（）使进程成为一个会话组长。setsid（）调用成功后，进程成为新的会话组长和进程组长，并与原来的登录会话、进程组和控制终端脱离。 
- 禁止进程重新打开控制终端。经过以上步骤，进程已经成为一个无终端的会话组长，但是它可以重新申请打开一个终端。为了避免这种情况发生，可以通过使进程不再是会话组长来实现。再一次通过fork（）创建新的子进程，使调用fork的进程退出。 
- 关闭不再需要的文件描述符。子进程从父进程继承打开的文件描述符。如不关闭，将会浪费系统资源，造成进程所在的文件系统无法卸下以及引起无法预料的错误。首先获得最高文件描述符值，然后用一个循环程序，关闭0到最高文件描述符值的所有文件描述符。 
- 将当前目录更改为根目录。 
- 子进程从父进程继承的文件创建屏蔽字可能会拒绝某些许可权。为防止这一点，使用unmask（0）将屏蔽字清零。 
- 处理SIGCHLD信号。对于服务器进程，在请求到来时往往生成子进程处理请求。如果子进程等待父进程捕获状态，则子进程将成为僵尸进程（zombie），从而占用系统资源。如果父进程等待子进程结束，将增加父进程的负担，影响服务器进程的并发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，子进程结束时不会产生僵尸进程。 

**孤儿进程** 

如果父进程先退出，子进程还没退出，那么子进程的父进程将变为init进程。（注：任何一个进程都必须有父进程）。 

一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 

**僵尸进程** 

如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。 

设置僵尸进程的==目的==是维护子进程的信息，以便父进程在以后某个时候获取。这些信息至少包括进程ID，进程的终止状态，以及该进程使用的CPU时间，所以当终止子进程的父进程调用wait或waitpid时就可以得到这些信息。如果一个进程终止，而该进程有子进程处于僵尸状态，那么它的所有僵尸子进程的父进程ID将被重置为1（init进程）。继承这些子进程的init进程将清理它们（也就是说init进程将wait它们，从而去除它们的僵尸状态）。

#### 如何避免僵尸进程

- 通过signal(SIGCHLD, SIG_IGN)通知内核对子进程的结束不关心，由内核回收。如果不想让父进程挂起，可以在父进程中加入一条语句：signal(SIGCHLD,SIG_IGN);表示父进程忽略SIGCHLD信号，该信号是子进程退出的时候向父进程发送的。 
- 父进程调用wait/waitpid等函数等待子进程结束，如果尚无子进程退出wait会导致父进程阻塞。waitpid可以通过传递WNOHANG使父进程不阻塞立即返回。 
- 如果父进程很忙可以用signal注册信号处理函数，在信号处理函数调用wait/waitpid等待子进程退出。 
- 通过两次调用fork。父进程首先调用fork创建一个子进程然后waitpid等待子进程退出，子进程再fork一个孙进程后退出。这样子进程退出后会被父进程等待回收，而对于孙子进程其父进程已经退出所以孙进程成为一个孤儿进程，孤儿进程由init进程接管，孙进程结束后，init会等待回收。 

第一种方法忽略SIGCHLD信号，这常用于并发服务器的性能的一个技巧因为并发服务器常常fork很多子进程，子进程终结之后需要服务器进程去wait清理资源。如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给init进程去处理，省去了大量僵尸进程占用系统资源。

#### 介绍一下几种典型的锁

**读写锁** 

- 多个读者可以同时进行读 
- 写者必须互斥（只允许一个写者写，也不能读者写者同时进行） 
- 写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者） 

**互斥锁** 

一次只能一个线程拥有互斥锁，其他线程只有等待 

互斥锁是在抢锁失败的情况下主动放弃CPU进入睡眠状态直到锁的状态改变时再唤醒，而操作系统负责线程调度，为了实现锁的状态发生改变时唤醒阻塞的线程或者进程，需要把锁交给操作系统管理，所以互斥锁在加锁操作时涉及上下文的切换。互斥锁实际的效率还是可以让人接受的，加锁的时间大概100ns左右，而实际上互斥锁的一种可能的实现是先自旋一段时间，当自旋的时间超过阀值之后再将线程投入睡眠中，因此在并发运算中使用互斥锁（每次占用锁的时间很短）的效果可能不亚于使用自旋锁 

**条件变量** 

互斥锁一个明显的缺点是他只有两种状态：锁定和非锁定。而条件变量通过允许线程阻塞和等待另一个线程发送信号的方法弥补了互斥锁的不足，他常和互斥锁一起使用，以免出现竞态条件。当条件不满足时，线程往往解开相应的互斥锁并阻塞线程然后等待条件发生变化。一旦其他的某个线程改变了条件变量，他将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程。总的来说`互斥锁是线程间互斥的机制，条件变量则是同步机制`。

**自旋锁** 

如果进线程无法取得锁，进线程不会立刻放弃CPU时间片，而是一直循环尝试获取锁，直到获取为止。如果别的线程长时期占有锁，那么自旋就是在浪费CPU做无用功，但是自旋锁一般应用于加锁时间很短的场景，这个时候效率比较高。

#### 常见内存分配内存错误

- 内存分配未成功，却使用了它。 

  编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行检查。如果是用malloc或new来申请内存，应该用if(pNULL) 或if(p!=NULL)进行防错处理。 

- 内存分配虽然成功，但是尚未初始化就引用它。 

  犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。 

- 内存分配成功并且已经初始化，但操作越过了内存的边界。 

  例如在使用数组时经常发生下标“多1”或者“少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。 

- 忘记了释放内存，造成内存泄露。 

  含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然挂掉，系统出现提示：内存耗尽。动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。 

- 释放了内存却继续使用它。常见于以下有三种情况： 

  - 程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。 
  - 函数的return语句写错了，注意不要返回指向“栈内存”的“指针”或者“引用”，因为该内存在函数体结束时被自动销毁。 
  - 使用free或delete释放了内存后，没有将指针设置为NULL。导致产生“野指针”。

#### 内存交换中，被换出的进程保存在哪里

保存在磁盘中，也就是外存中。具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式;对换区空间只占磁盘空间的小部分，被换出的进程数据就存放在对换区。由于对换的速度直接影响到系统的整体速度，因此对换区空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式(学过文件管理章节后即可理解)。总之，对换区的I/O速度比文件区的更快。

#### 原子操作是如何实现的

==处理器使用基于对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作。==首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。Pentium 6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器是不能自动保证其原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。但是，处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 

- ==使用总线锁保证原子性== 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，如图下图所示。

  “`c++ CPU1 CPU2 i=1 i=1 i+1 i+1 i=2 i=2Copy to clipboardErrorCopied “` 

  原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 

  处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。 

- ==使用缓存锁保证原子性== 第二个机制是通过缓存锁定来保证原子性。在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 

  频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。 所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为==缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，在如上图所示的例子中，当CPU1修改缓存行中的i时使用了缓存锁定，那么CPU2就不能使用同时缓存i的缓存行。== 

  但是有两种情况下处理器不会使用缓存锁定。 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。

#### 抖动你知道是什么吗？它也叫颠簸现象

刚刚换出的页面马上又要换入内存，刚刚换入的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数(分配给进程的物理块不够) 为进程分配的物理块太少，会使进程发生抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率 为了研究为应该为每个进程分配多少个物理块，Denning 提出了进程工作集” 的概念

# 设计模式

## 设计模式分类

总共有 23 种设计模式。这些模式可以分为四大类：**创建型模式**（Creational Patterns）、**结构型模式**（Structural Patterns）、**行为型模式**（Behavioral Patterns）、**J2EE 设计模式**。 

| 序号 | 模式 & 描述                                                  | 包括                                                         |
| :--- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 1    | **创建型模式** 这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 | 工厂模式（Factory Pattern）<br />抽象工厂模式（Abstract Factory Pattern）<br />单例模式（Singleton Pattern）<br />建造者模式（Builder Pattern）<br />原型模式（Prototype Pattern） |
| 2    | **结构型模式** 这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 | 适配器模式（Adapter Pattern）<br />桥接模式（Bridge Pattern）<br />过滤器模式（Filter、Criteria Pattern）<br />组合模式（Composite Pattern）<br />装饰器模式（Decorator Pattern）<br />外观模式（Facade Pattern）<br />享元模式（Flyweight Pattern）<br />代理模式（Proxy Pattern） |
| 3    | **行为型模式** 这些设计模式特别关注对象之间的通信。          | 责任链模式（Chain of Responsibility Pattern）<br />命令模式（Command Pattern）<br />解释器模式（Interpreter Pattern）<br />迭代器模式（Iterator Pattern）<br />中介者模式（Mediator Pattern）<br />备忘录模式（Memento Pattern）<br />观察者模式（Observer Pattern）<br />状态模式（State Pattern）<br />空对象模式（Null Object Pattern）<br />策略模式（Strategy Pattern）<br />模板模式（Template Pattern）<br />访问者模式（Visitor Pattern） |
| 4    | **J2EE 模式** 这些设计模式特别关注表示层。这些模式是由 Sun Java Center 鉴定的。 | MVC 模式（MVC Pattern）业务代表模式（Business Delegate Pattern）组合实体模式（Composite Entity Pattern）数据访问对象模式（Data Access Object Pattern）前端控制器模式（Front Controller Pattern）拦截过滤器模式（Intercepting Filter Pattern）服务定位器模式（Service Locator Pattern）传输对象模式（Transfer Object Pattern） |

## 设计模式的六大原则

**1、开闭原则（Open Close Principle）**

开闭原则的意思是：**对扩展开放，对修改关闭**。在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热插拔的效果。简言之，是为了使程序的扩展性好，易于维护和升级。想要达到这样的效果，我们需要使用接口和抽象类，后面的具体设计中我们会提到这点。

**2、里氏代换原则（Liskov Substitution Principle）**

里氏代换原则是面向对象设计的基本原则之一。 里氏代换原则中说，任何基类可以出现的地方，子类一定可以出现。LSP 是继承复用的基石，只有当派生类可以替换掉基类，且软件单位的功能不受到影响时，基类才能真正被复用，而派生类也能够在基类的基础上增加新的行为。里氏代换原则是对开闭原则的补充。实现开闭原则的关键步骤就是抽象化，而基类与子类的继承关系就是抽象化的具体实现，所以里氏代换原则是对实现抽象化的具体步骤的规范。

**3、依赖倒转原则（Dependence Inversion Principle）**

这个原则是开闭原则的基础，具体内容：针对接口编程，依赖于抽象而不依赖于具体。

**4、接口隔离原则（Interface Segregation Principle）**

这个原则的意思是：使用多个隔离的接口，比使用单个接口要好。它还有另外一个意思是：降低类之间的耦合度。由此可见，其实设计模式就是从大型软件架构出发、便于升级和维护的软件设计思想，它强调降低依赖，降低耦合。

**5、迪米特法则，又称最少知道原则（Demeter Principle）**

最少知道原则是指：一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。

**6、合成复用原则（Composite Reuse Principle）**

合成复用原则是指：尽量使用合成/聚合的方式，而不是使用继承。

## 设计模式

### 工厂模式

**定义**

在基类中定义创建对象的一个接口，让子类决定实例化哪个类。工厂方法让一个类的实例化延迟到子类中进行。 

**工厂模式的分类**：
（1）简单工厂（Simple Factory）模式，又称静态工厂方法模式（Static Factory Method Pattern）。

（2）工厂方法（Factory Method）模式，又称多态性工厂（Polymorphic Factory）模式或虚拟构造子（Virtual Constructor）模式；

（3）抽象工厂（Abstract Factory）模式，又称工具箱（Kit 或Toolkit）模式。
在开源框架中的使用

**举两个比较常见的例子:**

(1)Spring中通过getBean(“xxx”)获取Bean；

**为什么要用工厂模式**
(1) 解耦 ：把对象的创建和使用的过程分开

(2)降低代码重复: 如果创建某个对象的过程都很复杂，需要一定的代码量，而且很多地方都要用到，那么就会有很多的重复代码。

(3) 降低维护成本 ：由于创建过程都由工厂统一管理，所以发生业务逻辑变化，不需要找到所有需要创建对象B的地方去逐个修正，只需要在工厂里修改即可，降低维护成本。

**简单工厂模式**

严格的说，简单工厂模式并不是23种常用的设计模式之一，它只算工厂模式的一个特殊实现。简单工厂模式在实际中的应用相对于其他2个工厂模式用的还是相对少得多，因为它只适应很多简单的情况。

最重要的是它违背了开闭原则（虽然可以通过反射的机制来避免）。因为每次你要新添加一个功能，都需要在生switch-case 语句（或者if-else 语句）中去修改代码，添加分支条件。

**工厂方法模式**

工厂方法模式应该是在工厂模式家族中使用的最多模式。

它是简单工厂模式的仅一步深化， 在工厂方法模式中，我们不再提供一个统一的工厂类来创建所有的对象，而是针对不同的对象提供不同的工厂。也就是说 **每个对象都有一个与之对应的工厂** 。

**应用实例：** 1、你需要一辆汽车，可以直接从工厂里面提货，而不用去管这辆汽车是怎么做出来的，以及这个汽车里面的具体实现。 

**优点：** 1、一个调用者想创建一个对象，只要知道其名称就可以了。 2、扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以。 3、屏蔽产品的具体实现，调用者只关心产品的接口。

**缺点：**每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。

**使用场景：** 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，"POP3"、"IMAP"、"HTTP"，可以把这三个作为产品类，共同实现一个接口。 

**抽象工厂模式**

抽象工厂模式是工厂方法的仅一步深化，在这个模式中的工厂类不单单可以创建一种产品，而是可以创建一组产品。 

**适用场景**

- 和工厂方法一样客户端不需要知道它所创建的对象的类。
- 需要一组对象共同完成某种功能时，并且可能存在多组对象完成不同功能的情况。（同属于同一个产品族的产品）
- 系统结构稳定，不会频繁的增加对象。（因为一旦增加就需要修改原有代码，不符合开闭原则）

**优点：**当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。

**缺点：**产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。

**使用场景：** 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。

### 建造者模式

无论是在现实世界中还是在软件系统中，都存在一些复杂的对象，它们拥有多个组成部分，如汽车，它包括车轮、方向盘、发动机等各种部件。而对于大多数用户而言，无须知道这些部件的装配细节，也几乎不会使用单独某个部件，而是使用一辆完整的汽车，可以通过建造者模式对其进行设计与描述，建造者模式可以将部件和其组装过程分开，一步一步创建一个复杂的对象。用户只需要指定复杂对象的类型就可以得到该对象，而无须知道其内部的具体构造细节.

**意图：**将一个复杂的构建与其表示相分离，使得同样的构建过程可以创建不同的表示。

**主要解决：**主要解决在软件系统中，有时候面临着"一个复杂对象"的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。

**何时使用：**一些基本部件不会变，而其组合经常变化的时候。

**如何解决：**将变与不变分离开。

**关键代码：**建造者：创建和提供实例，导演：管理建造出来的实例的依赖关系。

**应用实例：** 1、去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的"套餐"。 2、JAVA 中的 StringBuilder。

**优点：** 1、建造者独立，易扩展。 2、便于控制细节风险。

**缺点：** 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。

**使用场景：** 1、需要生成的对象具有复杂的内部结构。 2、需要生成的对象内部属性本身相互依赖。

**注意事项：**与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。

### 单例模式

##### 懒汉式

**是否 Lazy 初始化：**是

**是否多线程安全：**是

**实现难度：**易

**描述：**这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。

优点：第一次调用才初始化，避免内存浪费。

缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。

getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。

##### 饿汉式

**是否 Lazy 初始化：**否

**是否多线程安全：**是

**实现难度：**易

**描述：**这种方式比较常用，但容易产生垃圾对象。

优点：没有加锁，执行效率会提高。

缺点：类加载时就初始化，浪费内存。

它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载，这时候初始化 instance 显然没有达到 lazy loading 的效果。

##### 双检锁/双重校验

如果两个线程一起调用getInstance方法，并且都通过了第一次的判断instance==null，那么第一个线程获取了锁，然后实例化了instance，然后释放了锁，然后第二个线程得到了线程，然后马上也实例化了instance，这就尴尬了。单例模式就失败了。
所以加上第二次判断后，先进来的线程判断了一下，哦，为空，我创建一个，然后创建一个实例之后释放了锁，第二个线程进来之后，哎？已经有了，那我就不用创建了，然后释放了锁，开开心心的完成了单例模式。

**JDK 版本：**JDK1.5 起

**是否 Lazy 初始化：**是

**是否多线程安全：**是

**实现难度：**较复杂

**描述：**这种方式采用双锁机制，安全且在多线程情况下能保持高性能。

getInstance() 的性能对应用程序很关键。

———————————————————————————

```java
public class Singleton {  
	private volatile static Singleton singleton;  
	private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
        	if (singleton == null) {  
            	singleton = new Singleton();  
        	}  
        }
    }  
    return singleton;  
    }  
}
```



##### 登记式/静态内部类

**是否 Lazy 初始化：**是

**是否多线程安全：**是

**实现难度：**一般

**描述：**这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。

这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是：第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果），而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用，只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下，如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。



public class Singleton {  

​    private static class SingletonHolder {  

​    private static final Singleton INSTANCE = new Singleton();  

​    }  

​    private Singleton (){}  

​    public static final Singleton getInstance() {  

​    return SingletonHolder.INSTANCE;  

​    }  

}



### 代理模式

**意图：**为其他对象提供一种代理以控制对这个对象的访问。

**主要解决：**在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。

**何时使用：**想在访问一个类时做一些控制。

**如何解决：**增加中间层。

**关键代码：**实现与被代理类组合。

**应用实例：** 1、Windows 里面的快捷方式。 2、猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类。 3、买火车票不一定在火车站买，也可以去代售点。 4、一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制。 5、spring aop。

**优点：** 1、职责清晰。 2、高扩展性。 3、智能化。

**缺点：** 1、由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢。 2、实现代理模式需要额外的工作，有些代理模式的实现非常复杂。

**使用场景：**按职责来划分，通常有以下使用场景： 1、远程代理。 2、虚拟代理。 3、Copy-on-Write 代理。 4、保护（Protect or Access）代理。 5、Cache代理。 6、防火墙（Firewall）代理。 7、同步化（Synchronization）代理。 8、智能引用（Smart Reference）代理。

**注意事项：** 1、和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口。 2、和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制。

### 适配器模式

适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。

这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。

我们通过下面的实例来演示适配器模式的使用。其中，音频播放器设备只能播放 mp3 文件，通过使用一个更高级的音频播放器来播放 vlc 和 mp4 文件。

**意图：**将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。

**主要解决：**主要解决在软件系统中，常常要将一些"现存的对象"放到新的环境中，而新环境要求的接口是现对象不能满足的。

**何时使用：** 1、系统需要使用现有的类，而此类的接口不符合系统的需要。 2、想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口。 3、通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。）

**如何解决：**继承或依赖（推荐）。

**关键代码：**适配器继承或依赖已有的对象，实现想要的目标接口。

**应用实例：** 1、美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V。 2、JAVA JDK 1.1 提供了 Enumeration 接口，而在 1.2 中提供了 Iterator 接口，想要使用 1.2 的 JDK，则要将以前系统的 Enumeration 接口转化为 Iterator 接口，这时就需要适配器模式。 3、在 LINUX 上运行 WINDOWS 程序。 4、JAVA 中的 jdbc。

**优点：** 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。

**缺点：** 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。

**使用场景：**有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。

**注意事项：**适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。

## 设计模式之间的区别

#### 抽象工厂的工厂和工厂方法中的工厂

**抽象工厂是生产一整套有产品的工厂（至少要生产两个产品)，这些产品必须相互是有关系或有依赖的，而工厂方法中的工厂是生产单一产品的工厂。**

#### 抽象工厂模式VS建造者模式

抽象工厂模式实现对产品家族的创建，一个产品家族是这样的一系列产品：具有不同分类维度的产品组合，采用抽象工厂模式不需要关心构建过程，只关心什么产品由什么工厂生产即可。而建造者模式则是要求按照指定的蓝图建造产品，它的主要目的是通过组装零配件而产生一个新产品。

## 单例模式

**意图：**保证一个类仅有一个实例，并提供一个访问它的全局访问点。

**主要解决：**一个全局使用的类频繁地创建与销毁。

**何时使用：**当您想控制实例数目，节省系统资源的时候。

**如何解决：**判断系统是否已经有这个单例，如果有则返回，如果没有则创建。

**关键代码：**构造函数是私有的。

**应用实例：**

- 1、一个班级只有一个班主任。
- 2、Windows 是多进程多线程的，在操作一个文件的时候，就不可避免地出现多个进程或线程同时操作一个文件的现象，所以所有文件的处理必须通过唯一的实例来进行。
- 3、一些设备管理器常常设计为单例模式，比如一个电脑有两台打印机，在输出的时候就要处理不能两台打印机打印同一个文件。

**优点：**

- 1、在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存）。
- 2、避免对资源的多重占用（比如写文件操作）。

**缺点：**没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。

**使用场景：**

- 1、要求生产唯一序列号。
- 2、WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。
- 3、创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。

**注意事项：**getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。

**实现：**懒汉式，饿汉式，双检锁/双重校验锁，登记式/静态内部类，枚举

```java
//双重检查锁定
public class Singleton {  
    private volatile static Singleton singleton;  
    private Singleton (){}  
    public static Singleton getSingleton() {  
    if (singleton == null) {  
        synchronized (Singleton.class) {  
            if (singleton == null) {  
                singleton = new Singleton();  
            }  
        }  
    }  
    return singleton;  
    }  
}
```

```javaj a
singleton = new Singleton();
```

这句话不是原子操作，分为三个操作。重排序会出现问题。可能排序为132，另一个线程访问被返回未初始化完全的对象。这个时候就需要volatile禁止指令重排序。

1.给 Singleton 分配内存；

2.调用 Singleton 的构造函数来初始化成员变量；

3.将给 singleton 对象指向分配的内存空间（此时 singleton 才不为 null ）；

# Linux和GIT

## Linux

**Linux查看端口占用情况**

> - netstat  -anp|grep  端口号 

> 方法一：
>
> 1.先用ps -ef | grep xxx(某个进程)，可以查看某个进程的pid。
>
> 2.再用netstat -anp | grep pid号，可以查看到该进程占用的端口号!
>
> 方法二：
>
> 直接用**lsof**命令可以查看端口使用情况!

 **如何查看磁盘还有多少剩余空间** 

 这里主要可以用 df -ah 命令来查看，df 是用来查看文件系统磁盘空间使用情况的命令，-a 显示所有文件系统，-h 用人们可读的方式进行显示。 

**如何查看某个进程对 CPU 的使用情况**

1） 可以使用 top 命令

top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。

2） 使用 ps 命令

ps aux 可以显示所有使用者的进程，最常用的方法是ps aux，然后再利用一个管道符号导向到grep去查找特定的进程。比如查看nginx 进程可以用 

ps aux | grep nginx

**查看当前系统正在运行进程**

ps -ef / ps -aux

**查找正在执行的tomcat** 

ps -ef | grep tomcat 

### 一些基本的指令

cd / ： 返回到根目录
cd ~ ：返回到用户的主目录
cd ../ ： 返回上一级
内容：蓝色的是文件夹，白色的是文件，青蓝色是软连接（快捷方式），红色的是压缩包
mkdir ：创建文件夹
touch：创建文件
vi ：创建文件并编辑文件（a：进入编辑；esc退出编辑）
:q! ：不保存直接退出
:wq! :保存并退出
rm -rf ：删除
cat 文件名 ：查看文件（cat 是要一次性显示出来全部信息，当文件很大的时候容易卡顿死机）
more 文件名：查看文件（more 查看的时候，会分批查看）
**tail -x 文件名（查看文件x条信息）**
**tail -f 文件（查看文件的实时变化情况）**
ctrl + c 在linux中表示中断
yum 安装jdk1.8（ yum install -y java-1.8.0-openjdk-devel.x86_64）
sz 文件名 ：下载文件
（命令都是shell语言）
chmod 777 *：修改权限的作用（ 777分别代表用户可读可写可执行的作用）
find / -name 文件名 ：查找文件
mv ：剪切
ps -ef | grep tomcat ：查找正在执行的tomcat 
top ：查找那个性能消耗高（可以在任何目录下使用，ctrl + c 中断）



杀死进程：

配合ps指令使用

**方法二: 通过kill 进程id的方式可以实现,**

首先需要知道进程id, 例如,想要杀死firefox的进程,通过 ps -ef|grep firefox,可以查到firefox的进程id:

然后通过 kill 3781 就可以关闭进程了.

补充: 1. kill -9 来强制终止退出, 例如: kill -9 3781

**方法三: killall 通过程序的名字,来杀死进程**

例如: killall firefox
注意: 该命令可以使用 -9 参数来强制杀死进程, killall -9 firefox

方法四: pkill 通过程序的名字, 直接杀死所有进程
例如: pkill firefox

**方法五: 通过xkill 可以杀死图形程序应用, 例如firefox崩溃无响应,可以使用该命令.**
例如: 用法xkill , 会出现一个白色的x, 然后用鼠标单击想要杀死的应用,如
————————————————

### linux项目部署

**简单的**

将程序打包成war包（通过代码生成），通过rz命令上传到tomcat的webapp文件夹底下，tomcat会自动解压，然后直接运行tomcat就行

**用docker的**

将程序打包成war包，通过rz传到docker容器里面，（docker里面的vi和rz命令需要下载），然后重启tomcat，（docker里面有tomcat镜像，支持部署多个tomcat）

## Git

### git merge/rebase

#### Merge

当你运行 git merge 时，你的 HEAD 分支会生成一个新的提交，并保留每个提交历史的祖先。

![img](https://pic3.zhimg.com/80/v2-2f63458fe8dac6f680faf9c1fa4757a2_1440w.jpg)


Fast forward merge是一种不创建提交的合并类型，会更新分支指针到上一次提交。

\#### 优点

\- 使用简单，易于理解。
\- 保持源分支的原始上下文。
\- 源分支上的提交与其他分支的提交是分开的。
\- 可以保留提交历史。

\#### 缺点

\- 乱

#### Rebase

Rebase是将一个分支的修改重写到另一个分支上，而不需要创建新的提交。

你在特性分支上的每一个提交，都会在主分支上创建一个新的提交。这看起来就像这些提交一直是写在主分支之上的一样。

![img](https://pic1.zhimg.com/80/v2-2a15d46ba3e165689147a223570cd4dc_1440w.jpg)

\#### 优点

\- 代码历史是简化的、线性的、可读的。
\- 与许多独立的特性分支的提交历史相比，操作单个提交历史更容易。
\- 干净、清晰的提交信息可以更好地跟踪一个bug或何时引入的某个功能。可以避免众多的单行提交污染历史。

\#### 缺点

\- 会更改历史提交时间，可能会丢失上下文。

# 框架

### 简述SSM框架

SSM框架的基本原理分三层解释为：

**SpringMVC：**

1.客户端发送请求到DispacherServlet（分发器）

2.由DispacherServlet控制器查询HanderMapping，找到处理请求的Controller

3.Controller调用业务逻辑处理后，返回ModelAndView

4.DispacherSerclet查询视图解析器，找到ModelAndView指定的视图

5.视图负责将结果显示到客户端

**Spring：**

我们平时开发接触最多的估计就是IOC容器，它可以装载bean（也就是我们Java中的类，当然也包括service dao里面的），有了这个机制，我们就不用在每次使用这个类的时候为它初始化，很少看到关键字new。另外spring的aop，事务管理等等都是我们经常用到的。

**Mybatis：**

mybatis是对jdbc的封装，它让数据库底层操作变的透明。mybatis的操作都是围绕一个sqlSessionFactory实例展开的。mybatis通过配置文件关联到各实体类的Mapper文件，Mapper文件中配置了每个类对数据库所需进行的sql语句映射。在每次与数据库交互时，通过sqlSessionFactory拿到一个sqlSession，再执行sql命令

### Spring和SpringMVC的区别

首先 springmvc和spring它俩都是容器，容器就是管理对象的地方，例如Tomcat，就是管理servlet对象的，而springMVC容器和spring容器，就是管理bean对象的地方，再说的直白点，springmvc就是管理controller对象的容器，spring就是管理service和dao的容器，这下你明白了吧。所以我们在springmvc的配置文件里配置的扫描路径就是controller的路径，而spring的配置文件里自然配的就是service和dao的路径 

其次， spring容器和springmvc容器的关系是父子容器的关系。spring容器是父容器，springmvc是子容器。在子容器里可以访问父容器里的对象，但是在父容器里不可以访问子容器的对象，说的通俗点就是，在controller里可以访问service对象，但是在service里不可以访问controller对象

　　所以这么看的话，所有的bean，都是被spring或者springmvc容器管理的，他们可以直接注入。然后springMVC的拦截器也是springmvc容器管理的，所以在springmvc的拦截器里，可以直接注入bean对象。

### IOC和AOP

#### IOC:

控制反转，是一种降低对象之间耦合关系的设计思想，它的**主要目的**是借助于“第三方”(Spring 中的 IOC 容器) 实现具有依赖关系的对象之间的解耦(IOC容器管理对象，你只管使用即可)，从而降低代码之间的耦合度。

面试的时候最好能说出来个**例子**，加深理解。例子：租房子，以前租房子需要一个房子一个房子找，费时费力，然后现在加入一个房屋中介，把你需要的房型告诉中介，就可以直接选到需要的房子，中介就相当于spring容器。

实现原理简述：

- 创建xml配置文件，配置要创建的对象类
- 通过反射创建实例
- 获取需要注入的接口实现类并将其赋值给该接口

IOC（控制反转），这是spring的核心，他将对象的创建和调用交由了spring进行管理。你只需提供你需要哪个对象，他便能帮你创建好，你不必去关心实现的细节等。就好比你通过中介找对象一样，只需提要求，中介就会吧符合要求的姑娘推给你供你使用。所以类的创建、销毁都是由spring来控制，也就是说控制对象生存周期的不在是引用他的对象，而是spring。 **IoC 容器是 Spring 用来实现 IoC 的载体，  IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。** **IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。**实际项目中一个 Service 类可能有几百甚至上千个类作为它的底层，假如我们需要实例化这个 Service，你可能要每次都要搞清这个 Service 所有底层类的构造函数，这可能会把人逼疯。如果利用 IoC 的话，你只需要配置好，然后在需要的地方引用就行了，这大大增加了项目的可维护性且降低了开发难度。

ioc底层有用到反射，面试时如果可以扯一扯Java基础反射相关的东西；

![image-20210802002738276](https://gitee.com/powerfulboy/note-img/raw/master/image-20210802002738276.png)

ioc实现控制反转和依赖注入的两个阶段

![image-20210730155615101](https://gitee.com/powerfulboy/note-img/raw/master/HDAK8ul4kj7qUtB.png)

**俩种IOC容器**

* BeanFactory
  * 基础类型IOC容器，默认采用延迟初始化策略，容器启动初期速度较快，适合资源有限、功能要求不是很严格的场景。
* ApplicationContext
  * 是BeanFactory的子类，可以看作是更强大的BeanFactory
  * 提供了除beanfactory之外的高级特性，如事件发布、国际化信息支持等。
  * 系统资源要求较高，启动时完成所以初始化。



#### AOP

面向切面编程，是面向对象开发的一种补充，指不改变原来模型的基础上动态的修改模型以满足新的需求，如：动态的增加日志、权限等。AOP使业务逻辑各部分间的耦合度降低，提高程序可重用性，提高开发效率。

能够将那些与业务无关，**却为业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来**，便于**减少系统的重复代码**，**降低模块间的耦合度**，并**有利于未来的可拓展性和可维护性**。

使用aop之后将一些通用的功能抽象出来，在需要用到的地方直接使用即可，这样就大大的简化了的代码量，增加新功能也很方便，日志功能和事务管理都使用了aop。

AOP是由**代理模式实现**的（利用**反射和动态编译**将代理模式变成动态的），在java中采用的是JDK动态代理模式，但是JDK动态代理只适合代理接口而不适合代理类(这是因为对象分为代理对象和被代理对象嘛。如果代理一个类，那么代理对象也会继承类的字段，然后这些字段是实际上是不会被使用的，就比较浪费，所以只会代理接口)

**AOP实现原理简述**：Spring AOP同时支持CGLIB和JDK动态代理，它们是来回切换的

有实现接口的情况为JDK动态代理，横向抽取机制

没实现接口的情况为cglib动态代理

### spring设计模式

https://zhidao.baidu.com/question/1674417593883168307.html

**1.工厂模式**，这个很明显，在各种BeanFactory以及ApplicationContext创建中都用到了；
**2.模版模式**，这个也很明显，在各种BeanFactory以及ApplicationContext实现中也都用到了；
**3.代理模式**，在Aop实现中用到了JDK的动态代理；
**4.策略模式**，第一个地方，加载资源文件的方式，使用了不同的方法，比如：ClassPathResourece，FileSystemResource，ServletContextResource，UrlResource但他们都有共同的借口Resource；第二个地方就是在Aop的实现中，采用了两种不同的方式，JDK动态代理和CGLIB代理；
**5.单例模式**，这个比如在创建bean的时候。

### Spring注解

**@Component**

**作用：**调用无参构造创建一个bean对象，并把对象存入spring的IOC容器，交由spring容器进行管理。相当于在xml中配置一个bean。

**@Controller**

**作用：**作用上与@Component。一般用于表现层的注解。

**@Service**

**作用：**作用上与@Component。一般用于业务层的注解。

**@Repository**

**作用：**作用上与@Component。一般用于持久层的注解。

**@Bean**

**作用：**用于把当前方法的返回值作为bean对象存入spring的ioc容器中

**@Autowired和@Resource**

@Resource和@Autowired都是做bean的注入时使用，其实@Resource并不是Spring的注解，它的包是javax.annotation.Resource，需要导入，但是Spring支持该注解的注入。

- ==作用：==@Autowire和@Resource都是Spring支持的注解形式动态装配bean的方式。Autowire默认按照类型(byType)装配，如果想要按照名称(byName)装配，需结合@Qualifier注解使用。
- ==共同点：==两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。
- ==不同点：==
  - @Autowired为Spring提供的注解，需要导入包org.springframework.beans.factory.annotation.Autowired;只按照byType注入。
  - @Autowired注解是按照类型（byType）装配依赖对象，默认情况下它要求依赖对象必须存在，如果允许null值，可以设置它的required属性为false。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。
  - @Resource默认按照ByName自动注入，由J2EE提供，需要导入包javax.annotation.Resource。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。

### Spring中Bean的创建流程

![](//upload-images.jianshu.io/upload_images/6292941-18712c0427c127c6.png?imageMogr2/auto-orient/strip|imageView2/2/w/771/format/webp)

- 利用该类的构造方法来实例化得到一个对象（但是如果一个类中有多个构造方法， Spring则会进行选择，这个叫做推断构造方法，下文在详细介绍）
- 得到一个对象后，Spring会判断该对象中是否存在被@Autowired注解了的属 性，把这些属性找出来并由Spring进行赋值（依赖注入）
- 依赖注入后，Spring会判断该对象是否实现了BeanNameAware接口、 BeanClassLoaderAware接口、BeanFactoryAware接口，如果实现了，就表示当前 对象必须实现该接口中所定义的setBeanName()、setBeanClassLoader()、 setBeanFactory()方法，那Spring就会调用这些方法并传入相应的参数
- Aware回调后，Spring会判断该对象中是否存在某个方法被@PostConstruct注解 了，如果存在，Spring会调用当前对象的此方法（初始化前），上面的代码中初始化了一个adminUser的数据。
- 紧接着，Spring会判断该对象是否实现了InitializingBean接口，如果实现了，就 表示当前对象必须实现该接口中的afterPropertiesSet()方法，那Spring就会调用当前对象中的afterPropertiesSet()方法（初始化）
- 最后，Spring会判断当前对象需不需要进行AOP，如果不需要那么Bean就创建完 了，如果需要进行AOP，则会进行动态代理并生成一个代理对象做为Bean（初始化 后）
  关于第6步控制台没办法打出日志，因为初始后涉及到spring的源码操作，但是可以通过断点看一下，提一句例子中UserService是被LogAspect切面切的。

### springbean的生命周期

1. 实例化 Instantiation
2. 属性赋值 Populate
3. 初始化 Initialization
4. 销毁 Destruction

实例化 -> 属性赋值 -> 初始化 -> 销毁

首先是AbstractApplicationContext的refresh方法刷新容器，然后初始化一些Bean的扩展接口，比如BeanDefinitionRegister这种，spring.factories的处理

 然后: 是InstantiationAwareBeanPostProcessor的实例化前置接口调用，他会在构造方法之前调用，构造之后还会有MergedBeanDefinitionPostProcessor处理， 

然后: 就到属性填充阶段(populateBean)，调用InstantiationAwareBeanPostProcessor后置接口，Autowire注入处理， InstantiationAwareBeanPostProcessor的postProcessPropertyValues调用 

然后: initializeBean进行Bean初始化，包括Aware系列接口调用，BeanPostProcessor前置方法，然后是相关的初始化方法，比如@Bean的init-method、 InitializingBean，后面BeanPostProcessor后置方法 然后：后面就是使用，销毁阶段...

### spring解决循环依赖注入

- 你知道**循环依赖有哪几种形式**吗？
- 答：属性注入，构造方法注入，也可以是setter方法注入，因此对应有三种循环依赖的形式。

- 问：嗯，那你知道这几种循环依赖，哪些是没有问题的，哪些是程序会报错导致不能启动的吗？
- 答：构造依赖会报错，其他两种是不会报错的，程序是可以正常启动的。

1. `singletonObjects`，一级缓存，存储的是所有创建好了的单例Bean
2. `earlySingletonObjects`，二级缓存，完成实例化，但是还未进行属性注入及初始化的对象
3. `singletonFactories`，三级缓存，提前暴露的一个单例工厂，二级缓存中存储的就是从这个工厂中获取到的对象

1.一级缓存获取，获取不到再去二级缓存获取

*2.二级缓存获取，获取不到再去三级缓存*

3.三级缓存获取，并移动到二级缓存，并清空三级缓存

**Spring 是如何解决的循环依赖？**

Spring 为了解决单例的循环依赖问题，使用了三级缓存。其中一级缓存为单例池（`singletonObjects`），二级缓存为提前曝光对象（`earlySingletonObjects`），三级缓存为提前曝光对象工厂（`singletonFactories`）。

假设A、B循环引用，实例化 A 的时候就将其放入三级缓存中，接着填充属性的时候，发现依赖了 B，同样的流程也是实例化后放入三级缓存，接着去填充属性时又发现自己依赖 A，这时候从缓存中查找到早期暴露的 A，没有 AOP 代理的话，直接将 A 的原始对象注入 B，完成 B 的初始化后，进行属性填充和初始化，这时候 B 完成后，就去完成剩下的 A 的步骤，如果有 AOP 代理，就进行 AOP 处理获取代理后的对象 A，注入 B，走剩下的流程。

**为什么要使用三级缓存呢？二级缓存能解决循环依赖吗？**

如果没有 AOP 代理，二级缓存可以解决问题，但是有 AOP 代理的情况下，只用二级缓存就意味着所有 Bean 在实例化后就要完成 AOP 代理，这样违背了 Spring 设计的原则，Spring 在设计之初就是通过 `AnnotationAwareAspectJAutoProxyCreator` 这个后置处理器来在 Bean 生命周期的最后一步来完成 AOP 代理，而不是在实例化后就立马进行 AOP 代理。

### spring事务

##### spring事务传播行为

- ==定义：==事务传播行为用来描述由某一个事务传播行为修饰的方法被嵌套进另一个方法的时事务如何传播。

  简单来说：事务传播行为是指一个事务方法A被另一个事务方法B调用时，这个事务A应该如何处理。事务A应该在事务B中运行还是另起一个事务，这个由事务A的传播行为决定。

  事务传播属性定义`TransactionDefinition`

  ```java
  int PROPAGATION_REQUIRED = 0;
  int PROPAGATION_SUPPORTS = 1;
  int PROPAGATION_MANDATORY = 2;
  int PROPAGATION_REQUIRES_NEW = 3;
  int PROPAGATION_NOT_SUPPORTED = 4;
  int PROPAGATION_NEVER = 5;
  int PROPAGATION_NESTED = 6;
  ```

  

- 七种事务传播行为

  ![image-20210806105653157](https://gitee.com/shen1shen1/pic-md1/raw/master/image-20210806105653157.png)

参考链接：https://blog.csdn.net/weixin_48272905/article/details/108525283

##### Spring事务的隔离级别

事务隔离级别定义为`TransactionDefinition`

```
int ISOLATION_DEFAULT = -1;
int ISOLATION_READ_UNCOMMITTED = 1;
int ISOLATION_READ_COMMITTED = 2;
int ISOLATION_REPEATABLE_READ = 4;
int ISOLATION_SERIALIZABLE = 8;
```

* **ISOLATION_DEFAULT:**	使用数据库默认的隔离级别，Mysql 默认采用的**可重复读**隔离级别 Oracle 默认采用的**读取已提交**隔离级别.

* **ISOLATION_READ_UNCOMMITTED:** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**
* **ISOLATION_READ_COMMITTED:** 	允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**
* **ISOLATION_REPEATABLE_READ:** 	对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生。**
* **ISOLATION_SERIALIZABLE:** 	最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。但是这将严重影响程序的性能。通常情况下也不会用到该级别。

##### Spring事务基本配置样例

```
<aop:aspectj-autoproxy proxy-target-class="true"/>
	
<bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager">
	<property name="dataSource" ref="dataSource"/>
</bean>

<tx:advice id="transactionAdvice" transaction-manager="transactionManager">
	<tx:attributes>
		<tx:method name="add*" propagation="REQUIRED" rollback-for="Exception,RuntimeException,SQLException"/>
		<tx:method name="remove*" propagation="REQUIRED" rollback-for="Exception,RuntimeException,SQLException"/>
		<tx:method name="edit*" propagation="REQUIRED" rollback-for="Exception,RuntimeException,SQLException"/>
		<tx:method name="login" propagation="NOT_SUPPORTED"/>
		<tx:method name="query*" read-only="true"/>
	</tx:attributes>
</tx:advice>

<aop:config>
	<aop:advisor advice-ref="transactionAdvice" pointcut-ref="transactionPointcut"/>
    <aop:aspect ref="dataSource">
        <aop:pointcut id="transactionPointcut" expression="execution(public * com.gupaoedu..*.service..*Service.*(..))" />
    </aop:aspect>
</aop:config>
```



### SpringMVC工作原理

![image-20210830114040862](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20210830114050.png)

##### SpringMVC流程

1、 用户发送请求至前端控制器DispatcherServlet。

2、 DispatcherServlet收到请求调用HandlerMapping处理器映射器。

3、 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。

4、 DispatcherServlet调用HandlerAdapter处理器适配器。

5、 HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。

6、 Controller执行完成返回ModelAndView。

7、 HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。

8、 DispatcherServlet将ModelAndView传给ViewReslover视图解析器。

9、 ViewReslover解析后返回具体View。

10、DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。

11、 DispatcherServlet响应用户。

##### 组件说明：

以下组件通常使用框架提供实现：

DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。

HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 

HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器。

ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。

### Spring事务失效的原因

https://zhuanlan.zhihu.com/p/101396825

1. 数据库引擎不支持数据库（5.5.5之后默认InnoDB，支持；MyISAM不支持）

2. 没有被Spring管理，即类未被加载为Bean

3. 方法不是public的，如果事务非要用在非public上，可以开启`AspectJ`代理模式

4. 自身调用问题，例如：无事务A调用有事务注解的B,事务不生效；方法A上加了 `@Transactional`，B加了 `REQUIRES_NEW` 新开启一个事务，A调用B,B新开的事务不会生效；因为他们发生了自身调用，就调用该类自己的方法，而没有经过Spring的代理类，默认只有在外部调用事务才会生效

5. 数据源没有配置事务管理器

   ```
   @Bean
   public PlatformTransactionManager transactionManager(DataSource dataSource) {
       return new DataSourceTransactionManager(dataSource);
   }
   ```

   

6. 不支持事务； @Transactional(propagation = Propagation.NOT_SUPPORTED)

7. 未抛出异常

8. 异常类型错误；默认回滚`RuntimeExecptin`，想触发其他异常的回滚，需要配置注解，例如`@Transactional(rollbackFor = Exception.class)`

### JAVA_JDBC生命周期

**导jar包后：**

**1：加载驱动**
Class.forname(“全类名/jar包中Driver的相对路径：com.mysql.jdbc.Driver”)

**2：创建连接数据库对象**
DriverManager.getconnection()

**3：创建操作数据库对象**
connnection对象.createstatement()

**4：编写SQL语句**
“select * from 表名”

**5：执行SQL语句**
statement对象.extcutequery(sql)

（查询的情况下：
6：接收结果集，并操作结果集
ResultSet rs=statement对象.extcutequery(sql)
）

7：施放资源
statement对象.close()
connnection对象.close()

## SpringBoot

### SpringBoot注解

**1、@SpringBootApplication**

这个注解是Spring Boot最核心的注解，用在 Spring Boot的主类上，标识这是一个 Spring Boot 应用，用来开启 Spring Boot 的各项能力。实际上这个注解是@Configuration,@EnableAutoConfiguration,@ComponentScan三个注解的组合。由于这些注解一般都是一起使用，所以Spring Boot提供了一个统一的注解@SpringBootApplication。

**2、@EnableAutoConfiguration**

允许 Spring Boot 自动配置注解，开启这个注解之后，Spring Boot 就能根据当前类路径下的包或者类来配置 Spring Bean。

如：当前类路径下有 Mybatis 这个 JAR 包，MybatisAutoConfiguration 注解就能根据相关参数来配置 Mybatis 的各个 Spring Bean。

@EnableAutoConfiguration实现的关键在于引入了AutoConfigurationImportSelector，其核心逻辑为selectImports方法，逻辑大致如下：

　●　从配置文件META-INF/spring.factories加载所有可能用到的自动配置类；

　●　去重，并将exclude和excludeName属性携带的类排除；

　●　过滤，将满足条件（@Conditional）的自动配置类返回；

**3、@Configuration**

用于定义配置类，指出该类是 Bean 配置的信息源，相当于传统的xml配置文件，一般加在主类上。如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。

**4、@ComponentScan**

组件扫描。让spring Boot扫描到Configuration类并把它加入到程序上下文。

@ComponentScan注解默认就会装配标识了@Controller，@Service，@Repository，@Component注解的类到spring容器中。

**5、@Repository**

用于标注数据访问组件，即DAO组件。

使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。

**6、@Service**

一般用于修饰service层的组件

**7、@RestController**

用于标注控制层组件(如struts中的action)，表示这是个控制器bean,并且是将函数的返回值直 接填入HTTP响应体中,是REST风格的控制器；它是@Controller和@ResponseBody的合集。

**8、@ResponseBody**

表示该方法的返回结果直接写入HTTP response body中

一般在异步获取数据时使用，在使用@RequestMapping后，返回值通常解析为跳转路径，加上@responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。比如异步获取json数据，加上@responsebody后，会直接返回json数据。

**9、@Component**

泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。

**10、@Bean**

相当于XML中的<bean></bean>,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理。

**11、@AutoWired**

byType方式。把配置好的Bean拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。

当加上（required=false）时，就算找不到bean也不报错。

**12、@Qualifier**

当有多个同一类型的Bean时，可以用@Qualifier("name")来指定。与@Autowired配合使用

**13、@Resource(name="name",type="type")**

没有括号内内容的话，默认byName。与@Autowired干类似的事。

**14、@RequestMapping**

RequestMapping是一个用来处理请求地址映射的注解；提供路由信息，负责URL到Controller中的具体函数的映射，可用于类或方法上。用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。

**15、@RequestParam**

用在方法的参数前面。例：

```
@RequestParam String a =request.getParameter(``"a"``)。
```

**16、@PathVariable**

路径变量。参数与大括号里的名字一样要相同。例：

```
RequestMapping(``"user/get/mac/{macAddress}"``)`
    `public String getByMacAddress(@PathVariable String macAddress){``　　`
    `//do something;``
}
```

**17、@Profiles**

Spring Profiles提供了一种隔离应用程序配置的方式，并让这些配置只能在特定的环境下生效。

任何@Component或@Configuration都能被@Profile标记，从而限制加载它的时机。

```
@Configuration``@Profile(``"prod"``)
``public class ProductionConfiguration {``  
``// ...`
`}
```

**18、@ConfigurationProperties**

Spring Boot可使用注解的方式将自定义的properties文件映射到实体bean中，比如config.properties文件。

```
@Data`
`@ConfigurationProperties(``"rocketmq.consumer"``)`
`public class RocketMQConsumerProperties extends RocketMQProperties {`` 
        ``private boolean enabled = ``true``;``  
        ``private String consumerGroup;``  
        ``private MessageModel messageModel = MessageModel.CLUSTERING;``  
        ``private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;``  
        ``private int consumeThreadMin = 20;``  
        ``private int consumeThreadMax = 64;``  
        ``private int consumeConcurrentlyMaxSpan = 2000;``  
        ``private int pullThresholdForQueue = 1000;``  
        ``private int pullInterval = 0;``  
        ``private int consumeMessageBatchMaxSize = 1;``  
        ``private int pullBatchSize = 32;
	``}
```

### 简述SpringBoot框架

2.1什么是SpringBoot

Spring Boot 是所有基于 Spring 开发的项目的起点。Spring Boot 的设计是为了让你尽可能快的跑起来 Spring 应用程序并且尽可能减少你的配置文件。简单来说就是SpringBoot其实不是什么新的框架，它默认配置了很多框架的使用方式，就像maven整合了所有的jar包，spring boot整合了所有的框架（不知道这样比喻是否合适）。

2.2、SpringBoot四个主要特性

1、SpringBoot Starter：他将常用的依赖分组进行了整合，将其合并到一个依赖中，这样就可以一次性添加到项目的Maven或Gradle构建中；

2、自动配置：SpringBoot的自动配置特性利用了Spring4对条件化配置的支持，合理地推测应用所需的bean并自动化配置他们；

3、命令行接口：（Command-line-interface, CLI）：SpringBoot的CLI发挥了Groovy编程语言的优势，并结合自动配置进一步简化Spring应用的开发；

4、Actuatir：它为SpringBoot应用的所有特性构建一个小型的应用程序。但首先，我们快速了解每项特性，更好的体验他们如何简化Spring编程模型。

2.3 SpringBoot开发的具体好处

回顾我们之前的 SSM 项目，搭建过程还是比较繁琐的，需要：

1、配置web.xml，加载spring和spring mvc

2、配置数据库连接、配置spring事务

3、配置加载配置文件的读取，开启注解

。。。

配置完成之后部署tomcat 调试

而使用 Spring Boot 来开发项目则只需要非常少的几个配置就可以搭建起来一个 Web 项目，并且利用 IDEA 可以自动生成生成，这简直是太爽了...

## Mybatis

### 什么是MyBatis？

MyBatis前身叫ibatis是基于Java的数据持久层框架，它内部封装了JDBC，使开发者只需要关注SQL语句本身，而不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程。MyBatis通过xml或注解的方式将要执行的各种statement配置起来，并通过java对象和statement中SQL的动态参数进行映射生成最终执行的SQL语句，最后由MyBatis框架执行SQL并将结果映射为Java对象并返回。MyBatis 的本质就是 Java 对数据库的操作。

MyBatis虽然实现了JPA但是它并不是一个完完全全的ORM组件，而是一个基于SQL开发的半ORM组件。

### MyBatis的生命周期？

1、加载mybatis的配置文件（也加载关联的映射文件）

InputStream inputStream = Resources.getResourceAsStream("mybatis-config.xml");

2、构建SqlSessionFactory工厂

SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(inputStream);

SqlSessionFactory 的生命周期存在于整个 MyBatis 的应用之中，一旦创建了 SqlSessionFactory，就要长期保存它，直至不再使用 MyBatis 应用。
SqlSessionFactoryBuilder 的作用在于创建 SqlSessionFactory，创建成功后它就失去了作用，所以 SqlSessionFactoryBuilder 不需要长期存在，只作用于创建 SqlSessionFactory 的方法中即可。

3、创建能执行映射文件的SqlSession

SqlSession sqlSession = factory.openSession();

SqlSession 应该存活在一个业务请求中，处理完整个请求后，应该关闭这条连接，让它归还给 SqlSessionFactory，否则数据库资源就很快被耗费精光，系统就会瘫痪，所以用 try...catch...finally...语句来保证其正确关闭。

4、创建 SQL Mapper 接口，执行sqlSession.insert等方法

User user = new User("李四", "qqq", "小李", "lisi@qq.com");
sqlSession.insert("com.mybatis.pojo.User.add", user);
sqlSession.commit(); // 事务提交
sqlSession.close(); // 关闭

SQL Mapper 接口由 SqlSession 所创建，它的生命周期应该小于等于 SqlSession 的生命周期。 Mapper 代表的是一个请求中的业务处理 ，所以它应该在一个请求中，一旦处理完了相关的业务，就应该废弃它。

### 解决列名（表中的字段名称）和实体类中的属性名不一致

**方法一：使用别名的形式**

sql层面解决，直接as起别名

![image-20220324083203446](https://gitee.com/shen1shen1/pic-md1/raw/master/img/20220324083212.png)

**方法二：使用resultMap映射实体类属性名和表的字段名一一对应关系**

resultType可以指定将查询结果映射为pojo，但需要pojo的属性名和sql查询的列名一致方可映射成功。

如果sql查询字段名和pojo的属性名不一致,可以通过resultMap将字段名和属性名作一个对应关系,resultMap实质上还需要将查询结果映射到pojo对象中。

resultMap可以实现将查询结果映射为复杂类型的pojo，比如在查询结果映射对象中包括pojo和list实现一对一查询和一对多查询。

**方法三：在核心配置文件中启用下划线与驼峰式命名规则的映射** 

mapUnderscoreToCamelCase：是否启用下划线与驼峰式命名规则的映射（如first_name => firstName） 

### ResultType和ResultMap的区别

- 对象不同
  - resultmap:resultMap如果查询出来的列名和pojo的属性名不一致，通过定义一个resultMap对列名和pojo属性名之间作一个映射关系。
  - resulttype：resultType使用resultType进行输出映射，只有查询出来的列名和pojo中的属性名一致，该列才可以映射成功。
- 描述不同
  - resultmap：resultMap对于一对一表连接的处理方式通常为在主表的pojo中添加嵌套另一个表的pojo，然后在mapper.xml中采用association节点元素进行对另一个表的连接处理。
  - resulttype：resultType无法查询结果映射到pojo对象的pojo属性中，根据对结构集查询遍历的需要选择使用resultType还是resultMap。
- 类型适用不同
  - resultmap：mybatis中在查询进行select映射的时候，返回类型可以用resultType，也可以用resultMap。
  - resulttype：resultType是直接表示返回类型的,而resultMap则是对外部ResultMap的引用，但是resultType跟resultMap不能同时存在。

### mybatis怎么实现用接口从数据库查数据

- 通过动态代理调用代理对象的方法。
- 通过sqlSession执行sql操作的方法：insert|delete|select|update
- 利用Executor对象对其他三大对象进行调度。
- PreparedStatementHandler对sql进行预编译，并进行了基础配置，接着设置参数，并执行sql语句。
- ParameterHandler负责对参数进行设置，其中TypeHandler负责数据库类型和javabean类型的映射。
- 最后查询结果由ResultHandler封装。

### #{}和${}的区别

1.#将传入的数据都当成一个字符串，会对自动传入的数据加一个双引号。如：order by #user_id#，如果传入的值是111,那么解析成sql时的值为order by "111", 如果传入的值是id，则解析成的sql为order by "id".

2.将传入的数据直接显示生成在sql中。如：orderby将传入的数据直接显示生成在sql中。如：orderbyuser_id$，如果传入的值是111,那么解析成sql时的值为order by user_id, 如果传入的值是id，则解析成的sql为order by id.

3.#方式能够很大程度防止sql注入。

4.$方式无法防止Sql注入。

5.$方式一般用于传入数据库对象，例如传入表名.

6.一般能用#的就别用$.

MyBatis排序时使用order by 动态参数时需要注意，用$而不是#

### MyBatis二级缓存

一级缓存：基于PerpetualCache的HashMap本地缓存，其作用域为Session，当Session flush或close后，该Session中的所有Cache就将清空，默认打开一级缓存。

二级缓存：与一级缓存其机制相同，默认也是采用PerpetualCache,HashMap存储，不同在于其存储作用域为Mapper(NameSpace)，并且可自定义存储源，如Ehcache。默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接口（可用来保存对象的状态），可在它的映射文件中配置；

对于缓存数据更新机制，当某一个作用域（一级缓存Session/二级缓存NameSpaces）的进行了C/U/D操作后，默认该作用域下所有select中的缓存将被clear。

# MQ

MQ（Message Queue）消息队列，是基础数据结构中“先进先出”的一种数据结构。指把要传输的数据（消息）放在队列中，用队列机制来实现消息传递——生产者产生消息并把消息放入队列，然后由消费者去处理。消费者可以到指定队列拉取消息，或者订阅相应的队列，由MQ服务端给其推送消息。

**MQ的作用**

消息队列中间件是分布式系统中重要的组件，主要解决应用解耦，异步消息，流量削锋等问题，实现高性能，高可用，可伸缩和最终一致性架构。

**解耦：**一个业务需要多个模块共同实现，或者一条消息有多个系统需要对应处理，只需要主业务完成以后，发送一条MQ，其余模块消费MQ消息，即可实现业务，降低模块之间的耦合。

**异步**：主业务执行结束后从属业务通过MQ，异步执行，减低业务的响应时间，提高用户体验。

**削峰：**高并发情况下，业务异步处理，提供高峰期业务处理能力，避免系统瘫痪。

**MQ的缺点**

1、系统可用性降低。依赖服务也多，服务越容易挂掉。需要考虑MQ瘫痪的情况

2、系统复杂性提高。需要考虑消息丢失、消息重复消费、消息传递的顺序性

3、业务一致性。主业务和从属业务一致性的处理

### 消息队列有什么优缺点

优点上面已经说了，就是**在特殊场景下有其对应的好处**，**解耦**、**异步**、**削峰**。

缺点有以下几个：

- **系统可用性降低**
    系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？如何保证消息队列的高可用，可以[点击这里查看](https://zhuanlan.zhihu.com/docs/high-concurrency/how-to-ensure-high-availability-of-message-queues.md)。

- **系统复杂度提高**

    加入MQ后，还要考虑很多其他的问题，比如：消息有没有重复消费，消息丢失怎么处理，怎么保证消息传递的顺序性，等等

- **一致性问题**
    A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。

所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了 10 倍。但是关键时刻，用，还是得用的。



点对点（1V1）的这种形式，消息生产出来之后有且仅有一个消费者把他消费掉。这种场景就类似于Dubbo里面的consumer和provider。当consumer每需要一个服务 调一个服务就会有一个仅且一个provider为他提供服务（对一次服务来讲）。在这种情况下，理论上我们其实可以用MQ来代替Dubbo，但是Dubbo宕机之后还可以继续使用，MQ宕机的话就不能用了。这是一对一的这种形式，在某种程度上来讲点对点是可以解决Dubbo问题的

发布订阅（1VN）的这种形式，类似于QQ空间，你发一个动态，然后所有人都能看到。这一个生产者生产消息之后，N多个消费者都可以订阅到这条消息，各自做各自的处理。

MQ三个特性

削峰 异步 解耦

削峰指的是我们的业务请求，业务逻辑随着请求量的增大，你的业务系统压力会跟着他增大，当我们引入MQ之后，当我们的业务量增大之后，我们把所有的请求只要进MQ就结束了，立即返回，然后会把这个压力变成平稳的。这个削峰的话就像水库一样，跟线程池里的那个工作队列一样。随着我们请求压力的变大，他所有的业务系统压力因为被MQ给吞掉了，把这一堆请求都放到了你的MQ里面，我们的业务系统压力呢是从MQ中读出消息来之后才去做处理的，所以说压力没有那没大了。但是引入MQ之后也会遇到一个问题，当你的请求进入MQ之后，就要给前端页面一个响应了。但是这个响应一般是中间状态，比如买火车票的时候，下单完成后会显示，订单充足，订单正在处理中请稍后。。然后五秒之后，你的系统再次发送请求，然后告诉你请求成功了。或者是由我们的服务器主动推送这条消息给我们的手机端，但是这个时候用的就不是http协议了（websocket、或者自己封装一个协议、等等），因为HTTP协议不能主动给我们推送消息。然后这个就是MQ的削峰和异步。

然后1VN这种模式是真正的把这个东西给解耦掉了。我们很多步骤都是耦合在一起的，比如说，还是买火车票，下完订单之后，给你发短信啊、发邮件啊、发微信啊、发支付宝这些。这些操作按照以往来讲的话，要先邮件、再微信、再短信、再支付宝等等这些流程，假如每个花一秒时间，四个就是四秒。那按道理来讲，他们四个直接都没有关联，所以可以直接通过这个订阅模式来处理，短信订阅这个队列，微信、支付宝、邮箱都订阅这个队列，然后一条写进来，N个都接收了，接收到之后分别去处理自己的业务逻辑，最后去给他做一个日志的统一打印，或者说做一个统计。谁成功了，谁没成功。比如邮件是1，支付宝是2，微信是4，短信是8。然后成功了的话应该是15，要不是15就看少多少，比如少1那就是邮件没成功，少三就是邮件和支付宝没成功，方便快捷。



#### 没有被正确消费的怎么办

生产者不断生产消息，然后放到MQ里，消费者不断从MQ里取消息然后消费。

生产者正常的把消息放到MQ里面，由于种种原因MQ宕机了，再重启的时候里面消息丢了，消费者没收到消息。

生产者生产消息进MQ里面，然后消费者由于自身原因执行着执行着报错了，导致这个消息没有被正常消费，没有达到我们应有的效果，这个时候也可以说消息丢了

生产者正常的把消息放到MQ里面，然后消费者消费了一遍，由于网络原因，我又拿出那条消息，又消费了一遍。

1. 丢了

    最常见的就是在生产者里面留一个备份，当这个消息被确认正确消费之后，然后就可以清除这个备份。有了这个备份之后就不怕消息丢失了，MQ崩了之后还可以从备份里再拿回来。（可以用DB或者Redis，Redis的话可以用一个列表或者哈希来处理他）

    第一，对于每条消息我们要做唯一编号，这个编号在整个系统里边是唯一的，拿到这个唯一编号之后，然后用一个哈希或者什么，什么A机器的某一个消息队列的请求全放到这个哈希里边，key就是这个唯一编号，value就是整条消息。然后当我们这个消息确认被正确消费了，从这个Redis里边根据我们对应的规则找到他对应的消息，给他设置成null，然后再设置成过期。

    通过一个应答机制来保证我是这个消费者，正常被消费的

2. 重复

    可以借助MQ、Redis做幂等性处理，也可以消息本身做处理。比如转账的时候可以写上转帐户100元，转入100元，转账后账户余额200元

当转账成功后

![img](https://img-blog.csdn.net/20170816171523564?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvb01hdmVyaWNrMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)



# 缓存

## 什么时候用缓存

https://blog.csdn.net/superviser3000/article/details/98994780

缓存在互联网架构中是十分重要的一部分，良好设计的缓存可以有效缓解系统压力，提高系统整体性能。
但是，使用缓存也会提高技术复杂度，一般情况下从两个方面来确认是否需要缓存。

1. **CPU占用高的行为**
    某些过程需要消耗大量的cpu资源进行计算，可以根据业务考虑将结果保存缓存。
2. **数据库访问频繁**
    如果系统的访问量十分巨大，全部请求指到数据库中可能会导致连接不够甚至数据库崩溃，那么使用缓存是一种有效的暂时手段。
    注意，这意味着使用缓存可以随意应对高并发数据量，一旦发生缓存雪崩，而后端没有相应的处理方案的话，数据库肯定会陷入超负荷状态。

**缓存加速原理**

数据库访问数据，磁盘IO，慢
缓存里访问数据，内存操作，快
数据库里的热数据，可在缓存冗余一份
先访问缓存，如果命中，能大大的提升访问速度，降低数据库压力

### 使用基本方法 -Cache Aside 模式

1. 先访问缓存，如果命中直接返回结果
2. 如果没命中缓存，去数据库查询结果，返回并保存到缓存中一份记录

如果读没有命中，或者涉及写操作，系统流程将会变得更复杂。

读操作没有命中缓存

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91cGxvYWQtaW1hZ2VzLmppYW5zaHUuaW8vdXBsb2FkX2ltYWdlcy8xMzQ5MTExMy1jNmMxYjUxYzhkMTVhZmQzLmpwZz9pbWFnZU1vZ3IyL2F1dG8tb3JpZW50L3N0cmlwJTdDaW1hZ2VWaWV3Mi8yL3cvMjcwL2Zvcm1hdC93ZWJw)

image

 

尝试从缓存get数据，结果没有命中
从数据库获取数据，读从库，读写分离
把数据set到缓存，未来能够命中缓存

写操作

写需要修改数据库的值和缓存中的值，那么就会有两种修改方式

1. 先操作数据库，再写缓存
2. 先写缓存，再操作数据库

### 缓存的两种更新方法

- 更新
- 淘汰
    相比于更新，淘汰会多一次cache miss。
    更新操作可能会需要额外的IO操作去查库或者重新计算。
    所以在绝大部分场景下，淘汰比更新需要的性能更小，所以推荐直接淘汰，在下次请求cache miss之后再进行操作放入缓存。

根据上文分析，`操作缓存最好使用先操作数据库再淘汰缓存`是最好的使用方式。

缓存是通过牺牲强一致性来提高性能的。所以使用缓存提升性能，就是会有数据更新的延迟。这需要我们在设计时结合业务仔细思考是否适合用缓存。然后缓存一定要设置过期时间，这个时间太短太长都不好，太短的话请求可能会比较多的落到数据库上，这也意味着失去了缓存的优势。太长的话缓存中的脏数据会使系统长时间处于一个延迟的状态，而且系统中长时间没有人访问的数据一直存在内存中不过期，浪费内存。

# RPC

## RPC简介

### RFC

RFC(Request For Comments) 是由互联网工程任务组(IETF)发布的文件集。文件集中每个文件都有自己唯一编号，例如：rfc1831。目前RFC文件由互联网协会(Internet Society，ISOC)赞助发行。

RPC就收集到了rfc 1831中。可以通过下面网址查看：

https://datatracker.ietf.org/doc/rfc1831/

### RPC

RPC在rfc 1831中收录 ，RPC（Remote Procedure Call） 远程过程调用协议

![img](https://gitee.com/shen1shen1/pic-md1/raw/master/1650186381617wps1.jpg) 

RPC协议规定允许互联网中一台主机程序调用另一台主机程序，而程序员无需对这个交互过程进行编程。在RPC协议中强调当A程序调用B程序中功能或方法时，A是不知道B中方法具体实现的。

RPC是**上层协议**，底层可以基于TCP协议，也可以基于HTTP协议。一般我们说RPC都是基于RPC的具体实现，如：Dubbo框架。从广义上讲只要是满足网络中进行通讯调用都统称为RPC，甚至HTTP协议都可以说是RPC的具体实现，但是具体分析看来RPC协议要比HTTP协议更加高效，基于RPC的框架功能更多。

RPC协议是基于分布式架构而出现的，所以RPC在分布式项目中有着得天独厚的优势。

### RPC和HTTP对比

- **具体实现：**
  - RPC可以基于TCP协议，也可以基于HTTP协议
  - HTTP基于HTTP协议
- **效率：**
  - RPC：自定义具体实现可以减少很多无用的报文内容，使得报文体积更小。
  - HTTP：如果是HTTP 1.1 报文中很多内容都是无用的。如果是HTTP2.0以后和RPC相差不大，比RPC少的可能就是一些服务治理等功能。
- **连接方式：**
  - RPC：支持长连接。
  - HTTP：每次连接都是3次握手。（断开链接为4次挥手）
- **性能:**
  - RPC可以基于很多序列化方式。如：thrift
  - HTTP 主要是通过JSON，序列化和反序列效率更低。
- **注册中心:**
  - RPC:一般RPC框架都带有注册信息
  - HTTP：都是直连
- **负载均衡:**
  - RPC：绝大多熟RPC框架都带有负载均衡策略
  - HTTP：一般都需要借助第三方工具，如nginx
- **综合结论:RPC框架一般带有丰富的服务治理功能，更适合企业内部接口调用。而HTTP更适合多平台之间相互调用**

## 什么是RPC

- RPC（Remote Procedure Call）远程过程调用，简单的理解是一个节点请求另一个节点提供的服务
- 本地过程调用：如果需要将本地student对象的age+1，可以实现一个addAge()方法，将student对象传入，对年龄进行更新之后返回即可，本地方法调用的函数体通过函数指针来指定。
- 远程过程调用：上述操作的过程中，如果addAge()这个方法在服务端，执行函数的函数体在远程机器上，如何告诉机器需要调用这个方法呢？

1. 首先客户端需要告诉服务器，需要调用的函数，这里函数和进程ID存在一个映射，客户端远程调用时，需要查一下函数，找到对应的ID，然后执行函数的代码。
2. 客户端需要把本地参数传给远程函数，本地调用的过程中，直接压栈即可，但是在远程调用过程中不再同一个内存里，无法直接传递函数的参数，因此需要客户端把参数转换成字节流，传给服务端，然后服务端将字节流转换成自身能读取的格式，是一个序列化和反序列化的过程。
   3.数据准备好了之后，如何进行传输？网络传输层需要把调用的ID和序列化后的参数传给服务端，然后把计算好的结果序列化传给客户端，因此TCP层即可完成上述过程，gRPC中采用的是HTTP2协议。

## 手写RPC框架

### HTTPClient实现RPC

### RMI实现RPC

### RMI+Zookeeper自定义框架

单例模式：获取远程调用的对象，服务注册

开闭原则：面向扩展开放，面向修改关闭，这意味着一个实体是允许不改变他的源代码的前提下变更他的行为

反射：

观察者模式：watcher机制涉及状态的监听，而这一状态其实包含了两种状态：客户端与服务器之间的连接状态（通知状态）以及节点的状态（事件类型）

# Dubbo

### Dubbo是什么

Dubbo是阿里巴巴开源的基于JAVA的高性能RPC分布式服务框架，现已成为Apache基金会孵化项目。

### 为什么要用Dubbo

内部使用了 Netty、Zookeeper，保证了==高性能高可用性==。使用 Dubbo 可以将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，可用于提高业务复用灵活扩展，使前端应用能更快速的响应多变的市场需求。

### Dubbo的基本结构：

- 提供者Provider：向注册中心注册服务，暴露服务提供的一方；
- 服务消费者Comsumer:向注册中心注册服务，并获取服务提供列表来使用，服务消费的一方；
- 注册中心Register:服务注册与发现的注册中心；
- 服务监控中心Monitor:统计服务调用次数和调用时间的监控中心；
- 服务容器Container：服务运行容器。

详细查看Dubbo篇：[Dubbo基本原理介绍](https://mp.weixin.qq.com/s?__biz=MzUzOTk5MzYyNg==&mid=2247483891&idx=1&sn=09fb28190ca061c96358ff693345e4f6&chksm=fb3eb286cc493b9021fba07f973ebe13e9122be7fe8219aafdb21ecb4b82676973f4481e1b60&token=230166154&lang=zh_CN#rd)

### Dubbo能做什么

- 透明化的远程方法调用
     -  就像调用本地方法一样调用远程方法
     -  只需简单配置，没有任何API侵入
   - 软负载均衡及容错机制
        -  可在内网代替F5等硬件负载均衡器
   - 服务自动注册与发现
        -  不在需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并可以平滑添加或删除服务提供者。

### 微服务的组成模块

微服务存在的原因：节约成本

Spring cloud:功能多传输慢，dubbo功能少，传输快

微服务模块：

1. **生产者**：对其他人有用的模块，自己用，其他人也有可能用。例如生成二维码，短信发送，文件上传。本质是tomcat+springboot，解析的是自定义协议，不是http协议，和调用controller相同
2. **消费者**：调用方是消费者，类比京东，我就是消费者，原理和MyBatis相同，是AOP
3. **中央管理平台**：JSF管理平台的接口，注册接口，**核心功能是**：记录消费者，生产者，生产者上线主动通知中央管理平台
4. **服务发现，服务治理**：JSF管理平台点进去接口对应的机器统计。管理消费者，生产者有哪些，
5. **传输协议**：dubbo传输快的原因，为了内部传输快，需要自定义协议，减少协议中的一些冗余
6. **传输序列化反序列化**：过程非常慢，毫秒级开销。对象转成字符串，在由字符串重组为对象，原理是反射，性能慢，因为要遍历（内存里的）方法区，（属性，构造方法），检查有没有注解。**优化：**1.去反射，用新的结构代替,例如protobuffer。2.启动时反射可以避免发送数据时反射。可以编译生成一个类能把需要发的类和对象名字，值都发过去，启动的时候调用这个类。通过伴生类。把所有数据类型转成一个byte数组，数据长度通过一个启动时注解确定。
7. **流量控制**：限制消费者调用量，每分钟多少次，消费者自己限制自己，消费者引用的时候会有一个消费者j a r包，一旦超出自己的最大调用，不发送，并且报警，重新申请。**限流算法：**一分钟内多台服务器一共不超过某个调用量。      每个消费者内部有nginx,通过负载均衡确定访问到哪一台机器。
8. **权限控制**：申请之后才能调用。如果没有这一层，生产者崩溃无法找到原因。由消费者自己拦截。
